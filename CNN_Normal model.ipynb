{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02383f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D,Conv1D,MaxPooling1D\n",
    "from keras.preprocessing import image\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_fornat = 'retina'\n",
    "pd.set_option('display.max_rows',2000)\n",
    "pd.set_option('display.max_columns',2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669160f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read multiple file\n",
    "import os\n",
    "import glob\n",
    "fpath = 'C:/Users/HP/Desktop/Data/DataAnalysis_raman/spectrum400pic_Xfixed/'\n",
    "read_file = glob.glob(os.path.join(fpath,\"*.npy\"))\n",
    "np_array = []\n",
    "for file in read_file:\n",
    "    data = np.load(file)\n",
    "    np_array.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4aab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[-0.00864469  0.0006357   0.01244438 ...  0.20125262  0.24801245\n",
      "   0.22432554]\n",
      " [ 0.0018402   0.00993099  0.02183564 ...  0.37911781  0.43591616\n",
      "   0.46893506]\n",
      " [ 0.13422352  0.13921366  0.14955479 ...  0.18717591  0.15615716\n",
      "   0.12713   ]\n",
      " ...\n",
      " [ 0.05029795  0.06236732  0.0761603  ...  0.30991094  0.30719812\n",
      "   0.26446351]\n",
      " [ 0.0201164   0.03192383  0.04508201 ...  0.27126067  0.22192419\n",
      "   0.22990213]\n",
      " [ 0.01482185  0.02738802  0.04101932 ...  0.22819835  0.19387345\n",
      "   0.19890692]]\n",
      "y\n",
      "[[1.         0.         0.        ]\n",
      " [0.         1.         0.        ]\n",
      " [0.         0.         1.        ]\n",
      " ...\n",
      " [0.06008469 0.65929652 0.28061879]\n",
      " [0.34946664 0.36030602 0.29022734]\n",
      " [0.31033173 0.50012997 0.1895383 ]]\n"
     ]
    }
   ],
   "source": [
    "data2 = np.load('all_processed_data.npz')\n",
    "lst = data2.files\n",
    "for item in lst:\n",
    "    print(item)\n",
    "    print(data2[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c557e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64) (400, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(np_array)\n",
    "y = data2['y']\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0f63244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "52d9b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 64, 64) (80, 64, 64) (320, 3) (80, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b704e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 64, 64) (400, 3)\n",
      "(320, 64, 64, 1) (80, 64, 64, 1) (320, 3, 1) (80, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train = np.expand_dims(X_train, 3)\n",
    "X_test = np.expand_dims(X_test, 3)\n",
    "y_train = np.expand_dims(y_train, 2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "#CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e63e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 64, 64, 1) (80, 64, 64, 1) (320, 3, 1) (80, 3)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,(3,3), activation='relu', input_shape=(64,64,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(32,(3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128,(3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048,activation='tanh'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552ff1a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 62, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 29, 29, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 6147      \n",
      "=================================================================\n",
      "Total params: 1,163,075\n",
      "Trainable params: 1,158,499\n",
      "Non-trainable params: 4,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "919b72b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1445 - val_loss: 0.0793\n",
      "Epoch 2/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1215 - val_loss: 0.0794\n",
      "Epoch 3/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1185 - val_loss: 0.0797\n",
      "Epoch 4/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1063 - val_loss: 0.0798\n",
      "Epoch 5/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0942 - val_loss: 0.0799\n",
      "Epoch 6/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0907 - val_loss: 0.0797\n",
      "Epoch 7/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0892 - val_loss: 0.0796\n",
      "Epoch 8/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0799 - val_loss: 0.0795\n",
      "Epoch 9/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0864 - val_loss: 0.0797\n",
      "Epoch 10/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0776 - val_loss: 0.0799\n",
      "Epoch 11/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0759 - val_loss: 0.0800\n",
      "Epoch 12/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0798 - val_loss: 0.0804\n",
      "Epoch 13/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0738 - val_loss: 0.0811\n",
      "Epoch 14/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0758 - val_loss: 0.0810\n",
      "Epoch 15/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0737 - val_loss: 0.0804\n",
      "Epoch 16/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0732 - val_loss: 0.0798\n",
      "Epoch 17/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0706 - val_loss: 0.0794\n",
      "Epoch 18/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0671 - val_loss: 0.0792\n",
      "Epoch 19/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0684 - val_loss: 0.0792\n",
      "Epoch 20/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0647 - val_loss: 0.0794\n",
      "Epoch 21/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0634 - val_loss: 0.0798\n",
      "Epoch 22/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0647 - val_loss: 0.0796\n",
      "Epoch 23/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0618 - val_loss: 0.0793\n",
      "Epoch 24/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0592 - val_loss: 0.0796\n",
      "Epoch 25/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0569 - val_loss: 0.0797\n",
      "Epoch 26/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0583 - val_loss: 0.0796\n",
      "Epoch 27/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0578 - val_loss: 0.0798\n",
      "Epoch 28/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0554 - val_loss: 0.0801\n",
      "Epoch 29/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0554 - val_loss: 0.0799\n",
      "Epoch 30/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0472 - val_loss: 0.0794\n",
      "Epoch 31/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0490 - val_loss: 0.0805\n",
      "Epoch 32/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0498 - val_loss: 0.0849\n",
      "Epoch 33/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0461 - val_loss: 0.0890\n",
      "Epoch 34/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0418 - val_loss: 0.0858\n",
      "Epoch 35/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0507 - val_loss: 0.0840\n",
      "Epoch 36/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0462 - val_loss: 0.0838\n",
      "Epoch 37/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0447 - val_loss: 0.0890\n",
      "Epoch 38/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0380 - val_loss: 0.0975\n",
      "Epoch 39/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0426 - val_loss: 0.1007\n",
      "Epoch 40/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0424 - val_loss: 0.0969\n",
      "Epoch 41/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0330 - val_loss: 0.0943\n",
      "Epoch 42/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0386 - val_loss: 0.0930\n",
      "Epoch 43/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0342 - val_loss: 0.0943\n",
      "Epoch 44/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0346 - val_loss: 0.1016\n",
      "Epoch 45/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0352 - val_loss: 0.1017\n",
      "Epoch 46/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0308 - val_loss: 0.0984\n",
      "Epoch 47/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0318 - val_loss: 0.0949\n",
      "Epoch 48/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0353 - val_loss: 0.1119\n",
      "Epoch 49/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0306 - val_loss: 0.1303\n",
      "Epoch 50/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0316 - val_loss: 0.1450\n",
      "Epoch 51/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0358 - val_loss: 0.1387\n",
      "Epoch 52/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0328 - val_loss: 0.1208\n",
      "Epoch 53/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0309 - val_loss: 0.1039\n",
      "Epoch 54/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0284 - val_loss: 0.0999\n",
      "Epoch 55/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0327 - val_loss: 0.1043\n",
      "Epoch 56/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0327 - val_loss: 0.1148\n",
      "Epoch 57/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0280 - val_loss: 0.1215\n",
      "Epoch 58/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0280 - val_loss: 0.1235\n",
      "Epoch 59/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0285 - val_loss: 0.1244\n",
      "Epoch 60/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0276 - val_loss: 0.1236\n",
      "Epoch 61/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0251 - val_loss: 0.1231\n",
      "Epoch 62/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0234 - val_loss: 0.1197\n",
      "Epoch 63/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0238 - val_loss: 0.1210\n",
      "Epoch 64/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0237 - val_loss: 0.1232\n",
      "Epoch 65/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0256 - val_loss: 0.1251\n",
      "Epoch 66/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0222 - val_loss: 0.1355\n",
      "Epoch 67/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0202 - val_loss: 0.1526\n",
      "Epoch 68/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0239 - val_loss: 0.1688\n",
      "Epoch 69/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0258 - val_loss: 0.1757\n",
      "Epoch 70/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0204 - val_loss: 0.1813\n",
      "Epoch 71/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0212 - val_loss: 0.1774\n",
      "Epoch 72/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0211 - val_loss: 0.1703\n",
      "Epoch 73/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0218 - val_loss: 0.1519\n",
      "Epoch 74/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0177 - val_loss: 0.1349\n",
      "Epoch 75/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0221 - val_loss: 0.1253\n",
      "Epoch 76/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0194 - val_loss: 0.1236\n",
      "Epoch 77/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0215 - val_loss: 0.1382\n",
      "Epoch 78/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0211 - val_loss: 0.1490\n",
      "Epoch 79/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0179 - val_loss: 0.1513\n",
      "Epoch 80/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0203 - val_loss: 0.1660\n",
      "Epoch 81/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0210 - val_loss: 0.2075\n",
      "Epoch 82/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0226 - val_loss: 0.2076\n",
      "Epoch 83/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0247 - val_loss: 0.1779\n",
      "Epoch 84/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0195 - val_loss: 0.1459\n",
      "Epoch 85/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0184 - val_loss: 0.1379\n",
      "Epoch 86/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0200 - val_loss: 0.1478\n",
      "Epoch 87/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0178 - val_loss: 0.1490\n",
      "Epoch 88/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0200 - val_loss: 0.1446\n",
      "Epoch 89/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0198 - val_loss: 0.1449\n",
      "Epoch 90/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0190 - val_loss: 0.1588\n",
      "Epoch 91/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0178 - val_loss: 0.1883\n",
      "Epoch 92/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0175 - val_loss: 0.2295\n",
      "Epoch 93/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0166 - val_loss: 0.2514\n",
      "Epoch 94/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0194 - val_loss: 0.2453\n",
      "Epoch 95/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0178 - val_loss: 0.2167\n",
      "Epoch 96/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0159 - val_loss: 0.1811\n",
      "Epoch 97/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0192 - val_loss: 0.1735\n",
      "Epoch 98/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0149 - val_loss: 0.1801\n",
      "Epoch 99/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0155 - val_loss: 0.1821\n",
      "Epoch 100/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0154 - val_loss: 0.1777\n",
      "Epoch 101/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0137 - val_loss: 0.1727\n",
      "Epoch 102/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0153 - val_loss: 0.1603\n",
      "Epoch 103/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0125 - val_loss: 0.1504\n",
      "Epoch 104/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0140 - val_loss: 0.1669\n",
      "Epoch 105/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0123 - val_loss: 0.1996\n",
      "Epoch 106/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0137 - val_loss: 0.2143\n",
      "Epoch 107/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0151 - val_loss: 0.1758\n",
      "Epoch 108/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0136 - val_loss: 0.1434\n",
      "Epoch 109/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0141 - val_loss: 0.1329\n",
      "Epoch 110/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0145 - val_loss: 0.1353\n",
      "Epoch 111/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0157 - val_loss: 0.1630\n",
      "Epoch 112/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0139 - val_loss: 0.1852\n",
      "Epoch 113/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0169 - val_loss: 0.1939\n",
      "Epoch 114/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0144 - val_loss: 0.1636\n",
      "Epoch 115/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0162 - val_loss: 0.1502\n",
      "Epoch 116/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0141 - val_loss: 0.1372\n",
      "Epoch 117/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0146 - val_loss: 0.1231\n",
      "Epoch 118/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0133 - val_loss: 0.1272\n",
      "Epoch 119/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0138 - val_loss: 0.1285\n",
      "Epoch 120/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0134 - val_loss: 0.1262\n",
      "Epoch 121/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0132 - val_loss: 0.1298\n",
      "Epoch 122/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0121 - val_loss: 0.1521\n",
      "Epoch 123/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0148 - val_loss: 0.1853\n",
      "Epoch 124/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - val_loss: 0.2101\n",
      "Epoch 125/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0132 - val_loss: 0.2068\n",
      "Epoch 126/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0133 - val_loss: 0.1897\n",
      "Epoch 127/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0124 - val_loss: 0.1651\n",
      "Epoch 128/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0103 - val_loss: 0.1627\n",
      "Epoch 129/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0121 - val_loss: 0.1866\n",
      "Epoch 130/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.2017\n",
      "Epoch 131/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0139 - val_loss: 0.1946\n",
      "Epoch 132/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0121 - val_loss: 0.1832\n",
      "Epoch 133/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0128 - val_loss: 0.1851\n",
      "Epoch 134/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0134 - val_loss: 0.2115\n",
      "Epoch 135/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0104 - val_loss: 0.2381\n",
      "Epoch 136/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0112 - val_loss: 0.2408\n",
      "Epoch 137/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0103 - val_loss: 0.2234\n",
      "Epoch 138/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.2163\n",
      "Epoch 139/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0128 - val_loss: 0.2254\n",
      "Epoch 140/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0105 - val_loss: 0.2440\n",
      "Epoch 141/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0104 - val_loss: 0.2577\n",
      "Epoch 142/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0120 - val_loss: 0.2534\n",
      "Epoch 143/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0111 - val_loss: 0.2382\n",
      "Epoch 144/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0094 - val_loss: 0.2187\n",
      "Epoch 145/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0108 - val_loss: 0.2081\n",
      "Epoch 146/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0131 - val_loss: 0.2181\n",
      "Epoch 147/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0110 - val_loss: 0.2359\n",
      "Epoch 148/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0103 - val_loss: 0.2478\n",
      "Epoch 149/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0113 - val_loss: 0.2559\n",
      "Epoch 150/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0103 - val_loss: 0.2588\n",
      "Epoch 151/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0105 - val_loss: 0.2643\n",
      "Epoch 152/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0119 - val_loss: 0.2721\n",
      "Epoch 153/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0106 - val_loss: 0.2739\n",
      "Epoch 154/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0103 - val_loss: 0.2713\n",
      "Epoch 155/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0107 - val_loss: 0.2599\n",
      "Epoch 156/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0105 - val_loss: 0.2475\n",
      "Epoch 157/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0106 - val_loss: 0.2417\n",
      "Epoch 158/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0108 - val_loss: 0.2536\n",
      "Epoch 159/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0104 - val_loss: 0.2659\n",
      "Epoch 160/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0101 - val_loss: 0.2727\n",
      "Epoch 161/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0109 - val_loss: 0.2685\n",
      "Epoch 162/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0095 - val_loss: 0.2583\n",
      "Epoch 163/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0104 - val_loss: 0.2486\n",
      "Epoch 164/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0107 - val_loss: 0.2544\n",
      "Epoch 165/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0098 - val_loss: 0.2669\n",
      "Epoch 166/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0091 - val_loss: 0.2753\n",
      "Epoch 167/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0101 - val_loss: 0.2761\n",
      "Epoch 168/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0094 - val_loss: 0.2744\n",
      "Epoch 169/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0097 - val_loss: 0.2760\n",
      "Epoch 170/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0095 - val_loss: 0.2742\n",
      "Epoch 171/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0089 - val_loss: 0.2754\n",
      "Epoch 172/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0091 - val_loss: 0.2803\n",
      "Epoch 173/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0089 - val_loss: 0.2832\n",
      "Epoch 174/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0090 - val_loss: 0.2800\n",
      "Epoch 175/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0087 - val_loss: 0.2693\n",
      "Epoch 176/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0086 - val_loss: 0.2554\n",
      "Epoch 177/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0090 - val_loss: 0.2471\n",
      "Epoch 178/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0086 - val_loss: 0.2562\n",
      "Epoch 179/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0088 - val_loss: 0.2730\n",
      "Epoch 180/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0076 - val_loss: 0.2850\n",
      "Epoch 181/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0083 - val_loss: 0.2882\n",
      "Epoch 182/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0078 - val_loss: 0.2855\n",
      "Epoch 183/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0078 - val_loss: 0.2785\n",
      "Epoch 184/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0084 - val_loss: 0.2712\n",
      "Epoch 185/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0081 - val_loss: 0.2651\n",
      "Epoch 186/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0079 - val_loss: 0.2642\n",
      "Epoch 187/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0075 - val_loss: 0.2588\n",
      "Epoch 188/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0080 - val_loss: 0.2626\n",
      "Epoch 189/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0079 - val_loss: 0.2651\n",
      "Epoch 190/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0078 - val_loss: 0.2656\n",
      "Epoch 191/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0071 - val_loss: 0.2656\n",
      "Epoch 192/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0076 - val_loss: 0.2687\n",
      "Epoch 193/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0086 - val_loss: 0.2804\n",
      "Epoch 194/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0095 - val_loss: 0.2900\n",
      "Epoch 195/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0083 - val_loss: 0.2884\n",
      "Epoch 196/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0082 - val_loss: 0.2819\n",
      "Epoch 197/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0080 - val_loss: 0.2758\n",
      "Epoch 198/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0081 - val_loss: 0.2751\n",
      "Epoch 199/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0084 - val_loss: 0.2783\n",
      "Epoch 200/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0078 - val_loss: 0.2816\n",
      "Epoch 201/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0076 - val_loss: 0.2809\n",
      "Epoch 202/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0070 - val_loss: 0.2817\n",
      "Epoch 203/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0080 - val_loss: 0.2878\n",
      "Epoch 204/3000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0076 - val_loss: 0.2892\n",
      "Epoch 205/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0075 - val_loss: 0.2898\n",
      "Epoch 206/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0073 - val_loss: 0.2868\n",
      "Epoch 207/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0079 - val_loss: 0.2757\n",
      "Epoch 208/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0067 - val_loss: 0.2524\n",
      "Epoch 209/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0074 - val_loss: 0.2570\n",
      "Epoch 210/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0079 - val_loss: 0.2699\n",
      "Epoch 211/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0075 - val_loss: 0.2797\n",
      "Epoch 212/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - val_loss: 0.2862\n",
      "Epoch 213/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0073 - val_loss: 0.2880\n",
      "Epoch 214/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0071 - val_loss: 0.2870\n",
      "Epoch 215/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0073 - val_loss: 0.2843\n",
      "Epoch 216/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0077 - val_loss: 0.2709\n",
      "Epoch 217/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0079 - val_loss: 0.2608\n",
      "Epoch 218/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0071 - val_loss: 0.2519\n",
      "Epoch 219/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0069 - val_loss: 0.2462\n",
      "Epoch 220/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0067 - val_loss: 0.2563\n",
      "Epoch 221/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0070 - val_loss: 0.2645\n",
      "Epoch 222/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0069 - val_loss: 0.2695\n",
      "Epoch 223/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0069 - val_loss: 0.2746\n",
      "Epoch 224/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0068 - val_loss: 0.2800\n",
      "Epoch 225/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0066 - val_loss: 0.2846\n",
      "Epoch 226/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - val_loss: 0.2867\n",
      "Epoch 227/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - val_loss: 0.2849\n",
      "Epoch 228/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0069 - val_loss: 0.2748\n",
      "Epoch 229/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0072 - val_loss: 0.2541\n",
      "Epoch 230/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0066 - val_loss: 0.2429\n",
      "Epoch 231/3000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0069 - val_loss: 0.2426\n",
      "Epoch 232/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0064 - val_loss: 0.2605\n",
      "Epoch 233/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0061 - val_loss: 0.2696\n",
      "Epoch 234/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0071 - val_loss: 0.2710\n",
      "Epoch 235/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - val_loss: 0.2701\n",
      "Epoch 236/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0067 - val_loss: 0.2668\n",
      "Epoch 237/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0062 - val_loss: 0.2600\n",
      "Epoch 238/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0063 - val_loss: 0.2640\n",
      "Epoch 239/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0066 - val_loss: 0.2670\n",
      "Epoch 240/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0066 - val_loss: 0.2736\n",
      "Epoch 241/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0059 - val_loss: 0.2740\n",
      "Epoch 242/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0062 - val_loss: 0.2711\n",
      "Epoch 243/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0063 - val_loss: 0.2643\n",
      "Epoch 244/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0056 - val_loss: 0.2587\n",
      "Epoch 245/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0057 - val_loss: 0.2529\n",
      "Epoch 246/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0051 - val_loss: 0.2378\n",
      "Epoch 247/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0054 - val_loss: 0.2174\n",
      "Epoch 248/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0059 - val_loss: 0.2130\n",
      "Epoch 249/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0058 - val_loss: 0.2077\n",
      "Epoch 250/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0059 - val_loss: 0.2088\n",
      "Epoch 251/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0058 - val_loss: 0.2663\n",
      "Epoch 252/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0059 - val_loss: 0.2867\n",
      "Epoch 253/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0063 - val_loss: 0.2925\n",
      "Epoch 254/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0063 - val_loss: 0.2933\n",
      "Epoch 255/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0057 - val_loss: 0.2934\n",
      "Epoch 256/3000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0054 - val_loss: 0.2935\n",
      "Epoch 257/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0050 - val_loss: 0.2906\n",
      "Epoch 258/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0056 - val_loss: 0.2944\n",
      "Epoch 259/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0059 - val_loss: 0.2986\n",
      "Epoch 260/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0054 - val_loss: 0.3005\n",
      "Epoch 261/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0064 - val_loss: 0.3009\n",
      "Epoch 262/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0063 - val_loss: 0.3007\n",
      "Epoch 263/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0064 - val_loss: 0.3000\n",
      "Epoch 264/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0061 - val_loss: 0.2997\n",
      "Epoch 265/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0059 - val_loss: 0.2993\n",
      "Epoch 266/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0058 - val_loss: 0.2995\n",
      "Epoch 267/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0062 - val_loss: 0.2999\n",
      "Epoch 268/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0061 - val_loss: 0.3005\n",
      "Epoch 269/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0052 - val_loss: 0.3018\n",
      "Epoch 270/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0054 - val_loss: 0.3023\n",
      "Epoch 271/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - val_loss: 0.3022\n",
      "Epoch 272/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0059 - val_loss: 0.3021\n",
      "Epoch 273/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0058 - val_loss: 0.3020\n",
      "Epoch 274/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0055 - val_loss: 0.3021\n",
      "Epoch 275/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0055 - val_loss: 0.3021\n",
      "Epoch 276/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0060 - val_loss: 0.3019\n",
      "Epoch 277/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0057 - val_loss: 0.3013\n",
      "Epoch 278/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0055 - val_loss: 0.3006\n",
      "Epoch 279/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0053 - val_loss: 0.3003\n",
      "Epoch 280/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0057 - val_loss: 0.3008\n",
      "Epoch 281/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0054 - val_loss: 0.3015\n",
      "Epoch 282/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0055 - val_loss: 0.3017\n",
      "Epoch 283/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0051 - val_loss: 0.3020\n",
      "Epoch 284/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0054 - val_loss: 0.3020\n",
      "Epoch 285/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0054 - val_loss: 0.3015\n",
      "Epoch 286/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0056 - val_loss: 0.3017\n",
      "Epoch 287/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0054 - val_loss: 0.3018\n",
      "Epoch 288/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0053 - val_loss: 0.3021\n",
      "Epoch 289/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0054 - val_loss: 0.3024\n",
      "Epoch 290/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0053 - val_loss: 0.3026\n",
      "Epoch 291/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0056 - val_loss: 0.3024\n",
      "Epoch 292/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0050 - val_loss: 0.3021\n",
      "Epoch 293/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0050 - val_loss: 0.3020\n",
      "Epoch 294/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0051 - val_loss: 0.3021\n",
      "Epoch 295/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0052 - val_loss: 0.3023\n",
      "Epoch 296/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0052 - val_loss: 0.3025\n",
      "Epoch 297/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0048 - val_loss: 0.3025\n",
      "Epoch 298/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0049 - val_loss: 0.3024\n",
      "Epoch 299/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0048 - val_loss: 0.3024\n",
      "Epoch 300/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0051 - val_loss: 0.3021\n",
      "Epoch 301/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0048 - val_loss: 0.3020\n",
      "Epoch 302/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0050 - val_loss: 0.3021\n",
      "Epoch 303/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0046 - val_loss: 0.3018\n",
      "Epoch 304/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0048 - val_loss: 0.3015\n",
      "Epoch 305/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0047 - val_loss: 0.3006\n",
      "Epoch 306/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0042 - val_loss: 0.2998\n",
      "Epoch 307/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0041 - val_loss: 0.3002\n",
      "Epoch 308/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0042 - val_loss: 0.3007\n",
      "Epoch 309/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0041 - val_loss: 0.3015\n",
      "Epoch 310/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.3021\n",
      "Epoch 311/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.3025\n",
      "Epoch 312/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0042 - val_loss: 0.3025\n",
      "Epoch 313/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0053 - val_loss: 0.3024\n",
      "Epoch 314/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.3018\n",
      "Epoch 315/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.3010\n",
      "Epoch 316/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0039 - val_loss: 0.3006\n",
      "Epoch 317/3000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0038 - val_loss: 0.3003\n",
      "Epoch 318/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0037 - val_loss: 0.2991\n",
      "Epoch 319/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0040 - val_loss: 0.2984\n",
      "Epoch 320/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0039 - val_loss: 0.2988\n",
      "Epoch 321/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0037 - val_loss: 0.2996\n",
      "Epoch 322/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0044 - val_loss: 0.2998\n",
      "Epoch 323/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0046 - val_loss: 0.2996\n",
      "Epoch 324/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0041 - val_loss: 0.2997\n",
      "Epoch 325/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.2997\n",
      "Epoch 326/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0042 - val_loss: 0.2998\n",
      "Epoch 327/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0044 - val_loss: 0.2991\n",
      "Epoch 328/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0041 - val_loss: 0.2982\n",
      "Epoch 329/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0039 - val_loss: 0.2975\n",
      "Epoch 330/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0040 - val_loss: 0.2963\n",
      "Epoch 331/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0037 - val_loss: 0.2957\n",
      "Epoch 332/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0039 - val_loss: 0.2945\n",
      "Epoch 333/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0038 - val_loss: 0.2946\n",
      "Epoch 334/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0040 - val_loss: 0.2945\n",
      "Epoch 335/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.2935\n",
      "Epoch 336/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - val_loss: 0.2915\n",
      "Epoch 337/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0037 - val_loss: 0.2901\n",
      "Epoch 338/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0038 - val_loss: 0.2885\n",
      "Epoch 339/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0036 - val_loss: 0.2861\n",
      "Epoch 340/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0036 - val_loss: 0.2855\n",
      "Epoch 341/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0036 - val_loss: 0.2869\n",
      "Epoch 342/3000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0034 - val_loss: 0.2881\n",
      "Epoch 343/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.2863\n",
      "Epoch 344/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0035 - val_loss: 0.2830\n",
      "Epoch 345/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.2812\n",
      "Epoch 346/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - val_loss: 0.2820\n",
      "Epoch 347/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2838\n",
      "Epoch 348/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - val_loss: 0.2848\n",
      "Epoch 349/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.2845\n",
      "Epoch 350/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.2828\n",
      "Epoch 351/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2808\n",
      "Epoch 352/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - val_loss: 0.2768\n",
      "Epoch 353/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2721\n",
      "Epoch 354/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.2664\n",
      "Epoch 355/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.2585\n",
      "Epoch 356/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.2573\n",
      "Epoch 357/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2608\n",
      "Epoch 358/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.2646\n",
      "Epoch 359/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.2676\n",
      "Epoch 360/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0042 - val_loss: 0.2709\n",
      "Epoch 361/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0049 - val_loss: 0.2713\n",
      "Epoch 362/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0043 - val_loss: 0.2691\n",
      "Epoch 363/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0041 - val_loss: 0.2646\n",
      "Epoch 364/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0041 - val_loss: 0.2615\n",
      "Epoch 365/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0040 - val_loss: 0.2594\n",
      "Epoch 366/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0038 - val_loss: 0.2593\n",
      "Epoch 367/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.2592\n",
      "Epoch 368/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0040 - val_loss: 0.2580\n",
      "Epoch 369/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.2575\n",
      "Epoch 370/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.2557\n",
      "Epoch 371/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.2536\n",
      "Epoch 372/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0039 - val_loss: 0.2521\n",
      "Epoch 373/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.2527\n",
      "Epoch 374/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0038 - val_loss: 0.2558\n",
      "Epoch 375/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.2574\n",
      "Epoch 376/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0041 - val_loss: 0.2571\n",
      "Epoch 377/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0038 - val_loss: 0.2538\n",
      "Epoch 378/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.2500\n",
      "Epoch 379/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0036 - val_loss: 0.2467\n",
      "Epoch 380/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.2453\n",
      "Epoch 381/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.2455\n",
      "Epoch 382/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.2463\n",
      "Epoch 383/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0038 - val_loss: 0.2482\n",
      "Epoch 384/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2495\n",
      "Epoch 385/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0037 - val_loss: 0.2497\n",
      "Epoch 386/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2486\n",
      "Epoch 387/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0038 - val_loss: 0.2480\n",
      "Epoch 388/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0038 - val_loss: 0.2484\n",
      "Epoch 389/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0036 - val_loss: 0.2484\n",
      "Epoch 390/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2472\n",
      "Epoch 391/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - val_loss: 0.2459\n",
      "Epoch 392/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.2441\n",
      "Epoch 393/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0037 - val_loss: 0.2424\n",
      "Epoch 394/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0037 - val_loss: 0.2417\n",
      "Epoch 395/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0036 - val_loss: 0.2426\n",
      "Epoch 396/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0035 - val_loss: 0.2450\n",
      "Epoch 397/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2477\n",
      "Epoch 398/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2506\n",
      "Epoch 399/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2507\n",
      "Epoch 400/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2502\n",
      "Epoch 401/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0036 - val_loss: 0.2482\n",
      "Epoch 402/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0036 - val_loss: 0.2447\n",
      "Epoch 403/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2423\n",
      "Epoch 404/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2406\n",
      "Epoch 405/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0035 - val_loss: 0.2396\n",
      "Epoch 406/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.2383\n",
      "Epoch 407/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.2384\n",
      "Epoch 408/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2392\n",
      "Epoch 409/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.2385\n",
      "Epoch 410/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0036 - val_loss: 0.2356\n",
      "Epoch 411/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2326\n",
      "Epoch 412/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.2312\n",
      "Epoch 413/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.2304\n",
      "Epoch 414/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.2305\n",
      "Epoch 415/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - val_loss: 0.2309\n",
      "Epoch 416/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2313\n",
      "Epoch 417/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2314\n",
      "Epoch 418/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2302\n",
      "Epoch 419/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0035 - val_loss: 0.2288\n",
      "Epoch 420/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0034 - val_loss: 0.2279\n",
      "Epoch 421/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2273\n",
      "Epoch 422/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.2273\n",
      "Epoch 423/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0034 - val_loss: 0.2277\n",
      "Epoch 424/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2284\n",
      "Epoch 425/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2294\n",
      "Epoch 426/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.2302\n",
      "Epoch 427/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2306\n",
      "Epoch 428/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0035 - val_loss: 0.2306\n",
      "Epoch 429/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.2304\n",
      "Epoch 430/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0034 - val_loss: 0.2296\n",
      "Epoch 431/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.2275\n",
      "Epoch 432/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0033 - val_loss: 0.2253\n",
      "Epoch 433/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - val_loss: 0.2240\n",
      "Epoch 434/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2238\n",
      "Epoch 435/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0033 - val_loss: 0.2244\n",
      "Epoch 436/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2250\n",
      "Epoch 437/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0033 - val_loss: 0.2253\n",
      "Epoch 438/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0033 - val_loss: 0.2254\n",
      "Epoch 439/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2252\n",
      "Epoch 440/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0034 - val_loss: 0.2227\n",
      "Epoch 441/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - val_loss: 0.2202\n",
      "Epoch 442/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2179\n",
      "Epoch 443/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2156\n",
      "Epoch 444/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.2139\n",
      "Epoch 445/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0032 - val_loss: 0.2133\n",
      "Epoch 446/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2133\n",
      "Epoch 447/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2134\n",
      "Epoch 448/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2134\n",
      "Epoch 449/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0033 - val_loss: 0.2131\n",
      "Epoch 450/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2131\n",
      "Epoch 451/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0031 - val_loss: 0.2130\n",
      "Epoch 452/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2125\n",
      "Epoch 453/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2120\n",
      "Epoch 454/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2118\n",
      "Epoch 455/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2113\n",
      "Epoch 456/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2105\n",
      "Epoch 457/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.2095\n",
      "Epoch 458/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2086\n",
      "Epoch 459/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2078\n",
      "Epoch 460/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - val_loss: 0.2072\n",
      "Epoch 461/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2065\n",
      "Epoch 462/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0033 - val_loss: 0.2066\n",
      "Epoch 463/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2072\n",
      "Epoch 464/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2077\n",
      "Epoch 465/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2080\n",
      "Epoch 466/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2075\n",
      "Epoch 467/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2071\n",
      "Epoch 468/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.2063\n",
      "Epoch 469/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.2058\n",
      "Epoch 470/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0032 - val_loss: 0.2048\n",
      "Epoch 471/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2038\n",
      "Epoch 472/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.2034\n",
      "Epoch 473/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0031 - val_loss: 0.2037\n",
      "Epoch 474/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.2041\n",
      "Epoch 475/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.2045\n",
      "Epoch 476/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2047\n",
      "Epoch 477/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.2042\n",
      "Epoch 478/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2031\n",
      "Epoch 479/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.2026\n",
      "Epoch 480/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - val_loss: 0.2023\n",
      "Epoch 481/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - val_loss: 0.2022\n",
      "Epoch 482/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.2022\n",
      "Epoch 483/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0032 - val_loss: 0.2022\n",
      "Epoch 484/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0031 - val_loss: 0.2026\n",
      "Epoch 485/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.2027\n",
      "Epoch 486/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.2028\n",
      "Epoch 487/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.2031\n",
      "Epoch 488/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.2030\n",
      "Epoch 489/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.2018\n",
      "Epoch 490/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0031 - val_loss: 0.1996\n",
      "Epoch 491/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - val_loss: 0.1980\n",
      "Epoch 492/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1969\n",
      "Epoch 493/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1968\n",
      "Epoch 494/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1973\n",
      "Epoch 495/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.1978\n",
      "Epoch 496/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0032 - val_loss: 0.1977\n",
      "Epoch 497/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1974\n",
      "Epoch 498/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0032 - val_loss: 0.1975\n",
      "Epoch 499/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1976\n",
      "Epoch 500/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1976\n",
      "Epoch 501/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1972\n",
      "Epoch 502/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0031 - val_loss: 0.1962\n",
      "Epoch 503/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0031 - val_loss: 0.1952\n",
      "Epoch 504/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0031 - val_loss: 0.1941\n",
      "Epoch 505/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.1930\n",
      "Epoch 506/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1921\n",
      "Epoch 507/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1913\n",
      "Epoch 508/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1910\n",
      "Epoch 509/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0032 - val_loss: 0.1911\n",
      "Epoch 510/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1915\n",
      "Epoch 511/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1915\n",
      "Epoch 512/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1911\n",
      "Epoch 513/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1902\n",
      "Epoch 514/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1889\n",
      "Epoch 515/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1876\n",
      "Epoch 516/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1878\n",
      "Epoch 517/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0031 - val_loss: 0.1883\n",
      "Epoch 518/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1888\n",
      "Epoch 519/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1892\n",
      "Epoch 520/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1885\n",
      "Epoch 521/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1867\n",
      "Epoch 522/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1842\n",
      "Epoch 523/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1820\n",
      "Epoch 524/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1805\n",
      "Epoch 525/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1806\n",
      "Epoch 526/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - val_loss: 0.1821\n",
      "Epoch 527/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1838\n",
      "Epoch 528/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1847\n",
      "Epoch 529/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1845\n",
      "Epoch 530/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1828\n",
      "Epoch 531/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0031 - val_loss: 0.1806\n",
      "Epoch 532/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1786\n",
      "Epoch 533/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1783\n",
      "Epoch 534/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1788\n",
      "Epoch 535/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1797\n",
      "Epoch 536/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1810\n",
      "Epoch 537/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0031 - val_loss: 0.1824\n",
      "Epoch 538/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1824\n",
      "Epoch 539/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1816\n",
      "Epoch 540/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1801\n",
      "Epoch 541/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1780\n",
      "Epoch 542/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1758\n",
      "Epoch 543/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1747\n",
      "Epoch 544/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1741\n",
      "Epoch 545/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1741\n",
      "Epoch 546/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1742\n",
      "Epoch 547/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1737\n",
      "Epoch 548/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1732\n",
      "Epoch 549/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1720\n",
      "Epoch 550/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1712\n",
      "Epoch 551/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1709\n",
      "Epoch 552/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1711\n",
      "Epoch 553/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1711\n",
      "Epoch 554/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0030 - val_loss: 0.1708\n",
      "Epoch 555/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1703\n",
      "Epoch 556/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0031 - val_loss: 0.1691\n",
      "Epoch 557/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1681\n",
      "Epoch 558/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1668\n",
      "Epoch 559/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0031 - val_loss: 0.1661\n",
      "Epoch 560/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1657\n",
      "Epoch 561/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1660\n",
      "Epoch 562/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1665\n",
      "Epoch 563/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1666\n",
      "Epoch 564/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1661\n",
      "Epoch 565/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0031 - val_loss: 0.1647\n",
      "Epoch 566/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1628\n",
      "Epoch 567/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 0.1615\n",
      "Epoch 568/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1610\n",
      "Epoch 569/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1605\n",
      "Epoch 570/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1593\n",
      "Epoch 571/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1579\n",
      "Epoch 572/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1555\n",
      "Epoch 573/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1528\n",
      "Epoch 574/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1564\n",
      "Epoch 575/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1593\n",
      "Epoch 576/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1604\n",
      "Epoch 577/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1604\n",
      "Epoch 578/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1593\n",
      "Epoch 579/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0030 - val_loss: 0.1574\n",
      "Epoch 580/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1560\n",
      "Epoch 581/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1551\n",
      "Epoch 582/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1553\n",
      "Epoch 583/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 0.1556\n",
      "Epoch 584/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1558\n",
      "Epoch 585/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1559\n",
      "Epoch 586/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 0.1555\n",
      "Epoch 587/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1551\n",
      "Epoch 588/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1553\n",
      "Epoch 589/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1556\n",
      "Epoch 590/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1562\n",
      "Epoch 591/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1562\n",
      "Epoch 592/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1555\n",
      "Epoch 593/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1547\n",
      "Epoch 594/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 0.1542\n",
      "Epoch 595/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1539\n",
      "Epoch 596/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1538\n",
      "Epoch 597/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1536\n",
      "Epoch 598/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0031 - val_loss: 0.1524\n",
      "Epoch 599/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1514\n",
      "Epoch 600/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1499\n",
      "Epoch 601/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1492\n",
      "Epoch 602/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0030 - val_loss: 0.1489\n",
      "Epoch 603/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1486\n",
      "Epoch 604/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1486\n",
      "Epoch 605/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 0.1491\n",
      "Epoch 606/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1489\n",
      "Epoch 607/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1482\n",
      "Epoch 608/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1474\n",
      "Epoch 609/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0030 - val_loss: 0.1463\n",
      "Epoch 610/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 0.1454\n",
      "Epoch 611/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1443\n",
      "Epoch 612/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1430\n",
      "Epoch 613/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1421\n",
      "Epoch 614/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1417\n",
      "Epoch 615/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1415\n",
      "Epoch 616/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1416\n",
      "Epoch 617/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1417\n",
      "Epoch 618/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0030 - val_loss: 0.1415\n",
      "Epoch 619/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1409\n",
      "Epoch 620/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0030 - val_loss: 0.1398\n",
      "Epoch 621/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1391\n",
      "Epoch 622/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1383\n",
      "Epoch 623/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0030 - val_loss: 0.1382\n",
      "Epoch 624/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1383\n",
      "Epoch 625/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1383\n",
      "Epoch 626/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0030 - val_loss: 0.1374\n",
      "Epoch 627/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 0.1356\n",
      "Epoch 628/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1336\n",
      "Epoch 629/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1320\n",
      "Epoch 630/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1314\n",
      "Epoch 631/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0029 - val_loss: 0.1311\n",
      "Epoch 632/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1311\n",
      "Epoch 633/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1307\n",
      "Epoch 634/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1306\n",
      "Epoch 635/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.1310\n",
      "Epoch 636/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1306\n",
      "Epoch 637/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0029 - val_loss: 0.1293\n",
      "Epoch 638/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0029 - val_loss: 0.1283\n",
      "Epoch 639/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0029 - val_loss: 0.1269\n",
      "Epoch 640/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0027 - val_loss: 0.1247\n",
      "Epoch 641/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1215\n",
      "Epoch 642/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1230\n",
      "Epoch 643/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1242\n",
      "Epoch 644/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1230\n",
      "Epoch 645/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1275\n",
      "Epoch 646/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1301\n",
      "Epoch 647/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1303\n",
      "Epoch 648/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0029 - val_loss: 0.1293\n",
      "Epoch 649/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1277\n",
      "Epoch 650/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1267\n",
      "Epoch 651/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0029 - val_loss: 0.1262\n",
      "Epoch 652/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0030 - val_loss: 0.1262\n",
      "Epoch 653/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0030 - val_loss: 0.1265\n",
      "Epoch 654/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1260\n",
      "Epoch 655/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1249\n",
      "Epoch 656/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1238\n",
      "Epoch 657/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.1232\n",
      "Epoch 658/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1233\n",
      "Epoch 659/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1237\n",
      "Epoch 660/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 0.1241\n",
      "Epoch 661/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1249\n",
      "Epoch 662/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0029 - val_loss: 0.1266\n",
      "Epoch 663/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1275\n",
      "Epoch 664/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1266\n",
      "Epoch 665/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1247\n",
      "Epoch 666/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1222\n",
      "Epoch 667/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1208\n",
      "Epoch 668/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1212\n",
      "Epoch 669/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0028 - val_loss: 0.1226\n",
      "Epoch 670/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1241\n",
      "Epoch 671/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1254\n",
      "Epoch 672/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - val_loss: 0.1267\n",
      "Epoch 673/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1271\n",
      "Epoch 674/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1263\n",
      "Epoch 675/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1243\n",
      "Epoch 676/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0029 - val_loss: 0.1225\n",
      "Epoch 677/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1217\n",
      "Epoch 678/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1226\n",
      "Epoch 679/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1242\n",
      "Epoch 680/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1262\n",
      "Epoch 681/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1278\n",
      "Epoch 682/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1284\n",
      "Epoch 683/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1274\n",
      "Epoch 684/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1251\n",
      "Epoch 685/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0029 - val_loss: 0.1232\n",
      "Epoch 686/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0028 - val_loss: 0.1221\n",
      "Epoch 687/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0028 - val_loss: 0.1215\n",
      "Epoch 688/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0029 - val_loss: 0.1218\n",
      "Epoch 689/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0028 - val_loss: 0.1216\n",
      "Epoch 690/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1210\n",
      "Epoch 691/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1202\n",
      "Epoch 692/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1188\n",
      "Epoch 693/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0031 - val_loss: 0.1204\n",
      "Epoch 694/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1211\n",
      "Epoch 695/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1207\n",
      "Epoch 696/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 0.1196\n",
      "Epoch 697/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1189\n",
      "Epoch 698/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1179\n",
      "Epoch 699/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1169\n",
      "Epoch 700/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1155\n",
      "Epoch 701/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1146\n",
      "Epoch 702/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 0.1138\n",
      "Epoch 703/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1129\n",
      "Epoch 704/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1123\n",
      "Epoch 705/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1116\n",
      "Epoch 706/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1111\n",
      "Epoch 707/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0027 - val_loss: 0.1111\n",
      "Epoch 708/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1113\n",
      "Epoch 709/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0036 - val_loss: 0.1129\n",
      "Epoch 710/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1152\n",
      "Epoch 711/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1174\n",
      "Epoch 712/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0030 - val_loss: 0.1180\n",
      "Epoch 713/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0030 - val_loss: 0.1172\n",
      "Epoch 714/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1154\n",
      "Epoch 715/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1137\n",
      "Epoch 716/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0029 - val_loss: 0.1122\n",
      "Epoch 717/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0030 - val_loss: 0.1118\n",
      "Epoch 718/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1120\n",
      "Epoch 719/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0028 - val_loss: 0.1123\n",
      "Epoch 720/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1124\n",
      "Epoch 721/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1125\n",
      "Epoch 722/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0029 - val_loss: 0.1123\n",
      "Epoch 723/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1126\n",
      "Epoch 724/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1133\n",
      "Epoch 725/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1137\n",
      "Epoch 726/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1140\n",
      "Epoch 727/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1136\n",
      "Epoch 728/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1127\n",
      "Epoch 729/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0028 - val_loss: 0.1119\n",
      "Epoch 730/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1111\n",
      "Epoch 731/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1107\n",
      "Epoch 732/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0028 - val_loss: 0.1106\n",
      "Epoch 733/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0029 - val_loss: 0.1107\n",
      "Epoch 734/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1109\n",
      "Epoch 735/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1109\n",
      "Epoch 736/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0027 - val_loss: 0.1110\n",
      "Epoch 737/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1109\n",
      "Epoch 738/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0028 - val_loss: 0.1106\n",
      "Epoch 739/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0028 - val_loss: 0.1097\n",
      "Epoch 740/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.1088\n",
      "Epoch 741/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0027 - val_loss: 0.1079\n",
      "Epoch 742/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1072\n",
      "Epoch 743/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1069\n",
      "Epoch 744/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0028 - val_loss: 0.1070\n",
      "Epoch 745/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1075\n",
      "Epoch 746/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1084\n",
      "Epoch 747/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1091\n",
      "Epoch 748/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1091\n",
      "Epoch 749/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1087\n",
      "Epoch 750/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1084\n",
      "Epoch 751/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1080\n",
      "Epoch 752/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1074\n",
      "Epoch 753/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1069\n",
      "Epoch 754/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1066\n",
      "Epoch 755/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1064\n",
      "Epoch 756/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0027 - val_loss: 0.1064\n",
      "Epoch 757/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1065\n",
      "Epoch 758/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1057\n",
      "Epoch 759/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0028 - val_loss: 0.1043\n",
      "Epoch 760/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1031\n",
      "Epoch 761/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1023\n",
      "Epoch 762/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1020\n",
      "Epoch 763/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1018\n",
      "Epoch 764/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.1020\n",
      "Epoch 765/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0027 - val_loss: 0.1021\n",
      "Epoch 766/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1022\n",
      "Epoch 767/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0027 - val_loss: 0.1026\n",
      "Epoch 768/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1024\n",
      "Epoch 769/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1023\n",
      "Epoch 770/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1021\n",
      "Epoch 771/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0026 - val_loss: 0.1024\n",
      "Epoch 772/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1028\n",
      "Epoch 773/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1033\n",
      "Epoch 774/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1041\n",
      "Epoch 775/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1041\n",
      "Epoch 776/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1040\n",
      "Epoch 777/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1035\n",
      "Epoch 778/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1032\n",
      "Epoch 779/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1031\n",
      "Epoch 780/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.1029\n",
      "Epoch 781/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1032\n",
      "Epoch 782/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1037\n",
      "Epoch 783/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0026 - val_loss: 0.1041\n",
      "Epoch 784/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.1042\n",
      "Epoch 785/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1040\n",
      "Epoch 786/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0026 - val_loss: 0.1034\n",
      "Epoch 787/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1031\n",
      "Epoch 788/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1027\n",
      "Epoch 789/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.1021\n",
      "Epoch 790/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.1017\n",
      "Epoch 791/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1016\n",
      "Epoch 792/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.1017\n",
      "Epoch 793/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1015\n",
      "Epoch 794/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1017\n",
      "Epoch 795/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.1017\n",
      "Epoch 796/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1018\n",
      "Epoch 797/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1016\n",
      "Epoch 798/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1014\n",
      "Epoch 799/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1010\n",
      "Epoch 800/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1003\n",
      "Epoch 801/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0027 - val_loss: 0.1002\n",
      "Epoch 802/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1003\n",
      "Epoch 803/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1004\n",
      "Epoch 804/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1004\n",
      "Epoch 805/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1005\n",
      "Epoch 806/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.1005\n",
      "Epoch 807/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - val_loss: 0.1003\n",
      "Epoch 808/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.1000\n",
      "Epoch 809/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1001\n",
      "Epoch 810/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1002\n",
      "Epoch 811/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0025 - val_loss: 0.0999\n",
      "Epoch 812/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0025 - val_loss: 0.0998\n",
      "Epoch 813/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0995\n",
      "Epoch 814/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0992\n",
      "Epoch 815/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0994\n",
      "Epoch 816/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0999\n",
      "Epoch 817/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1007\n",
      "Epoch 818/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1011\n",
      "Epoch 819/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1010\n",
      "Epoch 820/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1005\n",
      "Epoch 821/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0995\n",
      "Epoch 822/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0026 - val_loss: 0.0986\n",
      "Epoch 823/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0984\n",
      "Epoch 824/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0988\n",
      "Epoch 825/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0999\n",
      "Epoch 826/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.1006\n",
      "Epoch 827/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1008\n",
      "Epoch 828/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.1003\n",
      "Epoch 829/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0998\n",
      "Epoch 830/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0994\n",
      "Epoch 831/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0991\n",
      "Epoch 832/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0991\n",
      "Epoch 833/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.0992\n",
      "Epoch 834/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0998\n",
      "Epoch 835/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.1000\n",
      "Epoch 836/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0998\n",
      "Epoch 837/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0025 - val_loss: 0.0993\n",
      "Epoch 838/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0985\n",
      "Epoch 839/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0983\n",
      "Epoch 840/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0985\n",
      "Epoch 841/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0987\n",
      "Epoch 842/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0991\n",
      "Epoch 843/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0992\n",
      "Epoch 844/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0990\n",
      "Epoch 845/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0988\n",
      "Epoch 846/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0987\n",
      "Epoch 847/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0026 - val_loss: 0.0987\n",
      "Epoch 848/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0986\n",
      "Epoch 849/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0984\n",
      "Epoch 850/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0984\n",
      "Epoch 851/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0985\n",
      "Epoch 852/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0985\n",
      "Epoch 853/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0986\n",
      "Epoch 854/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0989\n",
      "Epoch 855/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0991\n",
      "Epoch 856/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0025 - val_loss: 0.0992\n",
      "Epoch 857/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0988\n",
      "Epoch 858/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0986\n",
      "Epoch 859/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0984\n",
      "Epoch 860/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0984\n",
      "Epoch 861/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - val_loss: 0.0986\n",
      "Epoch 862/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0989\n",
      "Epoch 863/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0990\n",
      "Epoch 864/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0989\n",
      "Epoch 865/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0984\n",
      "Epoch 866/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0982\n",
      "Epoch 867/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0983\n",
      "Epoch 868/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0986\n",
      "Epoch 869/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0989\n",
      "Epoch 870/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0992\n",
      "Epoch 871/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0994\n",
      "Epoch 872/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0990\n",
      "Epoch 873/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0984\n",
      "Epoch 874/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0978\n",
      "Epoch 875/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0974\n",
      "Epoch 876/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0973\n",
      "Epoch 877/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0973\n",
      "Epoch 878/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0977\n",
      "Epoch 879/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0982\n",
      "Epoch 880/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0987\n",
      "Epoch 881/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0989\n",
      "Epoch 882/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0989\n",
      "Epoch 883/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0986\n",
      "Epoch 884/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0026 - val_loss: 0.0982\n",
      "Epoch 885/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0976\n",
      "Epoch 886/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0969\n",
      "Epoch 887/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0967\n",
      "Epoch 888/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0969\n",
      "Epoch 889/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0972\n",
      "Epoch 890/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0975\n",
      "Epoch 891/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0977\n",
      "Epoch 892/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0976\n",
      "Epoch 893/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0973\n",
      "Epoch 894/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0969\n",
      "Epoch 895/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0967\n",
      "Epoch 896/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0967\n",
      "Epoch 897/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0025 - val_loss: 0.0970\n",
      "Epoch 898/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0974\n",
      "Epoch 899/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0974\n",
      "Epoch 900/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0970\n",
      "Epoch 901/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0963\n",
      "Epoch 902/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 903/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 904/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 905/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0958\n",
      "Epoch 906/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 907/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0961\n",
      "Epoch 908/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0960\n",
      "Epoch 909/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0961\n",
      "Epoch 910/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0961\n",
      "Epoch 911/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0964\n",
      "Epoch 912/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0965\n",
      "Epoch 913/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0966\n",
      "Epoch 914/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0964\n",
      "Epoch 915/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0963\n",
      "Epoch 916/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0967\n",
      "Epoch 917/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0972\n",
      "Epoch 918/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0973\n",
      "Epoch 919/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0968\n",
      "Epoch 920/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0963\n",
      "Epoch 921/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0962\n",
      "Epoch 922/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0966\n",
      "Epoch 923/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0971\n",
      "Epoch 924/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0026 - val_loss: 0.0975\n",
      "Epoch 925/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0973\n",
      "Epoch 926/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0025 - val_loss: 0.0967\n",
      "Epoch 927/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 928/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 929/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0953\n",
      "Epoch 930/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0957\n",
      "Epoch 931/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0963\n",
      "Epoch 932/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0968\n",
      "Epoch 933/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0026 - val_loss: 0.0967\n",
      "Epoch 934/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0963\n",
      "Epoch 935/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0960\n",
      "Epoch 936/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 937/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 938/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0960\n",
      "Epoch 939/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0958\n",
      "Epoch 940/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0956\n",
      "Epoch 941/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0956\n",
      "Epoch 942/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0958\n",
      "Epoch 943/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0960\n",
      "Epoch 944/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0961\n",
      "Epoch 945/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 946/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0956\n",
      "Epoch 947/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 948/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0951\n",
      "Epoch 949/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 950/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 951/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0954\n",
      "Epoch 952/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0956\n",
      "Epoch 953/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0957\n",
      "Epoch 954/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 955/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0958\n",
      "Epoch 956/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0955\n",
      "Epoch 957/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 958/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 959/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 960/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0954\n",
      "Epoch 961/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 962/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0951\n",
      "Epoch 963/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0947\n",
      "Epoch 964/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 965/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 966/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 967/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0948\n",
      "Epoch 968/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0947\n",
      "Epoch 969/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0944\n",
      "Epoch 970/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0942\n",
      "Epoch 971/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 972/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0939\n",
      "Epoch 973/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 974/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 975/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 976/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0949\n",
      "Epoch 977/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 978/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0957\n",
      "Epoch 979/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0960\n",
      "Epoch 980/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0958\n",
      "Epoch 981/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0954\n",
      "Epoch 982/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 983/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0954\n",
      "Epoch 984/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 985/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0963\n",
      "Epoch 986/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0965\n",
      "Epoch 987/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0964\n",
      "Epoch 988/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0959\n",
      "Epoch 989/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 990/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0948\n",
      "Epoch 991/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0025 - val_loss: 0.0947\n",
      "Epoch 992/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0948\n",
      "Epoch 993/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0948\n",
      "Epoch 994/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 995/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0942\n",
      "Epoch 996/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0938\n",
      "Epoch 997/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 998/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0947\n",
      "Epoch 999/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0955\n",
      "Epoch 1000/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0957\n",
      "Epoch 1001/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 1002/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 1003/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1004/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0937\n",
      "Epoch 1005/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1006/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 1007/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0026 - val_loss: 0.0946\n",
      "Epoch 1008/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 1009/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1010/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1011/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1012/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0944\n",
      "Epoch 1013/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0951\n",
      "Epoch 1014/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0025 - val_loss: 0.0955\n",
      "Epoch 1015/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0953\n",
      "Epoch 1016/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0948\n",
      "Epoch 1017/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0942\n",
      "Epoch 1018/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1019/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1020/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0944\n",
      "Epoch 1021/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0947\n",
      "Epoch 1022/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0951\n",
      "Epoch 1023/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0954\n",
      "Epoch 1024/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0952\n",
      "Epoch 1025/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 1026/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1027/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1028/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1029/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0943\n",
      "Epoch 1030/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0944\n",
      "Epoch 1031/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0948\n",
      "Epoch 1032/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0950\n",
      "Epoch 1033/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0950\n",
      "Epoch 1034/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 1035/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1036/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0936\n",
      "Epoch 1037/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0934\n",
      "Epoch 1038/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0932\n",
      "Epoch 1039/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0931\n",
      "Epoch 1040/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0931\n",
      "Epoch 1041/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0933\n",
      "Epoch 1042/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0936\n",
      "Epoch 1043/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0939\n",
      "Epoch 1044/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0939\n",
      "Epoch 1045/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1046/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0939\n",
      "Epoch 1047/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0935\n",
      "Epoch 1048/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0934\n",
      "Epoch 1049/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0934\n",
      "Epoch 1050/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0932\n",
      "Epoch 1051/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0931\n",
      "Epoch 1052/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0932\n",
      "Epoch 1053/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0936\n",
      "Epoch 1054/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0943\n",
      "Epoch 1055/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 1056/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0944\n",
      "Epoch 1057/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0938\n",
      "Epoch 1058/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0931\n",
      "Epoch 1059/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0928\n",
      "Epoch 1060/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0933\n",
      "Epoch 1061/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1062/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 1063/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 1064/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0946\n",
      "Epoch 1065/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0943\n",
      "Epoch 1066/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0943\n",
      "Epoch 1067/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0025 - val_loss: 0.0943\n",
      "Epoch 1068/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0940\n",
      "Epoch 1069/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0937\n",
      "Epoch 1070/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0936\n",
      "Epoch 1071/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0936\n",
      "Epoch 1072/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0937\n",
      "Epoch 1073/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0941\n",
      "Epoch 1074/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0025 - val_loss: 0.0944\n",
      "Epoch 1075/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0945\n",
      "Epoch 1076/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0025 - val_loss: 0.0942\n",
      "Epoch 1077/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0025 - val_loss: 0.0937\n",
      "Epoch 1078/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0025 - val_loss: 0.0933\n",
      "Epoch 1079/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0025 - val_loss: 0.0932\n",
      "Epoch 1080/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0024 - val_loss: 0.0938\n",
      "Epoch 1081/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0010 - val_loss: 0.0950\n",
      "Epoch 1082/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0965\n",
      "Epoch 1083/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0013 - val_loss: 0.0977\n",
      "Epoch 1084/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0012 - val_loss: 0.0984\n",
      "Epoch 1085/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0988\n",
      "Epoch 1086/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0012 - val_loss: 0.0995\n",
      "Epoch 1087/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.1013\n",
      "Epoch 1088/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0012 - val_loss: 0.1039\n",
      "Epoch 1089/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0012 - val_loss: 0.1059\n",
      "Epoch 1090/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0012 - val_loss: 0.1057\n",
      "Epoch 1091/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0011 - val_loss: 0.1044\n",
      "Epoch 1092/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 0.1027\n",
      "Epoch 1093/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0010 - val_loss: 0.1019\n",
      "Epoch 1094/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0011 - val_loss: 0.1020\n",
      "Epoch 1095/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.1022\n",
      "Epoch 1096/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.1016\n",
      "Epoch 1097/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 0.1004\n",
      "Epoch 1098/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0011 - val_loss: 0.0986\n",
      "Epoch 1099/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0972\n",
      "Epoch 1100/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.0971\n",
      "Epoch 1101/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0010 - val_loss: 0.0977\n",
      "Epoch 1102/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0011 - val_loss: 0.0979\n",
      "Epoch 1103/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0010 - val_loss: 0.0979\n",
      "Epoch 1104/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.9869e-04 - val_loss: 0.0974\n",
      "Epoch 1105/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.9810e-04 - val_loss: 0.0967\n",
      "Epoch 1106/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.9714e-04 - val_loss: 0.0966\n",
      "Epoch 1107/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8500e-04 - val_loss: 0.0969\n",
      "Epoch 1108/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0010 - val_loss: 0.0975\n",
      "Epoch 1109/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.9112e-04 - val_loss: 0.0976\n",
      "Epoch 1110/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.8471e-04 - val_loss: 0.0974\n",
      "Epoch 1111/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.9751e-04 - val_loss: 0.0969\n",
      "Epoch 1112/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.7059e-04 - val_loss: 0.0963\n",
      "Epoch 1113/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0010 - val_loss: 0.0958\n",
      "Epoch 1114/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.8925e-04 - val_loss: 0.0957\n",
      "Epoch 1115/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.7884e-04 - val_loss: 0.0961\n",
      "Epoch 1116/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.6744e-04 - val_loss: 0.0965\n",
      "Epoch 1117/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.7894e-04 - val_loss: 0.0966\n",
      "Epoch 1118/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.7919e-04 - val_loss: 0.0963\n",
      "Epoch 1119/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.8306e-04 - val_loss: 0.0958\n",
      "Epoch 1120/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8369e-04 - val_loss: 0.0956\n",
      "Epoch 1121/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.0958\n",
      "Epoch 1122/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7508e-04 - val_loss: 0.0956\n",
      "Epoch 1123/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0010 - val_loss: 0.0951\n",
      "Epoch 1124/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0010 - val_loss: 0.0942\n",
      "Epoch 1125/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.9740e-04 - val_loss: 0.0937\n",
      "Epoch 1126/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.8321e-04 - val_loss: 0.0939\n",
      "Epoch 1127/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.6271e-04 - val_loss: 0.0946\n",
      "Epoch 1128/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0010 - val_loss: 0.0953\n",
      "Epoch 1129/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 0.0954\n",
      "Epoch 1130/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.6211e-04 - val_loss: 0.0950\n",
      "Epoch 1131/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.7502e-04 - val_loss: 0.0942\n",
      "Epoch 1132/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.7307e-04 - val_loss: 0.0934\n",
      "Epoch 1133/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7614e-04 - val_loss: 0.0928\n",
      "Epoch 1134/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.8792e-04 - val_loss: 0.0930\n",
      "Epoch 1135/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6917e-04 - val_loss: 0.0939\n",
      "Epoch 1136/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4800e-04 - val_loss: 0.0947\n",
      "Epoch 1137/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0010 - val_loss: 0.0948\n",
      "Epoch 1138/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6988e-04 - val_loss: 0.0945\n",
      "Epoch 1139/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5449e-04 - val_loss: 0.0942\n",
      "Epoch 1140/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.7386e-04 - val_loss: 0.0943\n",
      "Epoch 1141/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4581e-04 - val_loss: 0.0946\n",
      "Epoch 1142/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6625e-04 - val_loss: 0.0950\n",
      "Epoch 1143/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.9971e-04 - val_loss: 0.0948\n",
      "Epoch 1144/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.8031e-04 - val_loss: 0.0941\n",
      "Epoch 1145/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6715e-04 - val_loss: 0.0937\n",
      "Epoch 1146/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6928e-04 - val_loss: 0.0939\n",
      "Epoch 1147/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6794e-04 - val_loss: 0.0944\n",
      "Epoch 1148/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.9322e-04 - val_loss: 0.0944\n",
      "Epoch 1149/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.9174e-04 - val_loss: 0.0940\n",
      "Epoch 1150/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5069e-04 - val_loss: 0.0935\n",
      "Epoch 1151/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.7915e-04 - val_loss: 0.0933\n",
      "Epoch 1152/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.6707e-04 - val_loss: 0.0935\n",
      "Epoch 1153/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 9.7812e-04 - val_loss: 0.0938\n",
      "Epoch 1154/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 9.5748e-04 - val_loss: 0.0940\n",
      "Epoch 1155/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.8276e-04 - val_loss: 0.0938\n",
      "Epoch 1156/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 9.4484e-04 - val_loss: 0.0936\n",
      "Epoch 1157/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6807e-04 - val_loss: 0.0932\n",
      "Epoch 1158/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5253e-04 - val_loss: 0.0934\n",
      "Epoch 1159/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5582e-04 - val_loss: 0.0937\n",
      "Epoch 1160/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.7338e-04 - val_loss: 0.0942\n",
      "Epoch 1161/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.5160e-04 - val_loss: 0.0943\n",
      "Epoch 1162/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6115e-04 - val_loss: 0.0937\n",
      "Epoch 1163/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3042e-04 - val_loss: 0.0934\n",
      "Epoch 1164/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.7115e-04 - val_loss: 0.0936\n",
      "Epoch 1165/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.4502e-04 - val_loss: 0.0938\n",
      "Epoch 1166/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4511e-04 - val_loss: 0.0939\n",
      "Epoch 1167/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6823e-04 - val_loss: 0.0940\n",
      "Epoch 1168/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.7059e-04 - val_loss: 0.0938\n",
      "Epoch 1169/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6808e-04 - val_loss: 0.0935\n",
      "Epoch 1170/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5951e-04 - val_loss: 0.0934\n",
      "Epoch 1171/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.5878e-04 - val_loss: 0.0936\n",
      "Epoch 1172/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6605e-04 - val_loss: 0.0938\n",
      "Epoch 1173/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.6257e-04 - val_loss: 0.0940\n",
      "Epoch 1174/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4458e-04 - val_loss: 0.0940\n",
      "Epoch 1175/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5528e-04 - val_loss: 0.0943\n",
      "Epoch 1176/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2215e-04 - val_loss: 0.0944\n",
      "Epoch 1177/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6257e-04 - val_loss: 0.0946\n",
      "Epoch 1178/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3506e-04 - val_loss: 0.0943\n",
      "Epoch 1179/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5466e-04 - val_loss: 0.0941\n",
      "Epoch 1180/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4814e-04 - val_loss: 0.0941\n",
      "Epoch 1181/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2706e-04 - val_loss: 0.0941\n",
      "Epoch 1182/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.6564e-04 - val_loss: 0.0939\n",
      "Epoch 1183/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6566e-04 - val_loss: 0.0937\n",
      "Epoch 1184/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3593e-04 - val_loss: 0.0937\n",
      "Epoch 1185/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5304e-04 - val_loss: 0.0938\n",
      "Epoch 1186/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.6426e-04 - val_loss: 0.0939\n",
      "Epoch 1187/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3112e-04 - val_loss: 0.0939\n",
      "Epoch 1188/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5956e-04 - val_loss: 0.0940\n",
      "Epoch 1189/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.9871e-04 - val_loss: 0.0937\n",
      "Epoch 1190/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5256e-04 - val_loss: 0.0938\n",
      "Epoch 1191/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7087e-04 - val_loss: 0.0939\n",
      "Epoch 1192/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4142e-04 - val_loss: 0.0941\n",
      "Epoch 1193/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5012e-04 - val_loss: 0.0943\n",
      "Epoch 1194/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9082e-04 - val_loss: 0.0943\n",
      "Epoch 1195/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7461e-04 - val_loss: 0.0941\n",
      "Epoch 1196/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3971e-04 - val_loss: 0.0938\n",
      "Epoch 1197/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7041e-04 - val_loss: 0.0939\n",
      "Epoch 1198/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.5049e-04 - val_loss: 0.0940\n",
      "Epoch 1199/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7693e-04 - val_loss: 0.0945\n",
      "Epoch 1200/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4817e-04 - val_loss: 0.0950\n",
      "Epoch 1201/3000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 9.5123e-04 - val_loss: 0.0952\n",
      "Epoch 1202/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6971e-04 - val_loss: 0.0951\n",
      "Epoch 1203/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.6846e-04 - val_loss: 0.0951\n",
      "Epoch 1204/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7857e-04 - val_loss: 0.0949\n",
      "Epoch 1205/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6621e-04 - val_loss: 0.0946\n",
      "Epoch 1206/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4858e-04 - val_loss: 0.0943\n",
      "Epoch 1207/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3697e-04 - val_loss: 0.0943\n",
      "Epoch 1208/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6322e-04 - val_loss: 0.0945\n",
      "Epoch 1209/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4988e-04 - val_loss: 0.0950\n",
      "Epoch 1210/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5302e-04 - val_loss: 0.0952\n",
      "Epoch 1211/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4247e-04 - val_loss: 0.0951\n",
      "Epoch 1212/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4555e-04 - val_loss: 0.0945\n",
      "Epoch 1213/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6516e-04 - val_loss: 0.0940\n",
      "Epoch 1214/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4853e-04 - val_loss: 0.0934\n",
      "Epoch 1215/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3363e-04 - val_loss: 0.0933\n",
      "Epoch 1216/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4160e-04 - val_loss: 0.0934\n",
      "Epoch 1217/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4171e-04 - val_loss: 0.0937\n",
      "Epoch 1218/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3477e-04 - val_loss: 0.0941\n",
      "Epoch 1219/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4393e-04 - val_loss: 0.0945\n",
      "Epoch 1220/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6508e-04 - val_loss: 0.0944\n",
      "Epoch 1221/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.5366e-04 - val_loss: 0.0943\n",
      "Epoch 1222/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6692e-04 - val_loss: 0.0941\n",
      "Epoch 1223/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5221e-04 - val_loss: 0.0936\n",
      "Epoch 1224/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6242e-04 - val_loss: 0.0933\n",
      "Epoch 1225/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6229e-04 - val_loss: 0.0933\n",
      "Epoch 1226/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5213e-04 - val_loss: 0.0937\n",
      "Epoch 1227/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6462e-04 - val_loss: 0.0945\n",
      "Epoch 1228/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5249e-04 - val_loss: 0.0948\n",
      "Epoch 1229/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7763e-04 - val_loss: 0.0943\n",
      "Epoch 1230/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5923e-04 - val_loss: 0.0935\n",
      "Epoch 1231/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4815e-04 - val_loss: 0.0929\n",
      "Epoch 1232/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7651e-04 - val_loss: 0.0930\n",
      "Epoch 1233/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.7029e-04 - val_loss: 0.0935\n",
      "Epoch 1234/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6330e-04 - val_loss: 0.0938\n",
      "Epoch 1235/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2194e-04 - val_loss: 0.0941\n",
      "Epoch 1236/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.4017e-04 - val_loss: 0.0941\n",
      "Epoch 1237/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4261e-04 - val_loss: 0.0939\n",
      "Epoch 1238/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6378e-04 - val_loss: 0.0937\n",
      "Epoch 1239/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6320e-04 - val_loss: 0.0934\n",
      "Epoch 1240/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4923e-04 - val_loss: 0.0932\n",
      "Epoch 1241/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.7529e-04 - val_loss: 0.0930\n",
      "Epoch 1242/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4448e-04 - val_loss: 0.0927\n",
      "Epoch 1243/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5226e-04 - val_loss: 0.0928\n",
      "Epoch 1244/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3845e-04 - val_loss: 0.0932\n",
      "Epoch 1245/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6248e-04 - val_loss: 0.0937\n",
      "Epoch 1246/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3252e-04 - val_loss: 0.0940\n",
      "Epoch 1247/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4726e-04 - val_loss: 0.0940\n",
      "Epoch 1248/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4742e-04 - val_loss: 0.0936\n",
      "Epoch 1249/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5285e-04 - val_loss: 0.0931\n",
      "Epoch 1250/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.2192e-04 - val_loss: 0.0927\n",
      "Epoch 1251/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5537e-04 - val_loss: 0.0928\n",
      "Epoch 1252/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3715e-04 - val_loss: 0.0930\n",
      "Epoch 1253/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1554e-04 - val_loss: 0.0933\n",
      "Epoch 1254/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2754e-04 - val_loss: 0.0935\n",
      "Epoch 1255/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7027e-04 - val_loss: 0.0934\n",
      "Epoch 1256/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2957e-04 - val_loss: 0.0930\n",
      "Epoch 1257/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3077e-04 - val_loss: 0.0927\n",
      "Epoch 1258/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4718e-04 - val_loss: 0.0927\n",
      "Epoch 1259/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.3571e-04 - val_loss: 0.0929\n",
      "Epoch 1260/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1679e-04 - val_loss: 0.0930\n",
      "Epoch 1261/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2321e-04 - val_loss: 0.0929\n",
      "Epoch 1262/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3444e-04 - val_loss: 0.0927\n",
      "Epoch 1263/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6399e-04 - val_loss: 0.0928\n",
      "Epoch 1264/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.2492e-04 - val_loss: 0.0930\n",
      "Epoch 1265/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 9.5227e-04 - val_loss: 0.0932\n",
      "Epoch 1266/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6112e-04 - val_loss: 0.0933\n",
      "Epoch 1267/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3489e-04 - val_loss: 0.0932\n",
      "Epoch 1268/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3942e-04 - val_loss: 0.0928\n",
      "Epoch 1269/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4664e-04 - val_loss: 0.0927\n",
      "Epoch 1270/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3241e-04 - val_loss: 0.0929\n",
      "Epoch 1271/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1482e-04 - val_loss: 0.0933\n",
      "Epoch 1272/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3773e-04 - val_loss: 0.0936\n",
      "Epoch 1273/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6512e-04 - val_loss: 0.0932\n",
      "Epoch 1274/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3233e-04 - val_loss: 0.0930\n",
      "Epoch 1275/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4394e-04 - val_loss: 0.0928\n",
      "Epoch 1276/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1912e-04 - val_loss: 0.0929\n",
      "Epoch 1277/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2509e-04 - val_loss: 0.0932\n",
      "Epoch 1278/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3852e-04 - val_loss: 0.0933\n",
      "Epoch 1279/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3180e-04 - val_loss: 0.0935\n",
      "Epoch 1280/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3359e-04 - val_loss: 0.0936\n",
      "Epoch 1281/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3883e-04 - val_loss: 0.0934\n",
      "Epoch 1282/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5264e-04 - val_loss: 0.0935\n",
      "Epoch 1283/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3365e-04 - val_loss: 0.0937\n",
      "Epoch 1284/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1251e-04 - val_loss: 0.0938\n",
      "Epoch 1285/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3964e-04 - val_loss: 0.0936\n",
      "Epoch 1286/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2860e-04 - val_loss: 0.0931\n",
      "Epoch 1287/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4741e-04 - val_loss: 0.0927\n",
      "Epoch 1288/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4143e-04 - val_loss: 0.0927\n",
      "Epoch 1289/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5528e-04 - val_loss: 0.0930\n",
      "Epoch 1290/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1964e-04 - val_loss: 0.0933\n",
      "Epoch 1291/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2549e-04 - val_loss: 0.0932\n",
      "Epoch 1292/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3504e-04 - val_loss: 0.0927\n",
      "Epoch 1293/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4375e-04 - val_loss: 0.0925\n",
      "Epoch 1294/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3073e-04 - val_loss: 0.0925\n",
      "Epoch 1295/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.8152e-04 - val_loss: 0.0929\n",
      "Epoch 1296/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2911e-04 - val_loss: 0.0934\n",
      "Epoch 1297/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.5632e-04 - val_loss: 0.0936\n",
      "Epoch 1298/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.7137e-04 - val_loss: 0.0933\n",
      "Epoch 1299/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4647e-04 - val_loss: 0.0931\n",
      "Epoch 1300/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.9037e-04 - val_loss: 0.0933\n",
      "Epoch 1301/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.6321e-04 - val_loss: 0.0933\n",
      "Epoch 1302/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3242e-04 - val_loss: 0.0930\n",
      "Epoch 1303/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7750e-04 - val_loss: 0.0926\n",
      "Epoch 1304/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5252e-04 - val_loss: 0.0923\n",
      "Epoch 1305/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3558e-04 - val_loss: 0.0925\n",
      "Epoch 1306/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6221e-04 - val_loss: 0.0930\n",
      "Epoch 1307/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4249e-04 - val_loss: 0.0935\n",
      "Epoch 1308/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.6764e-04 - val_loss: 0.0933\n",
      "Epoch 1309/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6645e-04 - val_loss: 0.0931\n",
      "Epoch 1310/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5284e-04 - val_loss: 0.0932\n",
      "Epoch 1311/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4786e-04 - val_loss: 0.0931\n",
      "Epoch 1312/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.6605e-04 - val_loss: 0.0931\n",
      "Epoch 1313/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.8372e-04 - val_loss: 0.0931\n",
      "Epoch 1314/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5622e-04 - val_loss: 0.0926\n",
      "Epoch 1315/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4245e-04 - val_loss: 0.0924\n",
      "Epoch 1316/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.3610e-04 - val_loss: 0.0924\n",
      "Epoch 1317/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5384e-04 - val_loss: 0.0926\n",
      "Epoch 1318/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.7199e-04 - val_loss: 0.0929\n",
      "Epoch 1319/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4923e-04 - val_loss: 0.0932\n",
      "Epoch 1320/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2819e-04 - val_loss: 0.0934\n",
      "Epoch 1321/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6455e-04 - val_loss: 0.0931\n",
      "Epoch 1322/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2556e-04 - val_loss: 0.0928\n",
      "Epoch 1323/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4131e-04 - val_loss: 0.0925\n",
      "Epoch 1324/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3963e-04 - val_loss: 0.0924\n",
      "Epoch 1325/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3800e-04 - val_loss: 0.0924\n",
      "Epoch 1326/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3792e-04 - val_loss: 0.0928\n",
      "Epoch 1327/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5357e-04 - val_loss: 0.0932\n",
      "Epoch 1328/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2664e-04 - val_loss: 0.0932\n",
      "Epoch 1329/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4967e-04 - val_loss: 0.0929\n",
      "Epoch 1330/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5296e-04 - val_loss: 0.0927\n",
      "Epoch 1331/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5583e-04 - val_loss: 0.0928\n",
      "Epoch 1332/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.5481e-04 - val_loss: 0.0933\n",
      "Epoch 1333/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5665e-04 - val_loss: 0.0939\n",
      "Epoch 1334/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4725e-04 - val_loss: 0.0943\n",
      "Epoch 1335/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6974e-04 - val_loss: 0.0939\n",
      "Epoch 1336/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2787e-04 - val_loss: 0.0934\n",
      "Epoch 1337/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4413e-04 - val_loss: 0.0930\n",
      "Epoch 1338/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4772e-04 - val_loss: 0.0929\n",
      "Epoch 1339/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1928e-04 - val_loss: 0.0931\n",
      "Epoch 1340/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6215e-04 - val_loss: 0.0933\n",
      "Epoch 1341/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6044e-04 - val_loss: 0.0933\n",
      "Epoch 1342/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3595e-04 - val_loss: 0.0931\n",
      "Epoch 1343/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3363e-04 - val_loss: 0.0928\n",
      "Epoch 1344/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2802e-04 - val_loss: 0.0926\n",
      "Epoch 1345/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2434e-04 - val_loss: 0.0928\n",
      "Epoch 1346/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.0910e-04 - val_loss: 0.0928\n",
      "Epoch 1347/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.3509e-04 - val_loss: 0.0927\n",
      "Epoch 1348/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2230e-04 - val_loss: 0.0925\n",
      "Epoch 1349/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1423e-04 - val_loss: 0.0926\n",
      "Epoch 1350/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2398e-04 - val_loss: 0.0925\n",
      "Epoch 1351/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4199e-04 - val_loss: 0.0926\n",
      "Epoch 1352/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2943e-04 - val_loss: 0.0926\n",
      "Epoch 1353/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2646e-04 - val_loss: 0.0927\n",
      "Epoch 1354/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.3315e-04 - val_loss: 0.0930\n",
      "Epoch 1355/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3116e-04 - val_loss: 0.0930\n",
      "Epoch 1356/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3436e-04 - val_loss: 0.0931\n",
      "Epoch 1357/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3698e-04 - val_loss: 0.0931\n",
      "Epoch 1358/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4736e-04 - val_loss: 0.0932\n",
      "Epoch 1359/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5793e-04 - val_loss: 0.0932\n",
      "Epoch 1360/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3995e-04 - val_loss: 0.0928\n",
      "Epoch 1361/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2531e-04 - val_loss: 0.0925\n",
      "Epoch 1362/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.4943e-04 - val_loss: 0.0925\n",
      "Epoch 1363/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2632e-04 - val_loss: 0.0925\n",
      "Epoch 1364/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0855e-04 - val_loss: 0.0930\n",
      "Epoch 1365/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4337e-04 - val_loss: 0.0935\n",
      "Epoch 1366/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4011e-04 - val_loss: 0.0938\n",
      "Epoch 1367/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0639e-04 - val_loss: 0.0938\n",
      "Epoch 1368/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1846e-04 - val_loss: 0.0935\n",
      "Epoch 1369/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.5874e-04 - val_loss: 0.0933\n",
      "Epoch 1370/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2823e-04 - val_loss: 0.0930\n",
      "Epoch 1371/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4235e-04 - val_loss: 0.0926\n",
      "Epoch 1372/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5235e-04 - val_loss: 0.0922\n",
      "Epoch 1373/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2270e-04 - val_loss: 0.0925\n",
      "Epoch 1374/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3365e-04 - val_loss: 0.0930\n",
      "Epoch 1375/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2073e-04 - val_loss: 0.0936\n",
      "Epoch 1376/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4479e-04 - val_loss: 0.0936\n",
      "Epoch 1377/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4775e-04 - val_loss: 0.0931\n",
      "Epoch 1378/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1280e-04 - val_loss: 0.0924\n",
      "Epoch 1379/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4417e-04 - val_loss: 0.0922\n",
      "Epoch 1380/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3829e-04 - val_loss: 0.0926\n",
      "Epoch 1381/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1668e-04 - val_loss: 0.0933\n",
      "Epoch 1382/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3777e-04 - val_loss: 0.0936\n",
      "Epoch 1383/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.4929e-04 - val_loss: 0.0934\n",
      "Epoch 1384/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4849e-04 - val_loss: 0.0934\n",
      "Epoch 1385/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.7257e-04 - val_loss: 0.0938\n",
      "Epoch 1386/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2767e-04 - val_loss: 0.0937\n",
      "Epoch 1387/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4028e-04 - val_loss: 0.0934\n",
      "Epoch 1388/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2496e-04 - val_loss: 0.0929\n",
      "Epoch 1389/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.5965e-04 - val_loss: 0.0924\n",
      "Epoch 1390/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5189e-04 - val_loss: 0.0923\n",
      "Epoch 1391/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5930e-04 - val_loss: 0.0926\n",
      "Epoch 1392/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2423e-04 - val_loss: 0.0932\n",
      "Epoch 1393/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1804e-04 - val_loss: 0.0935\n",
      "Epoch 1394/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3062e-04 - val_loss: 0.0933\n",
      "Epoch 1395/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1459e-04 - val_loss: 0.0930\n",
      "Epoch 1396/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4081e-04 - val_loss: 0.0927\n",
      "Epoch 1397/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2964e-04 - val_loss: 0.0926\n",
      "Epoch 1398/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3916e-04 - val_loss: 0.0925\n",
      "Epoch 1399/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1941e-04 - val_loss: 0.0925\n",
      "Epoch 1400/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.3923e-04 - val_loss: 0.0926\n",
      "Epoch 1401/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1363e-04 - val_loss: 0.0930\n",
      "Epoch 1402/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1482e-04 - val_loss: 0.0930\n",
      "Epoch 1403/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3387e-04 - val_loss: 0.0927\n",
      "Epoch 1404/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2843e-04 - val_loss: 0.0926\n",
      "Epoch 1405/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3247e-04 - val_loss: 0.0926\n",
      "Epoch 1406/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0364e-04 - val_loss: 0.0928\n",
      "Epoch 1407/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.3040e-04 - val_loss: 0.0931\n",
      "Epoch 1408/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3430e-04 - val_loss: 0.0931\n",
      "Epoch 1409/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2312e-04 - val_loss: 0.0929\n",
      "Epoch 1410/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0236e-04 - val_loss: 0.0928\n",
      "Epoch 1411/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.5882e-04 - val_loss: 0.0930\n",
      "Epoch 1412/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.5919e-04 - val_loss: 0.0932\n",
      "Epoch 1413/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.2123e-04 - val_loss: 0.0933\n",
      "Epoch 1414/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6040e-04 - val_loss: 0.0929\n",
      "Epoch 1415/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3429e-04 - val_loss: 0.0929\n",
      "Epoch 1416/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3122e-04 - val_loss: 0.0931\n",
      "Epoch 1417/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3662e-04 - val_loss: 0.0931\n",
      "Epoch 1418/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5746e-04 - val_loss: 0.0929\n",
      "Epoch 1419/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1932e-04 - val_loss: 0.0927\n",
      "Epoch 1420/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5902e-04 - val_loss: 0.0926\n",
      "Epoch 1421/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2846e-04 - val_loss: 0.0928\n",
      "Epoch 1422/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3719e-04 - val_loss: 0.0928\n",
      "Epoch 1423/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2748e-04 - val_loss: 0.0928\n",
      "Epoch 1424/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3355e-04 - val_loss: 0.0928\n",
      "Epoch 1425/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2864e-04 - val_loss: 0.0927\n",
      "Epoch 1426/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.1891e-04 - val_loss: 0.0929\n",
      "Epoch 1427/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.3392e-04 - val_loss: 0.0927\n",
      "Epoch 1428/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.3891e-04 - val_loss: 0.0925\n",
      "Epoch 1429/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1362e-04 - val_loss: 0.0925\n",
      "Epoch 1430/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5224e-04 - val_loss: 0.0929\n",
      "Epoch 1431/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1344e-04 - val_loss: 0.0932\n",
      "Epoch 1432/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9696e-04 - val_loss: 0.0933\n",
      "Epoch 1433/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3921e-04 - val_loss: 0.0931\n",
      "Epoch 1434/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2074e-04 - val_loss: 0.0929\n",
      "Epoch 1435/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2767e-04 - val_loss: 0.0926\n",
      "Epoch 1436/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3912e-04 - val_loss: 0.0927\n",
      "Epoch 1437/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3560e-04 - val_loss: 0.0928\n",
      "Epoch 1438/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3258e-04 - val_loss: 0.0925\n",
      "Epoch 1439/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2165e-04 - val_loss: 0.0920\n",
      "Epoch 1440/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3649e-04 - val_loss: 0.0917\n",
      "Epoch 1441/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5090e-04 - val_loss: 0.0917\n",
      "Epoch 1442/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4532e-04 - val_loss: 0.0920\n",
      "Epoch 1443/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2143e-04 - val_loss: 0.0924\n",
      "Epoch 1444/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2978e-04 - val_loss: 0.0924\n",
      "Epoch 1445/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4387e-04 - val_loss: 0.0919\n",
      "Epoch 1446/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.2317e-04 - val_loss: 0.0916\n",
      "Epoch 1447/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5733e-04 - val_loss: 0.0919\n",
      "Epoch 1448/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2115e-04 - val_loss: 0.0921\n",
      "Epoch 1449/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1691e-04 - val_loss: 0.0923\n",
      "Epoch 1450/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0566e-04 - val_loss: 0.0924\n",
      "Epoch 1451/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2994e-04 - val_loss: 0.0922\n",
      "Epoch 1452/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 9.2646e-04 - val_loss: 0.0924\n",
      "Epoch 1453/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5128e-04 - val_loss: 0.0926\n",
      "Epoch 1454/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2544e-04 - val_loss: 0.0928\n",
      "Epoch 1455/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4177e-04 - val_loss: 0.0925\n",
      "Epoch 1456/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2339e-04 - val_loss: 0.0926\n",
      "Epoch 1457/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2668e-04 - val_loss: 0.0930\n",
      "Epoch 1458/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2418e-04 - val_loss: 0.0937\n",
      "Epoch 1459/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4339e-04 - val_loss: 0.0936\n",
      "Epoch 1460/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4189e-04 - val_loss: 0.0929\n",
      "Epoch 1461/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0862e-04 - val_loss: 0.0922\n",
      "Epoch 1462/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4570e-04 - val_loss: 0.0921\n",
      "Epoch 1463/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5132e-04 - val_loss: 0.0925\n",
      "Epoch 1464/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.3047e-04 - val_loss: 0.0929\n",
      "Epoch 1465/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3466e-04 - val_loss: 0.0928\n",
      "Epoch 1466/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.2946e-04 - val_loss: 0.0927\n",
      "Epoch 1467/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3516e-04 - val_loss: 0.0927\n",
      "Epoch 1468/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9933e-04 - val_loss: 0.0928\n",
      "Epoch 1469/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0834e-04 - val_loss: 0.0929\n",
      "Epoch 1470/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3816e-04 - val_loss: 0.0925\n",
      "Epoch 1471/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2134e-04 - val_loss: 0.0923\n",
      "Epoch 1472/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.2069e-04 - val_loss: 0.0924\n",
      "Epoch 1473/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1792e-04 - val_loss: 0.0923\n",
      "Epoch 1474/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1192e-04 - val_loss: 0.0923\n",
      "Epoch 1475/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2015e-04 - val_loss: 0.0924\n",
      "Epoch 1476/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0149e-04 - val_loss: 0.0923\n",
      "Epoch 1477/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1862e-04 - val_loss: 0.0922\n",
      "Epoch 1478/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1605e-04 - val_loss: 0.0921\n",
      "Epoch 1479/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3645e-04 - val_loss: 0.0923\n",
      "Epoch 1480/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0753e-04 - val_loss: 0.0927\n",
      "Epoch 1481/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1701e-04 - val_loss: 0.0930\n",
      "Epoch 1482/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3390e-04 - val_loss: 0.0926\n",
      "Epoch 1483/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.2453e-04 - val_loss: 0.0920\n",
      "Epoch 1484/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3381e-04 - val_loss: 0.0919\n",
      "Epoch 1485/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2161e-04 - val_loss: 0.0927\n",
      "Epoch 1486/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0652e-04 - val_loss: 0.0933\n",
      "Epoch 1487/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2462e-04 - val_loss: 0.0933\n",
      "Epoch 1488/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3087e-04 - val_loss: 0.0931\n",
      "Epoch 1489/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0842e-04 - val_loss: 0.0935\n",
      "Epoch 1490/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4414e-04 - val_loss: 0.0938\n",
      "Epoch 1491/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1294e-04 - val_loss: 0.0939\n",
      "Epoch 1492/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3437e-04 - val_loss: 0.0932\n",
      "Epoch 1493/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3215e-04 - val_loss: 0.0922\n",
      "Epoch 1494/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1444e-04 - val_loss: 0.0919\n",
      "Epoch 1495/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3498e-04 - val_loss: 0.0920\n",
      "Epoch 1496/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3340e-04 - val_loss: 0.0928\n",
      "Epoch 1497/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3129e-04 - val_loss: 0.0933\n",
      "Epoch 1498/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2733e-04 - val_loss: 0.0930\n",
      "Epoch 1499/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2934e-04 - val_loss: 0.0926\n",
      "Epoch 1500/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2921e-04 - val_loss: 0.0924\n",
      "Epoch 1501/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2237e-04 - val_loss: 0.0919\n",
      "Epoch 1502/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2421e-04 - val_loss: 0.0917\n",
      "Epoch 1503/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1801e-04 - val_loss: 0.0919\n",
      "Epoch 1504/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1075e-04 - val_loss: 0.0923\n",
      "Epoch 1505/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0637e-04 - val_loss: 0.0926\n",
      "Epoch 1506/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2627e-04 - val_loss: 0.0927\n",
      "Epoch 1507/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.1102e-04 - val_loss: 0.0927\n",
      "Epoch 1508/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2709e-04 - val_loss: 0.0925\n",
      "Epoch 1509/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3768e-04 - val_loss: 0.0923\n",
      "Epoch 1510/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1122e-04 - val_loss: 0.0922\n",
      "Epoch 1511/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2779e-04 - val_loss: 0.0926\n",
      "Epoch 1512/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1614e-04 - val_loss: 0.0928\n",
      "Epoch 1513/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1314e-04 - val_loss: 0.0928\n",
      "Epoch 1514/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2041e-04 - val_loss: 0.0926\n",
      "Epoch 1515/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2061e-04 - val_loss: 0.0922\n",
      "Epoch 1516/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1875e-04 - val_loss: 0.0919\n",
      "Epoch 1517/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2941e-04 - val_loss: 0.0918\n",
      "Epoch 1518/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 9.3040e-04 - val_loss: 0.0921\n",
      "Epoch 1519/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.2511e-04 - val_loss: 0.0925\n",
      "Epoch 1520/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1095e-04 - val_loss: 0.0929\n",
      "Epoch 1521/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1788e-04 - val_loss: 0.0930\n",
      "Epoch 1522/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3484e-04 - val_loss: 0.0929\n",
      "Epoch 1523/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3402e-04 - val_loss: 0.0927\n",
      "Epoch 1524/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4210e-04 - val_loss: 0.0928\n",
      "Epoch 1525/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2475e-04 - val_loss: 0.0928\n",
      "Epoch 1526/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4629e-04 - val_loss: 0.0923\n",
      "Epoch 1527/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2061e-04 - val_loss: 0.0919\n",
      "Epoch 1528/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4687e-04 - val_loss: 0.0920\n",
      "Epoch 1529/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.2775e-04 - val_loss: 0.0925\n",
      "Epoch 1530/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0803e-04 - val_loss: 0.0931\n",
      "Epoch 1531/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3778e-04 - val_loss: 0.0930\n",
      "Epoch 1532/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.3943e-04 - val_loss: 0.0923\n",
      "Epoch 1533/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.3411e-04 - val_loss: 0.0918\n",
      "Epoch 1534/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2944e-04 - val_loss: 0.0918\n",
      "Epoch 1535/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.2261e-04 - val_loss: 0.0922\n",
      "Epoch 1536/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2777e-04 - val_loss: 0.0923\n",
      "Epoch 1537/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0194e-04 - val_loss: 0.0922\n",
      "Epoch 1538/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3603e-04 - val_loss: 0.0923\n",
      "Epoch 1539/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3181e-04 - val_loss: 0.0923\n",
      "Epoch 1540/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0909e-04 - val_loss: 0.0925\n",
      "Epoch 1541/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1491e-04 - val_loss: 0.0929\n",
      "Epoch 1542/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2003e-04 - val_loss: 0.0928\n",
      "Epoch 1543/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4141e-04 - val_loss: 0.0923\n",
      "Epoch 1544/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1872e-04 - val_loss: 0.0920\n",
      "Epoch 1545/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3279e-04 - val_loss: 0.0923\n",
      "Epoch 1546/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2594e-04 - val_loss: 0.0929\n",
      "Epoch 1547/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.3021e-04 - val_loss: 0.0932\n",
      "Epoch 1548/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1651e-04 - val_loss: 0.0927\n",
      "Epoch 1549/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0929e-04 - val_loss: 0.0921\n",
      "Epoch 1550/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4777e-04 - val_loss: 0.0918\n",
      "Epoch 1551/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0041e-04 - val_loss: 0.0917\n",
      "Epoch 1552/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1385e-04 - val_loss: 0.0919\n",
      "Epoch 1553/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1394e-04 - val_loss: 0.0924\n",
      "Epoch 1554/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1621e-04 - val_loss: 0.0929\n",
      "Epoch 1555/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2536e-04 - val_loss: 0.0931\n",
      "Epoch 1556/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1809e-04 - val_loss: 0.0932\n",
      "Epoch 1557/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0784e-04 - val_loss: 0.0933\n",
      "Epoch 1558/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1028e-04 - val_loss: 0.0933\n",
      "Epoch 1559/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3040e-04 - val_loss: 0.0931\n",
      "Epoch 1560/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9799e-04 - val_loss: 0.0926\n",
      "Epoch 1561/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1169e-04 - val_loss: 0.0921\n",
      "Epoch 1562/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3174e-04 - val_loss: 0.0923\n",
      "Epoch 1563/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.1916e-04 - val_loss: 0.0931\n",
      "Epoch 1564/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.1461e-04 - val_loss: 0.0936\n",
      "Epoch 1565/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3125e-04 - val_loss: 0.0932\n",
      "Epoch 1566/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.3427e-04 - val_loss: 0.0925\n",
      "Epoch 1567/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1312e-04 - val_loss: 0.0921\n",
      "Epoch 1568/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.1164e-04 - val_loss: 0.0919\n",
      "Epoch 1569/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3355e-04 - val_loss: 0.0920\n",
      "Epoch 1570/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0159e-04 - val_loss: 0.0922\n",
      "Epoch 1571/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1286e-04 - val_loss: 0.0926\n",
      "Epoch 1572/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.2599e-04 - val_loss: 0.0926\n",
      "Epoch 1573/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0283e-04 - val_loss: 0.0926\n",
      "Epoch 1574/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3113e-04 - val_loss: 0.0927\n",
      "Epoch 1575/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9987e-04 - val_loss: 0.0923\n",
      "Epoch 1576/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3424e-04 - val_loss: 0.0918\n",
      "Epoch 1577/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2278e-04 - val_loss: 0.0914\n",
      "Epoch 1578/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0782e-04 - val_loss: 0.0916\n",
      "Epoch 1579/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0769e-04 - val_loss: 0.0924\n",
      "Epoch 1580/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1644e-04 - val_loss: 0.0929\n",
      "Epoch 1581/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0529e-04 - val_loss: 0.0929\n",
      "Epoch 1582/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2751e-04 - val_loss: 0.0921\n",
      "Epoch 1583/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1295e-04 - val_loss: 0.0917\n",
      "Epoch 1584/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4988e-04 - val_loss: 0.0924\n",
      "Epoch 1585/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0911e-04 - val_loss: 0.0932\n",
      "Epoch 1586/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3259e-04 - val_loss: 0.0935\n",
      "Epoch 1587/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1361e-04 - val_loss: 0.0932\n",
      "Epoch 1588/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4350e-04 - val_loss: 0.0932\n",
      "Epoch 1589/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.6787e-04 - val_loss: 0.0935\n",
      "Epoch 1590/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.1838e-04 - val_loss: 0.0937\n",
      "Epoch 1591/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3599e-04 - val_loss: 0.0930\n",
      "Epoch 1592/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3450e-04 - val_loss: 0.0924\n",
      "Epoch 1593/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3346e-04 - val_loss: 0.0922\n",
      "Epoch 1594/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4803e-04 - val_loss: 0.0925\n",
      "Epoch 1595/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3779e-04 - val_loss: 0.0930\n",
      "Epoch 1596/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6356e-04 - val_loss: 0.0930\n",
      "Epoch 1597/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4791e-04 - val_loss: 0.0922\n",
      "Epoch 1598/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2080e-04 - val_loss: 0.0922\n",
      "Epoch 1599/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5771e-04 - val_loss: 0.0926\n",
      "Epoch 1600/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3191e-04 - val_loss: 0.0934\n",
      "Epoch 1601/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2247e-04 - val_loss: 0.0932\n",
      "Epoch 1602/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6114e-04 - val_loss: 0.0922\n",
      "Epoch 1603/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0410e-04 - val_loss: 0.0915\n",
      "Epoch 1604/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3266e-04 - val_loss: 0.0917\n",
      "Epoch 1605/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3293e-04 - val_loss: 0.0925\n",
      "Epoch 1606/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1237e-04 - val_loss: 0.0934\n",
      "Epoch 1607/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6201e-04 - val_loss: 0.0930\n",
      "Epoch 1608/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2521e-04 - val_loss: 0.0920\n",
      "Epoch 1609/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4202e-04 - val_loss: 0.0919\n",
      "Epoch 1610/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4608e-04 - val_loss: 0.0925\n",
      "Epoch 1611/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9392e-04 - val_loss: 0.0927\n",
      "Epoch 1612/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5075e-04 - val_loss: 0.0926\n",
      "Epoch 1613/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2957e-04 - val_loss: 0.0920\n",
      "Epoch 1614/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1850e-04 - val_loss: 0.0919\n",
      "Epoch 1615/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4131e-04 - val_loss: 0.0921\n",
      "Epoch 1616/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2333e-04 - val_loss: 0.0930\n",
      "Epoch 1617/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4308e-04 - val_loss: 0.0933\n",
      "Epoch 1618/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.5674e-04 - val_loss: 0.0928\n",
      "Epoch 1619/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1172e-04 - val_loss: 0.0923\n",
      "Epoch 1620/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.4139e-04 - val_loss: 0.0921\n",
      "Epoch 1621/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2162e-04 - val_loss: 0.0923\n",
      "Epoch 1622/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2950e-04 - val_loss: 0.0926\n",
      "Epoch 1623/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2324e-04 - val_loss: 0.0927\n",
      "Epoch 1624/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1167e-04 - val_loss: 0.0928\n",
      "Epoch 1625/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2687e-04 - val_loss: 0.0927\n",
      "Epoch 1626/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9445e-04 - val_loss: 0.0927\n",
      "Epoch 1627/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2647e-04 - val_loss: 0.0927\n",
      "Epoch 1628/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1047e-04 - val_loss: 0.0928\n",
      "Epoch 1629/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1322e-04 - val_loss: 0.0924\n",
      "Epoch 1630/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2624e-04 - val_loss: 0.0920\n",
      "Epoch 1631/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1229e-04 - val_loss: 0.0917\n",
      "Epoch 1632/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2132e-04 - val_loss: 0.0920\n",
      "Epoch 1633/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1430e-04 - val_loss: 0.0928\n",
      "Epoch 1634/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0291e-04 - val_loss: 0.0934\n",
      "Epoch 1635/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2693e-04 - val_loss: 0.0933\n",
      "Epoch 1636/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1660e-04 - val_loss: 0.0930\n",
      "Epoch 1637/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0333e-04 - val_loss: 0.0926\n",
      "Epoch 1638/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1421e-04 - val_loss: 0.0927\n",
      "Epoch 1639/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2761e-04 - val_loss: 0.0931\n",
      "Epoch 1640/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2121e-04 - val_loss: 0.0929\n",
      "Epoch 1641/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3235e-04 - val_loss: 0.0925\n",
      "Epoch 1642/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9420e-04 - val_loss: 0.0923\n",
      "Epoch 1643/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3058e-04 - val_loss: 0.0925\n",
      "Epoch 1644/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0697e-04 - val_loss: 0.0927\n",
      "Epoch 1645/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2587e-04 - val_loss: 0.0928\n",
      "Epoch 1646/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 9.1804e-04 - val_loss: 0.0928\n",
      "Epoch 1647/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2536e-04 - val_loss: 0.0924\n",
      "Epoch 1648/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0447e-04 - val_loss: 0.0923\n",
      "Epoch 1649/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.6436e-04 - val_loss: 0.0927\n",
      "Epoch 1650/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4209e-04 - val_loss: 0.0932\n",
      "Epoch 1651/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1955e-04 - val_loss: 0.0935\n",
      "Epoch 1652/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5525e-04 - val_loss: 0.0931\n",
      "Epoch 1653/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.4029e-04 - val_loss: 0.0928\n",
      "Epoch 1654/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2567e-04 - val_loss: 0.0923\n",
      "Epoch 1655/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1912e-04 - val_loss: 0.0922\n",
      "Epoch 1656/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0236e-04 - val_loss: 0.0924\n",
      "Epoch 1657/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6397e-04 - val_loss: 0.0925\n",
      "Epoch 1658/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0131e-04 - val_loss: 0.0926\n",
      "Epoch 1659/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1155e-04 - val_loss: 0.0930\n",
      "Epoch 1660/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.4160e-04 - val_loss: 0.0929\n",
      "Epoch 1661/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4251e-04 - val_loss: 0.0922\n",
      "Epoch 1662/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1564e-04 - val_loss: 0.0915\n",
      "Epoch 1663/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0889e-04 - val_loss: 0.0914\n",
      "Epoch 1664/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.3968e-04 - val_loss: 0.0920\n",
      "Epoch 1665/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1659e-04 - val_loss: 0.0928\n",
      "Epoch 1666/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1032e-04 - val_loss: 0.0930\n",
      "Epoch 1667/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0734e-04 - val_loss: 0.0927\n",
      "Epoch 1668/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2583e-04 - val_loss: 0.0923\n",
      "Epoch 1669/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1550e-04 - val_loss: 0.0916\n",
      "Epoch 1670/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2795e-04 - val_loss: 0.0918\n",
      "Epoch 1671/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2244e-04 - val_loss: 0.0924\n",
      "Epoch 1672/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0872e-04 - val_loss: 0.0933\n",
      "Epoch 1673/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0880e-04 - val_loss: 0.0937\n",
      "Epoch 1674/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2381e-04 - val_loss: 0.0934\n",
      "Epoch 1675/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.1938e-04 - val_loss: 0.0927\n",
      "Epoch 1676/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1192e-04 - val_loss: 0.0922\n",
      "Epoch 1677/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.1787e-04 - val_loss: 0.0921\n",
      "Epoch 1678/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2765e-04 - val_loss: 0.0925\n",
      "Epoch 1679/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.0771e-04 - val_loss: 0.0927\n",
      "Epoch 1680/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2804e-04 - val_loss: 0.0926\n",
      "Epoch 1681/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 9.0195e-04 - val_loss: 0.0924\n",
      "Epoch 1682/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2244e-04 - val_loss: 0.0921\n",
      "Epoch 1683/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4054e-04 - val_loss: 0.0921\n",
      "Epoch 1684/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4664e-04 - val_loss: 0.0917\n",
      "Epoch 1685/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3069e-04 - val_loss: 0.0914\n",
      "Epoch 1686/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 9.3167e-04 - val_loss: 0.0915\n",
      "Epoch 1687/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 9.1669e-04 - val_loss: 0.0922\n",
      "Epoch 1688/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.2281e-04 - val_loss: 0.0927\n",
      "Epoch 1689/3000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.2301e-04 - val_loss: 0.0926\n",
      "Epoch 1690/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3589e-04 - val_loss: 0.0921\n",
      "Epoch 1691/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9991e-04 - val_loss: 0.0919\n",
      "Epoch 1692/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2628e-04 - val_loss: 0.0923\n",
      "Epoch 1693/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3158e-04 - val_loss: 0.0928\n",
      "Epoch 1694/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3254e-04 - val_loss: 0.0929\n",
      "Epoch 1695/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1394e-04 - val_loss: 0.0927\n",
      "Epoch 1696/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2954e-04 - val_loss: 0.0924\n",
      "Epoch 1697/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3646e-04 - val_loss: 0.0921\n",
      "Epoch 1698/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.1879e-04 - val_loss: 0.0918\n",
      "Epoch 1699/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 9.1105e-04 - val_loss: 0.0919\n",
      "Epoch 1700/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9229e-04 - val_loss: 0.0920\n",
      "Epoch 1701/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.0382e-04 - val_loss: 0.0924\n",
      "Epoch 1702/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.3044e-04 - val_loss: 0.0926\n",
      "Epoch 1703/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1822e-04 - val_loss: 0.0924\n",
      "Epoch 1704/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9646e-04 - val_loss: 0.0920\n",
      "Epoch 1705/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4363e-04 - val_loss: 0.0920\n",
      "Epoch 1706/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.1565e-04 - val_loss: 0.0918\n",
      "Epoch 1707/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0255e-04 - val_loss: 0.0919\n",
      "Epoch 1708/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3287e-04 - val_loss: 0.0920\n",
      "Epoch 1709/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1818e-04 - val_loss: 0.0925\n",
      "Epoch 1710/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2137e-04 - val_loss: 0.0925\n",
      "Epoch 1711/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2058e-04 - val_loss: 0.0920\n",
      "Epoch 1712/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3620e-04 - val_loss: 0.0917\n",
      "Epoch 1713/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2201e-04 - val_loss: 0.0916\n",
      "Epoch 1714/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9368e-04 - val_loss: 0.0919\n",
      "Epoch 1715/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2520e-04 - val_loss: 0.0919\n",
      "Epoch 1716/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2762e-04 - val_loss: 0.0919\n",
      "Epoch 1717/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0260e-04 - val_loss: 0.0921\n",
      "Epoch 1718/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0146e-04 - val_loss: 0.0925\n",
      "Epoch 1719/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2808e-04 - val_loss: 0.0929\n",
      "Epoch 1720/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1295e-04 - val_loss: 0.0932\n",
      "Epoch 1721/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2488e-04 - val_loss: 0.0926\n",
      "Epoch 1722/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1336e-04 - val_loss: 0.0918\n",
      "Epoch 1723/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1531e-04 - val_loss: 0.0915\n",
      "Epoch 1724/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.1096e-04 - val_loss: 0.0917\n",
      "Epoch 1725/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.9621e-04 - val_loss: 0.0921\n",
      "Epoch 1726/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 9.3661e-04 - val_loss: 0.0926\n",
      "Epoch 1727/3000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 9.0354e-04 - val_loss: 0.0928\n",
      "Epoch 1728/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 9.1801e-04 - val_loss: 0.0926\n",
      "Epoch 1729/3000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 9.2200e-04 - val_loss: 0.0921\n",
      "Epoch 1730/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0414e-04 - val_loss: 0.0916\n",
      "Epoch 1731/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1036e-04 - val_loss: 0.0917\n",
      "Epoch 1732/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.3356e-04 - val_loss: 0.0919\n",
      "Epoch 1733/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9916e-04 - val_loss: 0.0920\n",
      "Epoch 1734/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.2650e-04 - val_loss: 0.0920\n",
      "Epoch 1735/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1324e-04 - val_loss: 0.0921\n",
      "Epoch 1736/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0400e-04 - val_loss: 0.0922\n",
      "Epoch 1737/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9683e-04 - val_loss: 0.0920\n",
      "Epoch 1738/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2727e-04 - val_loss: 0.0914\n",
      "Epoch 1739/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3485e-04 - val_loss: 0.0915\n",
      "Epoch 1740/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1908e-04 - val_loss: 0.0918\n",
      "Epoch 1741/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3039e-04 - val_loss: 0.0917\n",
      "Epoch 1742/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1074e-04 - val_loss: 0.0914\n",
      "Epoch 1743/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1356e-04 - val_loss: 0.0910\n",
      "Epoch 1744/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2648e-04 - val_loss: 0.0911\n",
      "Epoch 1745/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1980e-04 - val_loss: 0.0919\n",
      "Epoch 1746/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0885e-04 - val_loss: 0.0925\n",
      "Epoch 1747/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2312e-04 - val_loss: 0.0923\n",
      "Epoch 1748/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3217e-04 - val_loss: 0.0919\n",
      "Epoch 1749/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5242e-04 - val_loss: 0.0917\n",
      "Epoch 1750/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3099e-04 - val_loss: 0.0919\n",
      "Epoch 1751/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.6020e-04 - val_loss: 0.0921\n",
      "Epoch 1752/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9490e-04 - val_loss: 0.0917\n",
      "Epoch 1753/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1688e-04 - val_loss: 0.0913\n",
      "Epoch 1754/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1988e-04 - val_loss: 0.0913\n",
      "Epoch 1755/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1260e-04 - val_loss: 0.0916\n",
      "Epoch 1756/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2248e-04 - val_loss: 0.0920\n",
      "Epoch 1757/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.0586e-04 - val_loss: 0.0920\n",
      "Epoch 1758/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1255e-04 - val_loss: 0.0922\n",
      "Epoch 1759/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2334e-04 - val_loss: 0.0921\n",
      "Epoch 1760/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9227e-04 - val_loss: 0.0916\n",
      "Epoch 1761/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2232e-04 - val_loss: 0.0912\n",
      "Epoch 1762/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9595e-04 - val_loss: 0.0913\n",
      "Epoch 1763/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0136e-04 - val_loss: 0.0914\n",
      "Epoch 1764/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9089e-04 - val_loss: 0.0915\n",
      "Epoch 1765/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0611e-04 - val_loss: 0.0917\n",
      "Epoch 1766/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1822e-04 - val_loss: 0.0918\n",
      "Epoch 1767/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0478e-04 - val_loss: 0.0916\n",
      "Epoch 1768/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1340e-04 - val_loss: 0.0914\n",
      "Epoch 1769/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0656e-04 - val_loss: 0.0916\n",
      "Epoch 1770/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9658e-04 - val_loss: 0.0923\n",
      "Epoch 1771/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9943e-04 - val_loss: 0.0923\n",
      "Epoch 1772/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9127e-04 - val_loss: 0.0920\n",
      "Epoch 1773/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.4854e-04 - val_loss: 0.0915\n",
      "Epoch 1774/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9724e-04 - val_loss: 0.0913\n",
      "Epoch 1775/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8889e-04 - val_loss: 0.0911\n",
      "Epoch 1776/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1541e-04 - val_loss: 0.0913\n",
      "Epoch 1777/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9350e-04 - val_loss: 0.0917\n",
      "Epoch 1778/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9017e-04 - val_loss: 0.0919\n",
      "Epoch 1779/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0458e-04 - val_loss: 0.0915\n",
      "Epoch 1780/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9617e-04 - val_loss: 0.0915\n",
      "Epoch 1781/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1599e-04 - val_loss: 0.0917\n",
      "Epoch 1782/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1871e-04 - val_loss: 0.0921\n",
      "Epoch 1783/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.2171e-04 - val_loss: 0.0923\n",
      "Epoch 1784/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1145e-04 - val_loss: 0.0926\n",
      "Epoch 1785/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8557e-04 - val_loss: 0.0926\n",
      "Epoch 1786/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0476e-04 - val_loss: 0.0920\n",
      "Epoch 1787/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9931e-04 - val_loss: 0.0915\n",
      "Epoch 1788/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1086e-04 - val_loss: 0.0914\n",
      "Epoch 1789/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1068e-04 - val_loss: 0.0917\n",
      "Epoch 1790/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0676e-04 - val_loss: 0.0920\n",
      "Epoch 1791/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9171e-04 - val_loss: 0.0923\n",
      "Epoch 1792/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1194e-04 - val_loss: 0.0921\n",
      "Epoch 1793/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1789e-04 - val_loss: 0.0916\n",
      "Epoch 1794/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8938e-04 - val_loss: 0.0911\n",
      "Epoch 1795/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1519e-04 - val_loss: 0.0912\n",
      "Epoch 1796/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.2528e-04 - val_loss: 0.0918\n",
      "Epoch 1797/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1788e-04 - val_loss: 0.0922\n",
      "Epoch 1798/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0261e-04 - val_loss: 0.0920\n",
      "Epoch 1799/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2112e-04 - val_loss: 0.0913\n",
      "Epoch 1800/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9785e-04 - val_loss: 0.0911\n",
      "Epoch 1801/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9705e-04 - val_loss: 0.0910\n",
      "Epoch 1802/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.2858e-04 - val_loss: 0.0909\n",
      "Epoch 1803/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9462e-04 - val_loss: 0.0913\n",
      "Epoch 1804/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1198e-04 - val_loss: 0.0919\n",
      "Epoch 1805/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0604e-04 - val_loss: 0.0924\n",
      "Epoch 1806/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1920e-04 - val_loss: 0.0921\n",
      "Epoch 1807/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1340e-04 - val_loss: 0.0917\n",
      "Epoch 1808/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9404e-04 - val_loss: 0.0913\n",
      "Epoch 1809/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2933e-04 - val_loss: 0.0916\n",
      "Epoch 1810/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0551e-04 - val_loss: 0.0919\n",
      "Epoch 1811/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2744e-04 - val_loss: 0.0916\n",
      "Epoch 1812/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1407e-04 - val_loss: 0.0909\n",
      "Epoch 1813/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9536e-04 - val_loss: 0.0907\n",
      "Epoch 1814/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0470e-04 - val_loss: 0.0911\n",
      "Epoch 1815/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0267e-04 - val_loss: 0.0916\n",
      "Epoch 1816/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0757e-04 - val_loss: 0.0919\n",
      "Epoch 1817/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3315e-04 - val_loss: 0.0918\n",
      "Epoch 1818/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0225e-04 - val_loss: 0.0916\n",
      "Epoch 1819/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9176e-04 - val_loss: 0.0916\n",
      "Epoch 1820/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3467e-04 - val_loss: 0.0917\n",
      "Epoch 1821/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1634e-04 - val_loss: 0.0917\n",
      "Epoch 1822/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1401e-04 - val_loss: 0.0922\n",
      "Epoch 1823/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0636e-04 - val_loss: 0.0928\n",
      "Epoch 1824/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1958e-04 - val_loss: 0.0927\n",
      "Epoch 1825/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1050e-04 - val_loss: 0.0921\n",
      "Epoch 1826/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1500e-04 - val_loss: 0.0914\n",
      "Epoch 1827/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0997e-04 - val_loss: 0.0911\n",
      "Epoch 1828/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8606e-04 - val_loss: 0.0912\n",
      "Epoch 1829/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0317e-04 - val_loss: 0.0912\n",
      "Epoch 1830/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0922e-04 - val_loss: 0.0913\n",
      "Epoch 1831/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0448e-04 - val_loss: 0.0913\n",
      "Epoch 1832/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1085e-04 - val_loss: 0.0914\n",
      "Epoch 1833/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4653e-04 - val_loss: 0.0918\n",
      "Epoch 1834/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1151e-04 - val_loss: 0.0920\n",
      "Epoch 1835/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1721e-04 - val_loss: 0.0916\n",
      "Epoch 1836/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1486e-04 - val_loss: 0.0915\n",
      "Epoch 1837/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9936e-04 - val_loss: 0.0917\n",
      "Epoch 1838/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.1082e-04 - val_loss: 0.0924\n",
      "Epoch 1839/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0655e-04 - val_loss: 0.0928\n",
      "Epoch 1840/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1407e-04 - val_loss: 0.0925\n",
      "Epoch 1841/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.3263e-04 - val_loss: 0.0919\n",
      "Epoch 1842/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0235e-04 - val_loss: 0.0914\n",
      "Epoch 1843/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9974e-04 - val_loss: 0.0914\n",
      "Epoch 1844/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0547e-04 - val_loss: 0.0915\n",
      "Epoch 1845/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0436e-04 - val_loss: 0.0916\n",
      "Epoch 1846/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0756e-04 - val_loss: 0.0920\n",
      "Epoch 1847/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9787e-04 - val_loss: 0.0924\n",
      "Epoch 1848/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2377e-04 - val_loss: 0.0921\n",
      "Epoch 1849/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1484e-04 - val_loss: 0.0914\n",
      "Epoch 1850/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1551e-04 - val_loss: 0.0912\n",
      "Epoch 1851/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2171e-04 - val_loss: 0.0913\n",
      "Epoch 1852/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0778e-04 - val_loss: 0.0920\n",
      "Epoch 1853/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2990e-04 - val_loss: 0.0923\n",
      "Epoch 1854/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7291e-04 - val_loss: 0.0924\n",
      "Epoch 1855/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2645e-04 - val_loss: 0.0921\n",
      "Epoch 1856/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1123e-04 - val_loss: 0.0914\n",
      "Epoch 1857/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0901e-04 - val_loss: 0.0911\n",
      "Epoch 1858/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2202e-04 - val_loss: 0.0913\n",
      "Epoch 1859/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0672e-04 - val_loss: 0.0916\n",
      "Epoch 1860/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9874e-04 - val_loss: 0.0920\n",
      "Epoch 1861/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2563e-04 - val_loss: 0.0915\n",
      "Epoch 1862/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1466e-04 - val_loss: 0.0910\n",
      "Epoch 1863/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0169e-04 - val_loss: 0.0908\n",
      "Epoch 1864/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9256e-04 - val_loss: 0.0909\n",
      "Epoch 1865/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2494e-04 - val_loss: 0.0914\n",
      "Epoch 1866/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 8.9073e-04 - val_loss: 0.0918\n",
      "Epoch 1867/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2912e-04 - val_loss: 0.0920\n",
      "Epoch 1868/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.3348e-04 - val_loss: 0.0914\n",
      "Epoch 1869/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 8.9692e-04 - val_loss: 0.0908\n",
      "Epoch 1870/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0710e-04 - val_loss: 0.0908\n",
      "Epoch 1871/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0658e-04 - val_loss: 0.0912\n",
      "Epoch 1872/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1287e-04 - val_loss: 0.0914\n",
      "Epoch 1873/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8716e-04 - val_loss: 0.0911\n",
      "Epoch 1874/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8376e-04 - val_loss: 0.0911\n",
      "Epoch 1875/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 9.0001e-04 - val_loss: 0.0915\n",
      "Epoch 1876/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7919e-04 - val_loss: 0.0915\n",
      "Epoch 1877/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8904e-04 - val_loss: 0.0911\n",
      "Epoch 1878/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1136e-04 - val_loss: 0.0907\n",
      "Epoch 1879/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0594e-04 - val_loss: 0.0906\n",
      "Epoch 1880/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9666e-04 - val_loss: 0.0909\n",
      "Epoch 1881/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2461e-04 - val_loss: 0.0910\n",
      "Epoch 1882/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.8970e-04 - val_loss: 0.0914\n",
      "Epoch 1883/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9065e-04 - val_loss: 0.0917\n",
      "Epoch 1884/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9576e-04 - val_loss: 0.0918\n",
      "Epoch 1885/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9095e-04 - val_loss: 0.0917\n",
      "Epoch 1886/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0265e-04 - val_loss: 0.0915\n",
      "Epoch 1887/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1484e-04 - val_loss: 0.0914\n",
      "Epoch 1888/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7404e-04 - val_loss: 0.0914\n",
      "Epoch 1889/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9625e-04 - val_loss: 0.0915\n",
      "Epoch 1890/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8861e-04 - val_loss: 0.0912\n",
      "Epoch 1891/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0717e-04 - val_loss: 0.0911\n",
      "Epoch 1892/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9778e-04 - val_loss: 0.0913\n",
      "Epoch 1893/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9839e-04 - val_loss: 0.0911\n",
      "Epoch 1894/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8730e-04 - val_loss: 0.0909\n",
      "Epoch 1895/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0462e-04 - val_loss: 0.0907\n",
      "Epoch 1896/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9009e-04 - val_loss: 0.0910\n",
      "Epoch 1897/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9598e-04 - val_loss: 0.0911\n",
      "Epoch 1898/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8579e-04 - val_loss: 0.0911\n",
      "Epoch 1899/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1411e-04 - val_loss: 0.0915\n",
      "Epoch 1900/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7727e-04 - val_loss: 0.0914\n",
      "Epoch 1901/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8969e-04 - val_loss: 0.0913\n",
      "Epoch 1902/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0698e-04 - val_loss: 0.0915\n",
      "Epoch 1903/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8717e-04 - val_loss: 0.0917\n",
      "Epoch 1904/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0193e-04 - val_loss: 0.0916\n",
      "Epoch 1905/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0000e-04 - val_loss: 0.0915\n",
      "Epoch 1906/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0492e-04 - val_loss: 0.0916\n",
      "Epoch 1907/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9430e-04 - val_loss: 0.0920\n",
      "Epoch 1908/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9462e-04 - val_loss: 0.0921\n",
      "Epoch 1909/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2376e-04 - val_loss: 0.0913\n",
      "Epoch 1910/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8768e-04 - val_loss: 0.0905\n",
      "Epoch 1911/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0991e-04 - val_loss: 0.0905\n",
      "Epoch 1912/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1710e-04 - val_loss: 0.0913\n",
      "Epoch 1913/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8589e-04 - val_loss: 0.0916\n",
      "Epoch 1914/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2027e-04 - val_loss: 0.0912\n",
      "Epoch 1915/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9426e-04 - val_loss: 0.0908\n",
      "Epoch 1916/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.2597e-04 - val_loss: 0.0912\n",
      "Epoch 1917/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0294e-04 - val_loss: 0.0921\n",
      "Epoch 1918/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3863e-04 - val_loss: 0.0917\n",
      "Epoch 1919/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8629e-04 - val_loss: 0.0914\n",
      "Epoch 1920/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3642e-04 - val_loss: 0.0918\n",
      "Epoch 1921/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9526e-04 - val_loss: 0.0924\n",
      "Epoch 1922/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9997e-04 - val_loss: 0.0920\n",
      "Epoch 1923/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0871e-04 - val_loss: 0.0911\n",
      "Epoch 1924/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1451e-04 - val_loss: 0.0912\n",
      "Epoch 1925/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1349e-04 - val_loss: 0.0920\n",
      "Epoch 1926/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0733e-04 - val_loss: 0.0925\n",
      "Epoch 1927/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2703e-04 - val_loss: 0.0918\n",
      "Epoch 1928/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1574e-04 - val_loss: 0.0909\n",
      "Epoch 1929/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0888e-04 - val_loss: 0.0906\n",
      "Epoch 1930/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1521e-04 - val_loss: 0.0912\n",
      "Epoch 1931/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2075e-04 - val_loss: 0.0918\n",
      "Epoch 1932/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.1425e-04 - val_loss: 0.0920\n",
      "Epoch 1933/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3918e-04 - val_loss: 0.0918\n",
      "Epoch 1934/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2084e-04 - val_loss: 0.0916\n",
      "Epoch 1935/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0444e-04 - val_loss: 0.0914\n",
      "Epoch 1936/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2683e-04 - val_loss: 0.0909\n",
      "Epoch 1937/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0598e-04 - val_loss: 0.0908\n",
      "Epoch 1938/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2009e-04 - val_loss: 0.0912\n",
      "Epoch 1939/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0149e-04 - val_loss: 0.0919\n",
      "Epoch 1940/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3512e-04 - val_loss: 0.0922\n",
      "Epoch 1941/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2593e-04 - val_loss: 0.0917\n",
      "Epoch 1942/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2987e-04 - val_loss: 0.0915\n",
      "Epoch 1943/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9950e-04 - val_loss: 0.0913\n",
      "Epoch 1944/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4417e-04 - val_loss: 0.0913\n",
      "Epoch 1945/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1878e-04 - val_loss: 0.0916\n",
      "Epoch 1946/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8630e-04 - val_loss: 0.0918\n",
      "Epoch 1947/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0966e-04 - val_loss: 0.0917\n",
      "Epoch 1948/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1210e-04 - val_loss: 0.0915\n",
      "Epoch 1949/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.2901e-04 - val_loss: 0.0910\n",
      "Epoch 1950/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.0966e-04 - val_loss: 0.0910\n",
      "Epoch 1951/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.2654e-04 - val_loss: 0.0910\n",
      "Epoch 1952/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9888e-04 - val_loss: 0.0916\n",
      "Epoch 1953/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9345e-04 - val_loss: 0.0922\n",
      "Epoch 1954/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9930e-04 - val_loss: 0.0923\n",
      "Epoch 1955/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9763e-04 - val_loss: 0.0916\n",
      "Epoch 1956/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8569e-04 - val_loss: 0.0909\n",
      "Epoch 1957/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1189e-04 - val_loss: 0.0905\n",
      "Epoch 1958/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9088e-04 - val_loss: 0.0909\n",
      "Epoch 1959/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0515e-04 - val_loss: 0.0915\n",
      "Epoch 1960/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0145e-04 - val_loss: 0.0921\n",
      "Epoch 1961/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0155e-04 - val_loss: 0.0927\n",
      "Epoch 1962/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4504e-04 - val_loss: 0.0925\n",
      "Epoch 1963/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0157e-04 - val_loss: 0.0918\n",
      "Epoch 1964/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1273e-04 - val_loss: 0.0911\n",
      "Epoch 1965/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0104e-04 - val_loss: 0.0910\n",
      "Epoch 1966/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4711e-04 - val_loss: 0.0915\n",
      "Epoch 1967/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0613e-04 - val_loss: 0.0918\n",
      "Epoch 1968/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9296e-04 - val_loss: 0.0917\n",
      "Epoch 1969/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0101e-04 - val_loss: 0.0913\n",
      "Epoch 1970/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9651e-04 - val_loss: 0.0911\n",
      "Epoch 1971/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0714e-04 - val_loss: 0.0911\n",
      "Epoch 1972/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0431e-04 - val_loss: 0.0908\n",
      "Epoch 1973/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0637e-04 - val_loss: 0.0908\n",
      "Epoch 1974/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0828e-04 - val_loss: 0.0915\n",
      "Epoch 1975/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8542e-04 - val_loss: 0.0923\n",
      "Epoch 1976/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.0815e-04 - val_loss: 0.0925\n",
      "Epoch 1977/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9235e-04 - val_loss: 0.0921\n",
      "Epoch 1978/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9872e-04 - val_loss: 0.0916\n",
      "Epoch 1979/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8360e-04 - val_loss: 0.0918\n",
      "Epoch 1980/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0407e-04 - val_loss: 0.0925\n",
      "Epoch 1981/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1579e-04 - val_loss: 0.0926\n",
      "Epoch 1982/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9621e-04 - val_loss: 0.0923\n",
      "Epoch 1983/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2479e-04 - val_loss: 0.0924\n",
      "Epoch 1984/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9921e-04 - val_loss: 0.0922\n",
      "Epoch 1985/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1461e-04 - val_loss: 0.0914\n",
      "Epoch 1986/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9856e-04 - val_loss: 0.0910\n",
      "Epoch 1987/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1518e-04 - val_loss: 0.0912\n",
      "Epoch 1988/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9961e-04 - val_loss: 0.0919\n",
      "Epoch 1989/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9017e-04 - val_loss: 0.0927\n",
      "Epoch 1990/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 9.1132e-04 - val_loss: 0.0922\n",
      "Epoch 1991/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9810e-04 - val_loss: 0.0912\n",
      "Epoch 1992/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.8888e-04 - val_loss: 0.0906\n",
      "Epoch 1993/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.9703e-04 - val_loss: 0.0907\n",
      "Epoch 1994/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.9564e-04 - val_loss: 0.0915\n",
      "Epoch 1995/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9353e-04 - val_loss: 0.0918\n",
      "Epoch 1996/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0482e-04 - val_loss: 0.0916\n",
      "Epoch 1997/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9095e-04 - val_loss: 0.0912\n",
      "Epoch 1998/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8468e-04 - val_loss: 0.0910\n",
      "Epoch 1999/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0047e-04 - val_loss: 0.0909\n",
      "Epoch 2000/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8315e-04 - val_loss: 0.0912\n",
      "Epoch 2001/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2500e-04 - val_loss: 0.0916\n",
      "Epoch 2002/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7585e-04 - val_loss: 0.0920\n",
      "Epoch 2003/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9638e-04 - val_loss: 0.0922\n",
      "Epoch 2004/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9036e-04 - val_loss: 0.0922\n",
      "Epoch 2005/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0083e-04 - val_loss: 0.0921\n",
      "Epoch 2006/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2028e-04 - val_loss: 0.0920\n",
      "Epoch 2007/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8613e-04 - val_loss: 0.0918\n",
      "Epoch 2008/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0023e-04 - val_loss: 0.0917\n",
      "Epoch 2009/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8641e-04 - val_loss: 0.0920\n",
      "Epoch 2010/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9566e-04 - val_loss: 0.0919\n",
      "Epoch 2011/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0351e-04 - val_loss: 0.0918\n",
      "Epoch 2012/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8841e-04 - val_loss: 0.0917\n",
      "Epoch 2013/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9049e-04 - val_loss: 0.0914\n",
      "Epoch 2014/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0545e-04 - val_loss: 0.0912\n",
      "Epoch 2015/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1088e-04 - val_loss: 0.0915\n",
      "Epoch 2016/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8335e-04 - val_loss: 0.0920\n",
      "Epoch 2017/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0540e-04 - val_loss: 0.0919\n",
      "Epoch 2018/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.8776e-04 - val_loss: 0.0915\n",
      "Epoch 2019/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8635e-04 - val_loss: 0.0914\n",
      "Epoch 2020/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8620e-04 - val_loss: 0.0916\n",
      "Epoch 2021/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7783e-04 - val_loss: 0.0921\n",
      "Epoch 2022/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8661e-04 - val_loss: 0.0921\n",
      "Epoch 2023/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9971e-04 - val_loss: 0.0921\n",
      "Epoch 2024/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9978e-04 - val_loss: 0.0923\n",
      "Epoch 2025/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8411e-04 - val_loss: 0.0924\n",
      "Epoch 2026/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8964e-04 - val_loss: 0.0923\n",
      "Epoch 2027/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9074e-04 - val_loss: 0.0921\n",
      "Epoch 2028/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9754e-04 - val_loss: 0.0923\n",
      "Epoch 2029/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8530e-04 - val_loss: 0.0927\n",
      "Epoch 2030/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7998e-04 - val_loss: 0.0925\n",
      "Epoch 2031/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8868e-04 - val_loss: 0.0918\n",
      "Epoch 2032/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7877e-04 - val_loss: 0.0910\n",
      "Epoch 2033/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8802e-04 - val_loss: 0.0909\n",
      "Epoch 2034/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8315e-04 - val_loss: 0.0913\n",
      "Epoch 2035/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6706e-04 - val_loss: 0.0917\n",
      "Epoch 2036/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8176e-04 - val_loss: 0.0918\n",
      "Epoch 2037/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9435e-04 - val_loss: 0.0918\n",
      "Epoch 2038/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8932e-04 - val_loss: 0.0916\n",
      "Epoch 2039/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8911e-04 - val_loss: 0.0916\n",
      "Epoch 2040/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9999e-04 - val_loss: 0.0917\n",
      "Epoch 2041/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8776e-04 - val_loss: 0.0920\n",
      "Epoch 2042/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8847e-04 - val_loss: 0.0918\n",
      "Epoch 2043/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.8944e-04 - val_loss: 0.0918\n",
      "Epoch 2044/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7297e-04 - val_loss: 0.0920\n",
      "Epoch 2045/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9542e-04 - val_loss: 0.0922\n",
      "Epoch 2046/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9562e-04 - val_loss: 0.0922\n",
      "Epoch 2047/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7133e-04 - val_loss: 0.0920\n",
      "Epoch 2048/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1357e-04 - val_loss: 0.0918\n",
      "Epoch 2049/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7515e-04 - val_loss: 0.0914\n",
      "Epoch 2050/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9110e-04 - val_loss: 0.0917\n",
      "Epoch 2051/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9554e-04 - val_loss: 0.0921\n",
      "Epoch 2052/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0227e-04 - val_loss: 0.0920\n",
      "Epoch 2053/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6914e-04 - val_loss: 0.0917\n",
      "Epoch 2054/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0810e-04 - val_loss: 0.0921\n",
      "Epoch 2055/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8364e-04 - val_loss: 0.0923\n",
      "Epoch 2056/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0292e-04 - val_loss: 0.0915\n",
      "Epoch 2057/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6439e-04 - val_loss: 0.0913\n",
      "Epoch 2058/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.1126e-04 - val_loss: 0.0918\n",
      "Epoch 2059/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7397e-04 - val_loss: 0.0927\n",
      "Epoch 2060/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1811e-04 - val_loss: 0.0926\n",
      "Epoch 2061/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9068e-04 - val_loss: 0.0922\n",
      "Epoch 2062/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.5563e-04 - val_loss: 0.0923\n",
      "Epoch 2063/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9489e-04 - val_loss: 0.0927\n",
      "Epoch 2064/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3428e-04 - val_loss: 0.0927\n",
      "Epoch 2065/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0317e-04 - val_loss: 0.0923\n",
      "Epoch 2066/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9829e-04 - val_loss: 0.0922\n",
      "Epoch 2067/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9923e-04 - val_loss: 0.0928\n",
      "Epoch 2068/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1775e-04 - val_loss: 0.0932\n",
      "Epoch 2069/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2166e-04 - val_loss: 0.0926\n",
      "Epoch 2070/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9070e-04 - val_loss: 0.0919\n",
      "Epoch 2071/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 9.1500e-04 - val_loss: 0.0918\n",
      "Epoch 2072/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.0041e-04 - val_loss: 0.0926\n",
      "Epoch 2073/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9657e-04 - val_loss: 0.0930\n",
      "Epoch 2074/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 9.1112e-04 - val_loss: 0.0929\n",
      "Epoch 2075/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9610e-04 - val_loss: 0.0924\n",
      "Epoch 2076/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1739e-04 - val_loss: 0.0925\n",
      "Epoch 2077/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9104e-04 - val_loss: 0.0925\n",
      "Epoch 2078/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3751e-04 - val_loss: 0.0921\n",
      "Epoch 2079/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7739e-04 - val_loss: 0.0920\n",
      "Epoch 2080/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1690e-04 - val_loss: 0.0927\n",
      "Epoch 2081/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7934e-04 - val_loss: 0.0931\n",
      "Epoch 2082/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3926e-04 - val_loss: 0.0927\n",
      "Epoch 2083/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0684e-04 - val_loss: 0.0918\n",
      "Epoch 2084/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2489e-04 - val_loss: 0.0918\n",
      "Epoch 2085/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0858e-04 - val_loss: 0.0926\n",
      "Epoch 2086/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1789e-04 - val_loss: 0.0926\n",
      "Epoch 2087/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1663e-04 - val_loss: 0.0919\n",
      "Epoch 2088/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8844e-04 - val_loss: 0.0920\n",
      "Epoch 2089/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8818e-04 - val_loss: 0.0925\n",
      "Epoch 2090/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9290e-04 - val_loss: 0.0929\n",
      "Epoch 2091/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9347e-04 - val_loss: 0.0927\n",
      "Epoch 2092/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7992e-04 - val_loss: 0.0925\n",
      "Epoch 2093/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0305e-04 - val_loss: 0.0925\n",
      "Epoch 2094/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0100e-04 - val_loss: 0.0926\n",
      "Epoch 2095/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0129e-04 - val_loss: 0.0923\n",
      "Epoch 2096/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1110e-04 - val_loss: 0.0913\n",
      "Epoch 2097/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9264e-04 - val_loss: 0.0913\n",
      "Epoch 2098/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7993e-04 - val_loss: 0.0921\n",
      "Epoch 2099/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9491e-04 - val_loss: 0.0931\n",
      "Epoch 2100/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.5788e-04 - val_loss: 0.0930\n",
      "Epoch 2101/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8320e-04 - val_loss: 0.0926\n",
      "Epoch 2102/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1268e-04 - val_loss: 0.0923\n",
      "Epoch 2103/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8246e-04 - val_loss: 0.0924\n",
      "Epoch 2104/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1391e-04 - val_loss: 0.0921\n",
      "Epoch 2105/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9435e-04 - val_loss: 0.0920\n",
      "Epoch 2106/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0586e-04 - val_loss: 0.0926\n",
      "Epoch 2107/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8986e-04 - val_loss: 0.0931\n",
      "Epoch 2108/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0603e-04 - val_loss: 0.0927\n",
      "Epoch 2109/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8841e-04 - val_loss: 0.0919\n",
      "Epoch 2110/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8707e-04 - val_loss: 0.0914\n",
      "Epoch 2111/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8448e-04 - val_loss: 0.0916\n",
      "Epoch 2112/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.7431e-04 - val_loss: 0.0920\n",
      "Epoch 2113/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8296e-04 - val_loss: 0.0919\n",
      "Epoch 2114/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9961e-04 - val_loss: 0.0916\n",
      "Epoch 2115/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8727e-04 - val_loss: 0.0917\n",
      "Epoch 2116/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8201e-04 - val_loss: 0.0917\n",
      "Epoch 2117/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9471e-04 - val_loss: 0.0915\n",
      "Epoch 2118/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9553e-04 - val_loss: 0.0915\n",
      "Epoch 2119/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8903e-04 - val_loss: 0.0920\n",
      "Epoch 2120/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6749e-04 - val_loss: 0.0923\n",
      "Epoch 2121/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8914e-04 - val_loss: 0.0926\n",
      "Epoch 2122/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8963e-04 - val_loss: 0.0926\n",
      "Epoch 2123/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9413e-04 - val_loss: 0.0926\n",
      "Epoch 2124/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0694e-04 - val_loss: 0.0921\n",
      "Epoch 2125/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0195e-04 - val_loss: 0.0917\n",
      "Epoch 2126/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8607e-04 - val_loss: 0.0917\n",
      "Epoch 2127/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0077e-04 - val_loss: 0.0918\n",
      "Epoch 2128/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8402e-04 - val_loss: 0.0918\n",
      "Epoch 2129/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8768e-04 - val_loss: 0.0913\n",
      "Epoch 2130/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0328e-04 - val_loss: 0.0909\n",
      "Epoch 2131/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9132e-04 - val_loss: 0.0910\n",
      "Epoch 2132/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1040e-04 - val_loss: 0.0913\n",
      "Epoch 2133/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6998e-04 - val_loss: 0.0915\n",
      "Epoch 2134/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3208e-04 - val_loss: 0.0911\n",
      "Epoch 2135/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8200e-04 - val_loss: 0.0911\n",
      "Epoch 2136/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8803e-04 - val_loss: 0.0916\n",
      "Epoch 2137/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9051e-04 - val_loss: 0.0921\n",
      "Epoch 2138/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.3248e-04 - val_loss: 0.0917\n",
      "Epoch 2139/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0143e-04 - val_loss: 0.0912\n",
      "Epoch 2140/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0183e-04 - val_loss: 0.0912\n",
      "Epoch 2141/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 9.0635e-04 - val_loss: 0.0915\n",
      "Epoch 2142/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1243e-04 - val_loss: 0.0914\n",
      "Epoch 2143/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.2287e-04 - val_loss: 0.0911\n",
      "Epoch 2144/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8818e-04 - val_loss: 0.0910\n",
      "Epoch 2145/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4117e-04 - val_loss: 0.0911\n",
      "Epoch 2146/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8172e-04 - val_loss: 0.0915\n",
      "Epoch 2147/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9990e-04 - val_loss: 0.0919\n",
      "Epoch 2148/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7918e-04 - val_loss: 0.0918\n",
      "Epoch 2149/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9785e-04 - val_loss: 0.0914\n",
      "Epoch 2150/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0151e-04 - val_loss: 0.0916\n",
      "Epoch 2151/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9028e-04 - val_loss: 0.0917\n",
      "Epoch 2152/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2031e-04 - val_loss: 0.0914\n",
      "Epoch 2153/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9139e-04 - val_loss: 0.0912\n",
      "Epoch 2154/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1703e-04 - val_loss: 0.0912\n",
      "Epoch 2155/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8049e-04 - val_loss: 0.0911\n",
      "Epoch 2156/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1528e-04 - val_loss: 0.0909\n",
      "Epoch 2157/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.9600e-04 - val_loss: 0.0907\n",
      "Epoch 2158/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9886e-04 - val_loss: 0.0908\n",
      "Epoch 2159/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8673e-04 - val_loss: 0.0913\n",
      "Epoch 2160/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8358e-04 - val_loss: 0.0917\n",
      "Epoch 2161/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.8835e-04 - val_loss: 0.0914\n",
      "Epoch 2162/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9296e-04 - val_loss: 0.0909\n",
      "Epoch 2163/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9703e-04 - val_loss: 0.0908\n",
      "Epoch 2164/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9187e-04 - val_loss: 0.0914\n",
      "Epoch 2165/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0791e-04 - val_loss: 0.0915\n",
      "Epoch 2166/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9029e-04 - val_loss: 0.0912\n",
      "Epoch 2167/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8108e-04 - val_loss: 0.0913\n",
      "Epoch 2168/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0283e-04 - val_loss: 0.0911\n",
      "Epoch 2169/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9101e-04 - val_loss: 0.0907\n",
      "Epoch 2170/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0679e-04 - val_loss: 0.0907\n",
      "Epoch 2171/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.0059e-04 - val_loss: 0.0912\n",
      "Epoch 2172/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1473e-04 - val_loss: 0.0920\n",
      "Epoch 2173/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9039e-04 - val_loss: 0.0921\n",
      "Epoch 2174/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9866e-04 - val_loss: 0.0919\n",
      "Epoch 2175/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.8667e-04 - val_loss: 0.0919\n",
      "Epoch 2176/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9407e-04 - val_loss: 0.0915\n",
      "Epoch 2177/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7906e-04 - val_loss: 0.0912\n",
      "Epoch 2178/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9329e-04 - val_loss: 0.0916\n",
      "Epoch 2179/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8361e-04 - val_loss: 0.0919\n",
      "Epoch 2180/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9720e-04 - val_loss: 0.0921\n",
      "Epoch 2181/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8391e-04 - val_loss: 0.0922\n",
      "Epoch 2182/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8016e-04 - val_loss: 0.0917\n",
      "Epoch 2183/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8185e-04 - val_loss: 0.0911\n",
      "Epoch 2184/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9236e-04 - val_loss: 0.0911\n",
      "Epoch 2185/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0465e-04 - val_loss: 0.0916\n",
      "Epoch 2186/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.7727e-04 - val_loss: 0.0924\n",
      "Epoch 2187/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7411e-04 - val_loss: 0.0928\n",
      "Epoch 2188/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9075e-04 - val_loss: 0.0925\n",
      "Epoch 2189/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8507e-04 - val_loss: 0.0914\n",
      "Epoch 2190/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9645e-04 - val_loss: 0.0909\n",
      "Epoch 2191/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1244e-04 - val_loss: 0.0913\n",
      "Epoch 2192/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0281e-04 - val_loss: 0.0920\n",
      "Epoch 2193/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0125e-04 - val_loss: 0.0920\n",
      "Epoch 2194/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9822e-04 - val_loss: 0.0917\n",
      "Epoch 2195/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.9569e-04 - val_loss: 0.0909\n",
      "Epoch 2196/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.9355e-04 - val_loss: 0.0904\n",
      "Epoch 2197/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 9.2716e-04 - val_loss: 0.0905\n",
      "Epoch 2198/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.9061e-04 - val_loss: 0.0911\n",
      "Epoch 2199/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.8059e-04 - val_loss: 0.0918\n",
      "Epoch 2200/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8694e-04 - val_loss: 0.0925\n",
      "Epoch 2201/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.9305e-04 - val_loss: 0.0922\n",
      "Epoch 2202/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0165e-04 - val_loss: 0.0917\n",
      "Epoch 2203/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9259e-04 - val_loss: 0.0913\n",
      "Epoch 2204/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9164e-04 - val_loss: 0.0916\n",
      "Epoch 2205/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.0225e-04 - val_loss: 0.0919\n",
      "Epoch 2206/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6885e-04 - val_loss: 0.0918\n",
      "Epoch 2207/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9696e-04 - val_loss: 0.0917\n",
      "Epoch 2208/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 9.0591e-04 - val_loss: 0.0913\n",
      "Epoch 2209/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.8929e-04 - val_loss: 0.0912\n",
      "Epoch 2210/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.8570e-04 - val_loss: 0.0911\n",
      "Epoch 2211/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.7920e-04 - val_loss: 0.0912\n",
      "Epoch 2212/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.8767e-04 - val_loss: 0.0914\n",
      "Epoch 2213/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7954e-04 - val_loss: 0.0915\n",
      "Epoch 2214/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7342e-04 - val_loss: 0.0913\n",
      "Epoch 2215/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.7364e-04 - val_loss: 0.0907\n",
      "Epoch 2216/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8627e-04 - val_loss: 0.0909\n",
      "Epoch 2217/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9226e-04 - val_loss: 0.0914\n",
      "Epoch 2218/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8634e-04 - val_loss: 0.0913\n",
      "Epoch 2219/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.7241e-04 - val_loss: 0.0915\n",
      "Epoch 2220/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7792e-04 - val_loss: 0.0913\n",
      "Epoch 2221/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8023e-04 - val_loss: 0.0910\n",
      "Epoch 2222/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7927e-04 - val_loss: 0.0904\n",
      "Epoch 2223/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8383e-04 - val_loss: 0.0907\n",
      "Epoch 2224/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.0540e-04 - val_loss: 0.0913\n",
      "Epoch 2225/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7487e-04 - val_loss: 0.0915\n",
      "Epoch 2226/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.7071e-04 - val_loss: 0.0913\n",
      "Epoch 2227/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8966e-04 - val_loss: 0.0908\n",
      "Epoch 2228/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7094e-04 - val_loss: 0.0905\n",
      "Epoch 2229/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7754e-04 - val_loss: 0.0906\n",
      "Epoch 2230/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8613e-04 - val_loss: 0.0911\n",
      "Epoch 2231/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8229e-04 - val_loss: 0.0919\n",
      "Epoch 2232/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7782e-04 - val_loss: 0.0922\n",
      "Epoch 2233/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8669e-04 - val_loss: 0.0922\n",
      "Epoch 2234/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8890e-04 - val_loss: 0.0912\n",
      "Epoch 2235/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7740e-04 - val_loss: 0.0904\n",
      "Epoch 2236/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8028e-04 - val_loss: 0.0903\n",
      "Epoch 2237/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9843e-04 - val_loss: 0.0910\n",
      "Epoch 2238/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9502e-04 - val_loss: 0.0918\n",
      "Epoch 2239/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8120e-04 - val_loss: 0.0920\n",
      "Epoch 2240/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9752e-04 - val_loss: 0.0912\n",
      "Epoch 2241/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6811e-04 - val_loss: 0.0905\n",
      "Epoch 2242/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0208e-04 - val_loss: 0.0904\n",
      "Epoch 2243/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9300e-04 - val_loss: 0.0909\n",
      "Epoch 2244/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1052e-04 - val_loss: 0.0917\n",
      "Epoch 2245/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7903e-04 - val_loss: 0.0920\n",
      "Epoch 2246/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8391e-04 - val_loss: 0.0919\n",
      "Epoch 2247/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8968e-04 - val_loss: 0.0913\n",
      "Epoch 2248/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9029e-04 - val_loss: 0.0905\n",
      "Epoch 2249/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8422e-04 - val_loss: 0.0902\n",
      "Epoch 2250/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8549e-04 - val_loss: 0.0906\n",
      "Epoch 2251/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9698e-04 - val_loss: 0.0920\n",
      "Epoch 2252/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9826e-04 - val_loss: 0.0923\n",
      "Epoch 2253/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8214e-04 - val_loss: 0.0917\n",
      "Epoch 2254/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7931e-04 - val_loss: 0.0911\n",
      "Epoch 2255/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7790e-04 - val_loss: 0.0910\n",
      "Epoch 2256/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0621e-04 - val_loss: 0.0910\n",
      "Epoch 2257/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9585e-04 - val_loss: 0.0912\n",
      "Epoch 2258/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8409e-04 - val_loss: 0.0914\n",
      "Epoch 2259/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8517e-04 - val_loss: 0.0917\n",
      "Epoch 2260/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8961e-04 - val_loss: 0.0920\n",
      "Epoch 2261/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1497e-04 - val_loss: 0.0913\n",
      "Epoch 2262/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9053e-04 - val_loss: 0.0914\n",
      "Epoch 2263/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2388e-04 - val_loss: 0.0922\n",
      "Epoch 2264/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.9676e-04 - val_loss: 0.0925\n",
      "Epoch 2265/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3104e-04 - val_loss: 0.0917\n",
      "Epoch 2266/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9607e-04 - val_loss: 0.0916\n",
      "Epoch 2267/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0385e-04 - val_loss: 0.0921\n",
      "Epoch 2268/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0950e-04 - val_loss: 0.0922\n",
      "Epoch 2269/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9788e-04 - val_loss: 0.0915\n",
      "Epoch 2270/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7361e-04 - val_loss: 0.0912\n",
      "Epoch 2271/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8288e-04 - val_loss: 0.0918\n",
      "Epoch 2272/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0502e-04 - val_loss: 0.0923\n",
      "Epoch 2273/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8014e-04 - val_loss: 0.0924\n",
      "Epoch 2274/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8732e-04 - val_loss: 0.0920\n",
      "Epoch 2275/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8847e-04 - val_loss: 0.0918\n",
      "Epoch 2276/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6963e-04 - val_loss: 0.0917\n",
      "Epoch 2277/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8657e-04 - val_loss: 0.0918\n",
      "Epoch 2278/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6704e-04 - val_loss: 0.0919\n",
      "Epoch 2279/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7528e-04 - val_loss: 0.0919\n",
      "Epoch 2280/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6331e-04 - val_loss: 0.0916\n",
      "Epoch 2281/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.6640e-04 - val_loss: 0.0914\n",
      "Epoch 2282/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7358e-04 - val_loss: 0.0916\n",
      "Epoch 2283/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7132e-04 - val_loss: 0.0920\n",
      "Epoch 2284/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9174e-04 - val_loss: 0.0919\n",
      "Epoch 2285/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7682e-04 - val_loss: 0.0917\n",
      "Epoch 2286/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6999e-04 - val_loss: 0.0916\n",
      "Epoch 2287/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.7999e-04 - val_loss: 0.0916\n",
      "Epoch 2288/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9297e-04 - val_loss: 0.0917\n",
      "Epoch 2289/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9127e-04 - val_loss: 0.0916\n",
      "Epoch 2290/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.7414e-04 - val_loss: 0.0911\n",
      "Epoch 2291/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8280e-04 - val_loss: 0.0913\n",
      "Epoch 2292/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8504e-04 - val_loss: 0.0916\n",
      "Epoch 2293/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8623e-04 - val_loss: 0.0917\n",
      "Epoch 2294/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8450e-04 - val_loss: 0.0911\n",
      "Epoch 2295/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8719e-04 - val_loss: 0.0909\n",
      "Epoch 2296/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7382e-04 - val_loss: 0.0911\n",
      "Epoch 2297/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7844e-04 - val_loss: 0.0910\n",
      "Epoch 2298/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7036e-04 - val_loss: 0.0912\n",
      "Epoch 2299/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8215e-04 - val_loss: 0.0914\n",
      "Epoch 2300/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8296e-04 - val_loss: 0.0914\n",
      "Epoch 2301/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7784e-04 - val_loss: 0.0917\n",
      "Epoch 2302/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6668e-04 - val_loss: 0.0915\n",
      "Epoch 2303/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7441e-04 - val_loss: 0.0914\n",
      "Epoch 2304/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8121e-04 - val_loss: 0.0916\n",
      "Epoch 2305/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8067e-04 - val_loss: 0.0913\n",
      "Epoch 2306/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7112e-04 - val_loss: 0.0908\n",
      "Epoch 2307/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 9.0782e-04 - val_loss: 0.0911\n",
      "Epoch 2308/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7778e-04 - val_loss: 0.0917\n",
      "Epoch 2309/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8571e-04 - val_loss: 0.0915\n",
      "Epoch 2310/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9045e-04 - val_loss: 0.0911\n",
      "Epoch 2311/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6441e-04 - val_loss: 0.0914\n",
      "Epoch 2312/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6964e-04 - val_loss: 0.0919\n",
      "Epoch 2313/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8179e-04 - val_loss: 0.0922\n",
      "Epoch 2314/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6596e-04 - val_loss: 0.0917\n",
      "Epoch 2315/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8123e-04 - val_loss: 0.0915\n",
      "Epoch 2316/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8004e-04 - val_loss: 0.0915\n",
      "Epoch 2317/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8971e-04 - val_loss: 0.0916\n",
      "Epoch 2318/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7744e-04 - val_loss: 0.0914\n",
      "Epoch 2319/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1379e-04 - val_loss: 0.0915\n",
      "Epoch 2320/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8412e-04 - val_loss: 0.0920\n",
      "Epoch 2321/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9531e-04 - val_loss: 0.0920\n",
      "Epoch 2322/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9346e-04 - val_loss: 0.0920\n",
      "Epoch 2323/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1914e-04 - val_loss: 0.0925\n",
      "Epoch 2324/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7805e-04 - val_loss: 0.0927\n",
      "Epoch 2325/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0661e-04 - val_loss: 0.0923\n",
      "Epoch 2326/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1437e-04 - val_loss: 0.0924\n",
      "Epoch 2327/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7341e-04 - val_loss: 0.0926\n",
      "Epoch 2328/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0219e-04 - val_loss: 0.0918\n",
      "Epoch 2329/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7618e-04 - val_loss: 0.0915\n",
      "Epoch 2330/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8195e-04 - val_loss: 0.0917\n",
      "Epoch 2331/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7864e-04 - val_loss: 0.0920\n",
      "Epoch 2332/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9292e-04 - val_loss: 0.0917\n",
      "Epoch 2333/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8901e-04 - val_loss: 0.0915\n",
      "Epoch 2334/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7111e-04 - val_loss: 0.0916\n",
      "Epoch 2335/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0264e-04 - val_loss: 0.0913\n",
      "Epoch 2336/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8058e-04 - val_loss: 0.0912\n",
      "Epoch 2337/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8047e-04 - val_loss: 0.0915\n",
      "Epoch 2338/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8667e-04 - val_loss: 0.0912\n",
      "Epoch 2339/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8340e-04 - val_loss: 0.0908\n",
      "Epoch 2340/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8221e-04 - val_loss: 0.0910\n",
      "Epoch 2341/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9238e-04 - val_loss: 0.0915\n",
      "Epoch 2342/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 8.7987e-04 - val_loss: 0.0920\n",
      "Epoch 2343/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7867e-04 - val_loss: 0.0918\n",
      "Epoch 2344/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7090e-04 - val_loss: 0.0915\n",
      "Epoch 2345/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6287e-04 - val_loss: 0.0909\n",
      "Epoch 2346/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7084e-04 - val_loss: 0.0905\n",
      "Epoch 2347/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7042e-04 - val_loss: 0.0905\n",
      "Epoch 2348/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7498e-04 - val_loss: 0.0912\n",
      "Epoch 2349/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6510e-04 - val_loss: 0.0920\n",
      "Epoch 2350/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8901e-04 - val_loss: 0.0919\n",
      "Epoch 2351/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8551e-04 - val_loss: 0.0913\n",
      "Epoch 2352/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7811e-04 - val_loss: 0.0906\n",
      "Epoch 2353/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8277e-04 - val_loss: 0.0907\n",
      "Epoch 2354/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7317e-04 - val_loss: 0.0910\n",
      "Epoch 2355/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8681e-04 - val_loss: 0.0918\n",
      "Epoch 2356/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7057e-04 - val_loss: 0.0921\n",
      "Epoch 2357/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8180e-04 - val_loss: 0.0916\n",
      "Epoch 2358/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7803e-04 - val_loss: 0.0910\n",
      "Epoch 2359/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6738e-04 - val_loss: 0.0907\n",
      "Epoch 2360/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6495e-04 - val_loss: 0.0912\n",
      "Epoch 2361/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7320e-04 - val_loss: 0.0914\n",
      "Epoch 2362/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6174e-04 - val_loss: 0.0912\n",
      "Epoch 2363/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6688e-04 - val_loss: 0.0912\n",
      "Epoch 2364/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7686e-04 - val_loss: 0.0910\n",
      "Epoch 2365/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6252e-04 - val_loss: 0.0909\n",
      "Epoch 2366/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5924e-04 - val_loss: 0.0908\n",
      "Epoch 2367/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6977e-04 - val_loss: 0.0907\n",
      "Epoch 2368/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7741e-04 - val_loss: 0.0906\n",
      "Epoch 2369/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7832e-04 - val_loss: 0.0908\n",
      "Epoch 2370/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7903e-04 - val_loss: 0.0909\n",
      "Epoch 2371/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.7268e-04 - val_loss: 0.0910\n",
      "Epoch 2372/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7201e-04 - val_loss: 0.0911\n",
      "Epoch 2373/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7692e-04 - val_loss: 0.0911\n",
      "Epoch 2374/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6793e-04 - val_loss: 0.0913\n",
      "Epoch 2375/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7589e-04 - val_loss: 0.0911\n",
      "Epoch 2376/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9629e-04 - val_loss: 0.0904\n",
      "Epoch 2377/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.9507e-04 - val_loss: 0.0904\n",
      "Epoch 2378/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9520e-04 - val_loss: 0.0912\n",
      "Epoch 2379/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0927e-04 - val_loss: 0.0907\n",
      "Epoch 2380/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7329e-04 - val_loss: 0.0902\n",
      "Epoch 2381/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8470e-04 - val_loss: 0.0902\n",
      "Epoch 2382/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9031e-04 - val_loss: 0.0904\n",
      "Epoch 2383/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9712e-04 - val_loss: 0.0906\n",
      "Epoch 2384/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6461e-04 - val_loss: 0.0905\n",
      "Epoch 2385/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7738e-04 - val_loss: 0.0906\n",
      "Epoch 2386/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7905e-04 - val_loss: 0.0908\n",
      "Epoch 2387/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.0521e-04 - val_loss: 0.0904\n",
      "Epoch 2388/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7704e-04 - val_loss: 0.0901\n",
      "Epoch 2389/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9175e-04 - val_loss: 0.0902\n",
      "Epoch 2390/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6241e-04 - val_loss: 0.0902\n",
      "Epoch 2391/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0229e-04 - val_loss: 0.0900\n",
      "Epoch 2392/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8886e-04 - val_loss: 0.0897\n",
      "Epoch 2393/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9196e-04 - val_loss: 0.0902\n",
      "Epoch 2394/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9404e-04 - val_loss: 0.0910\n",
      "Epoch 2395/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8958e-04 - val_loss: 0.0909\n",
      "Epoch 2396/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0257e-04 - val_loss: 0.0896\n",
      "Epoch 2397/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.3479e-04 - val_loss: 0.0895\n",
      "Epoch 2398/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8787e-04 - val_loss: 0.0901\n",
      "Epoch 2399/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1526e-04 - val_loss: 0.0901\n",
      "Epoch 2400/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7715e-04 - val_loss: 0.0899\n",
      "Epoch 2401/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0036e-04 - val_loss: 0.0906\n",
      "Epoch 2402/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7640e-04 - val_loss: 0.0908\n",
      "Epoch 2403/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4621e-04 - val_loss: 0.0898\n",
      "Epoch 2404/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.2704e-04 - val_loss: 0.0895\n",
      "Epoch 2405/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0478e-04 - val_loss: 0.0903\n",
      "Epoch 2406/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8960e-04 - val_loss: 0.0906\n",
      "Epoch 2407/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9108e-04 - val_loss: 0.0906\n",
      "Epoch 2408/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9153e-04 - val_loss: 0.0909\n",
      "Epoch 2409/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.9456e-04 - val_loss: 0.0909\n",
      "Epoch 2410/3000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 8.8628e-04 - val_loss: 0.0903\n",
      "Epoch 2411/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 8.8969e-04 - val_loss: 0.0896\n",
      "Epoch 2412/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 9.1382e-04 - val_loss: 0.0903\n",
      "Epoch 2413/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 8.8190e-04 - val_loss: 0.0908\n",
      "Epoch 2414/3000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 8.7408e-04 - val_loss: 0.0908\n",
      "Epoch 2415/3000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 8.7432e-04 - val_loss: 0.0905\n",
      "Epoch 2416/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.8811e-04 - val_loss: 0.0899\n",
      "Epoch 2417/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7442e-04 - val_loss: 0.0899\n",
      "Epoch 2418/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.8318e-04 - val_loss: 0.0895\n",
      "Epoch 2419/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8791e-04 - val_loss: 0.0899\n",
      "Epoch 2420/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9941e-04 - val_loss: 0.0910\n",
      "Epoch 2421/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.5953e-04 - val_loss: 0.0916\n",
      "Epoch 2422/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9357e-04 - val_loss: 0.0910\n",
      "Epoch 2423/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7754e-04 - val_loss: 0.0904\n",
      "Epoch 2424/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7230e-04 - val_loss: 0.0899\n",
      "Epoch 2425/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8385e-04 - val_loss: 0.0901\n",
      "Epoch 2426/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.8754e-04 - val_loss: 0.0907\n",
      "Epoch 2427/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6059e-04 - val_loss: 0.0913\n",
      "Epoch 2428/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6476e-04 - val_loss: 0.0914\n",
      "Epoch 2429/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.7605e-04 - val_loss: 0.0911\n",
      "Epoch 2430/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6939e-04 - val_loss: 0.0909\n",
      "Epoch 2431/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.7542e-04 - val_loss: 0.0904\n",
      "Epoch 2432/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.6973e-04 - val_loss: 0.0901\n",
      "Epoch 2433/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6871e-04 - val_loss: 0.0904\n",
      "Epoch 2434/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6201e-04 - val_loss: 0.0910\n",
      "Epoch 2435/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.0844e-04 - val_loss: 0.0906\n",
      "Epoch 2436/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7236e-04 - val_loss: 0.0902\n",
      "Epoch 2437/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8382e-04 - val_loss: 0.0904\n",
      "Epoch 2438/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8714e-04 - val_loss: 0.0908\n",
      "Epoch 2439/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9135e-04 - val_loss: 0.0909\n",
      "Epoch 2440/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.6441e-04 - val_loss: 0.0909\n",
      "Epoch 2441/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8248e-04 - val_loss: 0.0908\n",
      "Epoch 2442/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 8.8857e-04 - val_loss: 0.0904\n",
      "Epoch 2443/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.7945e-04 - val_loss: 0.0905\n",
      "Epoch 2444/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.9188e-04 - val_loss: 0.0910\n",
      "Epoch 2445/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8006e-04 - val_loss: 0.0911\n",
      "Epoch 2446/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.7788e-04 - val_loss: 0.0905\n",
      "Epoch 2447/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8311e-04 - val_loss: 0.0903\n",
      "Epoch 2448/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.0577e-04 - val_loss: 0.0908\n",
      "Epoch 2449/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.7039e-04 - val_loss: 0.0912\n",
      "Epoch 2450/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0256e-04 - val_loss: 0.0907\n",
      "Epoch 2451/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.8348e-04 - val_loss: 0.0908\n",
      "Epoch 2452/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0503e-04 - val_loss: 0.0914\n",
      "Epoch 2453/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7990e-04 - val_loss: 0.0913\n",
      "Epoch 2454/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9672e-04 - val_loss: 0.0905\n",
      "Epoch 2455/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.7887e-04 - val_loss: 0.0905\n",
      "Epoch 2456/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7809e-04 - val_loss: 0.0912\n",
      "Epoch 2457/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7030e-04 - val_loss: 0.0917\n",
      "Epoch 2458/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8769e-04 - val_loss: 0.0915\n",
      "Epoch 2459/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8177e-04 - val_loss: 0.0911\n",
      "Epoch 2460/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.0058e-04 - val_loss: 0.0909\n",
      "Epoch 2461/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.2337e-04 - val_loss: 0.0905\n",
      "Epoch 2462/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.7913e-04 - val_loss: 0.0906\n",
      "Epoch 2463/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9132e-04 - val_loss: 0.0912\n",
      "Epoch 2464/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7981e-04 - val_loss: 0.0914\n",
      "Epoch 2465/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7079e-04 - val_loss: 0.0911\n",
      "Epoch 2466/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 9.0165e-04 - val_loss: 0.0910\n",
      "Epoch 2467/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7067e-04 - val_loss: 0.0909\n",
      "Epoch 2468/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.2054e-04 - val_loss: 0.0910\n",
      "Epoch 2469/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9545e-04 - val_loss: 0.0909\n",
      "Epoch 2470/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8008e-04 - val_loss: 0.0910\n",
      "Epoch 2471/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0529e-04 - val_loss: 0.0912\n",
      "Epoch 2472/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6810e-04 - val_loss: 0.0911\n",
      "Epoch 2473/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 8.8513e-04 - val_loss: 0.0913\n",
      "Epoch 2474/3000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 8.8660e-04 - val_loss: 0.0913\n",
      "Epoch 2475/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 8.7973e-04 - val_loss: 0.0915\n",
      "Epoch 2476/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6712e-04 - val_loss: 0.0914\n",
      "Epoch 2477/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.7325e-04 - val_loss: 0.0914\n",
      "Epoch 2478/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.8469e-04 - val_loss: 0.0917\n",
      "Epoch 2479/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.7808e-04 - val_loss: 0.0920\n",
      "Epoch 2480/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8238e-04 - val_loss: 0.0915\n",
      "Epoch 2481/3000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 8.8146e-04 - val_loss: 0.0911\n",
      "Epoch 2482/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.6321e-04 - val_loss: 0.0904\n",
      "Epoch 2483/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.7550e-04 - val_loss: 0.0902\n",
      "Epoch 2484/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.8924e-04 - val_loss: 0.0903\n",
      "Epoch 2485/3000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 8.6921e-04 - val_loss: 0.0907\n",
      "Epoch 2486/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9322e-04 - val_loss: 0.0912\n",
      "Epoch 2487/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9322e-04 - val_loss: 0.0909\n",
      "Epoch 2488/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 8.8079e-04 - val_loss: 0.0909\n",
      "Epoch 2489/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7589e-04 - val_loss: 0.0913\n",
      "Epoch 2490/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.8883e-04 - val_loss: 0.0914\n",
      "Epoch 2491/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7101e-04 - val_loss: 0.0915\n",
      "Epoch 2492/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7214e-04 - val_loss: 0.0915\n",
      "Epoch 2493/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8453e-04 - val_loss: 0.0912\n",
      "Epoch 2494/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6225e-04 - val_loss: 0.0910\n",
      "Epoch 2495/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7852e-04 - val_loss: 0.0907\n",
      "Epoch 2496/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6858e-04 - val_loss: 0.0908\n",
      "Epoch 2497/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7216e-04 - val_loss: 0.0911\n",
      "Epoch 2498/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6674e-04 - val_loss: 0.0911\n",
      "Epoch 2499/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7820e-04 - val_loss: 0.0911\n",
      "Epoch 2500/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5851e-04 - val_loss: 0.0912\n",
      "Epoch 2501/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9061e-04 - val_loss: 0.0918\n",
      "Epoch 2502/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6495e-04 - val_loss: 0.0917\n",
      "Epoch 2503/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.8805e-04 - val_loss: 0.0905\n",
      "Epoch 2504/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9864e-04 - val_loss: 0.0908\n",
      "Epoch 2505/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7156e-04 - val_loss: 0.0917\n",
      "Epoch 2506/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1944e-04 - val_loss: 0.0916\n",
      "Epoch 2507/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8510e-04 - val_loss: 0.0914\n",
      "Epoch 2508/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8546e-04 - val_loss: 0.0918\n",
      "Epoch 2509/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9503e-04 - val_loss: 0.0917\n",
      "Epoch 2510/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0255e-04 - val_loss: 0.0908\n",
      "Epoch 2511/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9196e-04 - val_loss: 0.0908\n",
      "Epoch 2512/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9859e-04 - val_loss: 0.0913\n",
      "Epoch 2513/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7126e-04 - val_loss: 0.0921\n",
      "Epoch 2514/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.4212e-04 - val_loss: 0.0910\n",
      "Epoch 2515/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6434e-04 - val_loss: 0.0906\n",
      "Epoch 2516/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9153e-04 - val_loss: 0.0912\n",
      "Epoch 2517/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7582e-04 - val_loss: 0.0915\n",
      "Epoch 2518/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8017e-04 - val_loss: 0.0913\n",
      "Epoch 2519/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9699e-04 - val_loss: 0.0918\n",
      "Epoch 2520/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9406e-04 - val_loss: 0.0926\n",
      "Epoch 2521/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6812e-04 - val_loss: 0.0928\n",
      "Epoch 2522/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.8147e-04 - val_loss: 0.0925\n",
      "Epoch 2523/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9707e-04 - val_loss: 0.0919\n",
      "Epoch 2524/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8114e-04 - val_loss: 0.0916\n",
      "Epoch 2525/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9292e-04 - val_loss: 0.0917\n",
      "Epoch 2526/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8137e-04 - val_loss: 0.0921\n",
      "Epoch 2527/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0254e-04 - val_loss: 0.0921\n",
      "Epoch 2528/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9827e-04 - val_loss: 0.0919\n",
      "Epoch 2529/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0160e-04 - val_loss: 0.0914\n",
      "Epoch 2530/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0721e-04 - val_loss: 0.0905\n",
      "Epoch 2531/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8779e-04 - val_loss: 0.0902\n",
      "Epoch 2532/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.9256e-04 - val_loss: 0.0909\n",
      "Epoch 2533/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8690e-04 - val_loss: 0.0920\n",
      "Epoch 2534/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8369e-04 - val_loss: 0.0921\n",
      "Epoch 2535/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0560e-04 - val_loss: 0.0909\n",
      "Epoch 2536/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0068e-04 - val_loss: 0.0902\n",
      "Epoch 2537/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8418e-04 - val_loss: 0.0901\n",
      "Epoch 2538/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8017e-04 - val_loss: 0.0904\n",
      "Epoch 2539/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0722e-04 - val_loss: 0.0902\n",
      "Epoch 2540/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7108e-04 - val_loss: 0.0903\n",
      "Epoch 2541/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9225e-04 - val_loss: 0.0908\n",
      "Epoch 2542/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8999e-04 - val_loss: 0.0907\n",
      "Epoch 2543/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7722e-04 - val_loss: 0.0903\n",
      "Epoch 2544/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7314e-04 - val_loss: 0.0900\n",
      "Epoch 2545/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9221e-04 - val_loss: 0.0902\n",
      "Epoch 2546/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7426e-04 - val_loss: 0.0905\n",
      "Epoch 2547/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 9.1633e-04 - val_loss: 0.0903\n",
      "Epoch 2548/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7125e-04 - val_loss: 0.0901\n",
      "Epoch 2549/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9054e-04 - val_loss: 0.0905\n",
      "Epoch 2550/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8499e-04 - val_loss: 0.0906\n",
      "Epoch 2551/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8214e-04 - val_loss: 0.0901\n",
      "Epoch 2552/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8693e-04 - val_loss: 0.0904\n",
      "Epoch 2553/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7540e-04 - val_loss: 0.0907\n",
      "Epoch 2554/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9026e-04 - val_loss: 0.0902\n",
      "Epoch 2555/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8408e-04 - val_loss: 0.0894\n",
      "Epoch 2556/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9190e-04 - val_loss: 0.0896\n",
      "Epoch 2557/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9454e-04 - val_loss: 0.0902\n",
      "Epoch 2558/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0008e-04 - val_loss: 0.0900\n",
      "Epoch 2559/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0065e-04 - val_loss: 0.0897\n",
      "Epoch 2560/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8774e-04 - val_loss: 0.0895\n",
      "Epoch 2561/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9902e-04 - val_loss: 0.0894\n",
      "Epoch 2562/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.1804e-04 - val_loss: 0.0898\n",
      "Epoch 2563/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9539e-04 - val_loss: 0.0903\n",
      "Epoch 2564/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0875e-04 - val_loss: 0.0902\n",
      "Epoch 2565/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6879e-04 - val_loss: 0.0897\n",
      "Epoch 2566/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.9254e-04 - val_loss: 0.0896\n",
      "Epoch 2567/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8417e-04 - val_loss: 0.0897\n",
      "Epoch 2568/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7580e-04 - val_loss: 0.0901\n",
      "Epoch 2569/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6863e-04 - val_loss: 0.0902\n",
      "Epoch 2570/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.8049e-04 - val_loss: 0.0902\n",
      "Epoch 2571/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7175e-04 - val_loss: 0.0895\n",
      "Epoch 2572/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0015e-04 - val_loss: 0.0892\n",
      "Epoch 2573/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1203e-04 - val_loss: 0.0900\n",
      "Epoch 2574/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6566e-04 - val_loss: 0.0910\n",
      "Epoch 2575/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0025e-04 - val_loss: 0.0904\n",
      "Epoch 2576/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8207e-04 - val_loss: 0.0898\n",
      "Epoch 2577/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8141e-04 - val_loss: 0.0903\n",
      "Epoch 2578/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6440e-04 - val_loss: 0.0905\n",
      "Epoch 2579/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0487e-04 - val_loss: 0.0905\n",
      "Epoch 2580/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6358e-04 - val_loss: 0.0908\n",
      "Epoch 2581/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0766e-04 - val_loss: 0.0914\n",
      "Epoch 2582/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9931e-04 - val_loss: 0.0906\n",
      "Epoch 2583/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9568e-04 - val_loss: 0.0895\n",
      "Epoch 2584/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.3021e-04 - val_loss: 0.0896\n",
      "Epoch 2585/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0426e-04 - val_loss: 0.0906\n",
      "Epoch 2586/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1013e-04 - val_loss: 0.0909\n",
      "Epoch 2587/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9944e-04 - val_loss: 0.0902\n",
      "Epoch 2588/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0214e-04 - val_loss: 0.0898\n",
      "Epoch 2589/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1449e-04 - val_loss: 0.0900\n",
      "Epoch 2590/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9757e-04 - val_loss: 0.0902\n",
      "Epoch 2591/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1316e-04 - val_loss: 0.0904\n",
      "Epoch 2592/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9058e-04 - val_loss: 0.0905\n",
      "Epoch 2593/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0684e-04 - val_loss: 0.0900\n",
      "Epoch 2594/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8213e-04 - val_loss: 0.0897\n",
      "Epoch 2595/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9692e-04 - val_loss: 0.0900\n",
      "Epoch 2596/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9260e-04 - val_loss: 0.0908\n",
      "Epoch 2597/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0126e-04 - val_loss: 0.0910\n",
      "Epoch 2598/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8239e-04 - val_loss: 0.0906\n",
      "Epoch 2599/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9818e-04 - val_loss: 0.0904\n",
      "Epoch 2600/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.6837e-04 - val_loss: 0.0899\n",
      "Epoch 2601/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6238e-04 - val_loss: 0.0897\n",
      "Epoch 2602/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0139e-04 - val_loss: 0.0905\n",
      "Epoch 2603/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7940e-04 - val_loss: 0.0908\n",
      "Epoch 2604/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8373e-04 - val_loss: 0.0904\n",
      "Epoch 2605/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6947e-04 - val_loss: 0.0906\n",
      "Epoch 2606/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.8487e-04 - val_loss: 0.0913\n",
      "Epoch 2607/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7688e-04 - val_loss: 0.0918\n",
      "Epoch 2608/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0448e-04 - val_loss: 0.0911\n",
      "Epoch 2609/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6595e-04 - val_loss: 0.0906\n",
      "Epoch 2610/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8229e-04 - val_loss: 0.0908\n",
      "Epoch 2611/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9636e-04 - val_loss: 0.0909\n",
      "Epoch 2612/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7059e-04 - val_loss: 0.0911\n",
      "Epoch 2613/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7257e-04 - val_loss: 0.0917\n",
      "Epoch 2614/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7143e-04 - val_loss: 0.0916\n",
      "Epoch 2615/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7547e-04 - val_loss: 0.0910\n",
      "Epoch 2616/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7093e-04 - val_loss: 0.0906\n",
      "Epoch 2617/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8894e-04 - val_loss: 0.0912\n",
      "Epoch 2618/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8076e-04 - val_loss: 0.0912\n",
      "Epoch 2619/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8308e-04 - val_loss: 0.0911\n",
      "Epoch 2620/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1560e-04 - val_loss: 0.0914\n",
      "Epoch 2621/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7165e-04 - val_loss: 0.0918\n",
      "Epoch 2622/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.1317e-04 - val_loss: 0.0910\n",
      "Epoch 2623/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8358e-04 - val_loss: 0.0909\n",
      "Epoch 2624/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9710e-04 - val_loss: 0.0916\n",
      "Epoch 2625/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8116e-04 - val_loss: 0.0918\n",
      "Epoch 2626/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7447e-04 - val_loss: 0.0910\n",
      "Epoch 2627/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7499e-04 - val_loss: 0.0909\n",
      "Epoch 2628/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6985e-04 - val_loss: 0.0909\n",
      "Epoch 2629/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.9662e-04 - val_loss: 0.0913\n",
      "Epoch 2630/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7617e-04 - val_loss: 0.0910\n",
      "Epoch 2631/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6899e-04 - val_loss: 0.0908\n",
      "Epoch 2632/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7819e-04 - val_loss: 0.0908\n",
      "Epoch 2633/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6764e-04 - val_loss: 0.0910\n",
      "Epoch 2634/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8613e-04 - val_loss: 0.0912\n",
      "Epoch 2635/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6449e-04 - val_loss: 0.0913\n",
      "Epoch 2636/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7957e-04 - val_loss: 0.0914\n",
      "Epoch 2637/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7543e-04 - val_loss: 0.0907\n",
      "Epoch 2638/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6940e-04 - val_loss: 0.0902\n",
      "Epoch 2639/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9062e-04 - val_loss: 0.0910\n",
      "Epoch 2640/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6713e-04 - val_loss: 0.0914\n",
      "Epoch 2641/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.6664e-04 - val_loss: 0.0913\n",
      "Epoch 2642/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6771e-04 - val_loss: 0.0910\n",
      "Epoch 2643/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8160e-04 - val_loss: 0.0908\n",
      "Epoch 2644/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6907e-04 - val_loss: 0.0906\n",
      "Epoch 2645/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8471e-04 - val_loss: 0.0908\n",
      "Epoch 2646/3000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 8.7164e-04 - val_loss: 0.0907\n",
      "Epoch 2647/3000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 8.7418e-04 - val_loss: 0.0907\n",
      "Epoch 2648/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.6825e-04 - val_loss: 0.0907\n",
      "Epoch 2649/3000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 8.6847e-04 - val_loss: 0.0906\n",
      "Epoch 2650/3000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 8.7427e-04 - val_loss: 0.0908\n",
      "Epoch 2651/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.6866e-04 - val_loss: 0.0909\n",
      "Epoch 2652/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.7436e-04 - val_loss: 0.0906\n",
      "Epoch 2653/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.6134e-04 - val_loss: 0.0907\n",
      "Epoch 2654/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.7244e-04 - val_loss: 0.0908\n",
      "Epoch 2655/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.5447e-04 - val_loss: 0.0908\n",
      "Epoch 2656/3000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 8.6135e-04 - val_loss: 0.0907\n",
      "Epoch 2657/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.6092e-04 - val_loss: 0.0908\n",
      "Epoch 2658/3000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 8.5258e-04 - val_loss: 0.0908\n",
      "Epoch 2659/3000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 8.6656e-04 - val_loss: 0.0911\n",
      "Epoch 2660/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.7542e-04 - val_loss: 0.0912\n",
      "Epoch 2661/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8376e-04 - val_loss: 0.0908\n",
      "Epoch 2662/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.6211e-04 - val_loss: 0.0902\n",
      "Epoch 2663/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.6289e-04 - val_loss: 0.0899\n",
      "Epoch 2664/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7746e-04 - val_loss: 0.0899\n",
      "Epoch 2665/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8255e-04 - val_loss: 0.0897\n",
      "Epoch 2666/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7142e-04 - val_loss: 0.0905\n",
      "Epoch 2667/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6096e-04 - val_loss: 0.0913\n",
      "Epoch 2668/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7014e-04 - val_loss: 0.0912\n",
      "Epoch 2669/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.5533e-04 - val_loss: 0.0910\n",
      "Epoch 2670/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5743e-04 - val_loss: 0.0909\n",
      "Epoch 2671/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8885e-04 - val_loss: 0.0909\n",
      "Epoch 2672/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.5740e-04 - val_loss: 0.0909\n",
      "Epoch 2673/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8535e-04 - val_loss: 0.0912\n",
      "Epoch 2674/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5866e-04 - val_loss: 0.0912\n",
      "Epoch 2675/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7308e-04 - val_loss: 0.0905\n",
      "Epoch 2676/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6459e-04 - val_loss: 0.0899\n",
      "Epoch 2677/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.5993e-04 - val_loss: 0.0901\n",
      "Epoch 2678/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6186e-04 - val_loss: 0.0910\n",
      "Epoch 2679/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7818e-04 - val_loss: 0.0911\n",
      "Epoch 2680/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7127e-04 - val_loss: 0.0908\n",
      "Epoch 2681/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6251e-04 - val_loss: 0.0907\n",
      "Epoch 2682/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5982e-04 - val_loss: 0.0904\n",
      "Epoch 2683/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9192e-04 - val_loss: 0.0907\n",
      "Epoch 2684/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6592e-04 - val_loss: 0.0911\n",
      "Epoch 2685/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7701e-04 - val_loss: 0.0911\n",
      "Epoch 2686/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8864e-04 - val_loss: 0.0909\n",
      "Epoch 2687/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7171e-04 - val_loss: 0.0902\n",
      "Epoch 2688/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8183e-04 - val_loss: 0.0899\n",
      "Epoch 2689/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6967e-04 - val_loss: 0.0907\n",
      "Epoch 2690/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8683e-04 - val_loss: 0.0909\n",
      "Epoch 2691/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6643e-04 - val_loss: 0.0903\n",
      "Epoch 2692/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9122e-04 - val_loss: 0.0900\n",
      "Epoch 2693/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7844e-04 - val_loss: 0.0903\n",
      "Epoch 2694/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9444e-04 - val_loss: 0.0907\n",
      "Epoch 2695/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.6947e-04 - val_loss: 0.0910\n",
      "Epoch 2696/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7463e-04 - val_loss: 0.0912\n",
      "Epoch 2697/3000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 8.6390e-04 - val_loss: 0.0907\n",
      "Epoch 2698/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.8308e-04 - val_loss: 0.0901\n",
      "Epoch 2699/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.7696e-04 - val_loss: 0.0904\n",
      "Epoch 2700/3000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.8416e-04 - val_loss: 0.0916\n",
      "Epoch 2701/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9521e-04 - val_loss: 0.0916\n",
      "Epoch 2702/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7243e-04 - val_loss: 0.0910\n",
      "Epoch 2703/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9209e-04 - val_loss: 0.0909\n",
      "Epoch 2704/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7728e-04 - val_loss: 0.0904\n",
      "Epoch 2705/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.8164e-04 - val_loss: 0.0897\n",
      "Epoch 2706/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0753e-04 - val_loss: 0.0906\n",
      "Epoch 2707/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7533e-04 - val_loss: 0.0913\n",
      "Epoch 2708/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9405e-04 - val_loss: 0.0906\n",
      "Epoch 2709/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7053e-04 - val_loss: 0.0898\n",
      "Epoch 2710/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8964e-04 - val_loss: 0.0896\n",
      "Epoch 2711/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7511e-04 - val_loss: 0.0900\n",
      "Epoch 2712/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7974e-04 - val_loss: 0.0899\n",
      "Epoch 2713/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7840e-04 - val_loss: 0.0903\n",
      "Epoch 2714/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7498e-04 - val_loss: 0.0908\n",
      "Epoch 2715/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8986e-04 - val_loss: 0.0903\n",
      "Epoch 2716/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6721e-04 - val_loss: 0.0898\n",
      "Epoch 2717/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9038e-04 - val_loss: 0.0901\n",
      "Epoch 2718/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7511e-04 - val_loss: 0.0904\n",
      "Epoch 2719/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8843e-04 - val_loss: 0.0902\n",
      "Epoch 2720/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9063e-04 - val_loss: 0.0902\n",
      "Epoch 2721/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6165e-04 - val_loss: 0.0905\n",
      "Epoch 2722/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9156e-04 - val_loss: 0.0907\n",
      "Epoch 2723/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8783e-04 - val_loss: 0.0911\n",
      "Epoch 2724/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7501e-04 - val_loss: 0.0908\n",
      "Epoch 2725/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0155e-04 - val_loss: 0.0899\n",
      "Epoch 2726/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8799e-04 - val_loss: 0.0895\n",
      "Epoch 2727/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1494e-04 - val_loss: 0.0896\n",
      "Epoch 2728/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9408e-04 - val_loss: 0.0904\n",
      "Epoch 2729/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6970e-04 - val_loss: 0.0911\n",
      "Epoch 2730/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.1610e-04 - val_loss: 0.0904\n",
      "Epoch 2731/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6589e-04 - val_loss: 0.0893\n",
      "Epoch 2732/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0695e-04 - val_loss: 0.0893\n",
      "Epoch 2733/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.6895e-04 - val_loss: 0.0898\n",
      "Epoch 2734/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8346e-04 - val_loss: 0.0902\n",
      "Epoch 2735/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.5892e-04 - val_loss: 0.0901\n",
      "Epoch 2736/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7407e-04 - val_loss: 0.0899\n",
      "Epoch 2737/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6362e-04 - val_loss: 0.0899\n",
      "Epoch 2738/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7453e-04 - val_loss: 0.0899\n",
      "Epoch 2739/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6621e-04 - val_loss: 0.0902\n",
      "Epoch 2740/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6998e-04 - val_loss: 0.0903\n",
      "Epoch 2741/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7803e-04 - val_loss: 0.0900\n",
      "Epoch 2742/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8479e-04 - val_loss: 0.0897\n",
      "Epoch 2743/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6945e-04 - val_loss: 0.0899\n",
      "Epoch 2744/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7412e-04 - val_loss: 0.0906\n",
      "Epoch 2745/3000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 8.8456e-04 - val_loss: 0.0910\n",
      "Epoch 2746/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7284e-04 - val_loss: 0.0905\n",
      "Epoch 2747/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7657e-04 - val_loss: 0.0897\n",
      "Epoch 2748/3000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 8.7191e-04 - val_loss: 0.0893\n",
      "Epoch 2749/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7211e-04 - val_loss: 0.0895\n",
      "Epoch 2750/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6394e-04 - val_loss: 0.0900\n",
      "Epoch 2751/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7698e-04 - val_loss: 0.0904\n",
      "Epoch 2752/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.7347e-04 - val_loss: 0.0901\n",
      "Epoch 2753/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7476e-04 - val_loss: 0.0895\n",
      "Epoch 2754/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7021e-04 - val_loss: 0.0892\n",
      "Epoch 2755/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7620e-04 - val_loss: 0.0897\n",
      "Epoch 2756/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7995e-04 - val_loss: 0.0902\n",
      "Epoch 2757/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8063e-04 - val_loss: 0.0907\n",
      "Epoch 2758/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0340e-04 - val_loss: 0.0903\n",
      "Epoch 2759/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7183e-04 - val_loss: 0.0894\n",
      "Epoch 2760/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8926e-04 - val_loss: 0.0892\n",
      "Epoch 2761/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8251e-04 - val_loss: 0.0898\n",
      "Epoch 2762/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9788e-04 - val_loss: 0.0904\n",
      "Epoch 2763/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8221e-04 - val_loss: 0.0902\n",
      "Epoch 2764/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9447e-04 - val_loss: 0.0892\n",
      "Epoch 2765/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6649e-04 - val_loss: 0.0886\n",
      "Epoch 2766/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9701e-04 - val_loss: 0.0887\n",
      "Epoch 2767/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7027e-04 - val_loss: 0.0894\n",
      "Epoch 2768/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8080e-04 - val_loss: 0.0896\n",
      "Epoch 2769/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9622e-04 - val_loss: 0.0891\n",
      "Epoch 2770/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7462e-04 - val_loss: 0.0888\n",
      "Epoch 2771/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0918e-04 - val_loss: 0.0898\n",
      "Epoch 2772/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7770e-04 - val_loss: 0.0900\n",
      "Epoch 2773/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6962e-04 - val_loss: 0.0893\n",
      "Epoch 2774/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7316e-04 - val_loss: 0.0891\n",
      "Epoch 2775/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5233e-04 - val_loss: 0.0891\n",
      "Epoch 2776/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8044e-04 - val_loss: 0.0889\n",
      "Epoch 2777/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5462e-04 - val_loss: 0.0892\n",
      "Epoch 2778/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9091e-04 - val_loss: 0.0897\n",
      "Epoch 2779/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7284e-04 - val_loss: 0.0895\n",
      "Epoch 2780/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7867e-04 - val_loss: 0.0889\n",
      "Epoch 2781/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9966e-04 - val_loss: 0.0891\n",
      "Epoch 2782/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6391e-04 - val_loss: 0.0897\n",
      "Epoch 2783/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9680e-04 - val_loss: 0.0896\n",
      "Epoch 2784/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7138e-04 - val_loss: 0.0892\n",
      "Epoch 2785/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0263e-04 - val_loss: 0.0894\n",
      "Epoch 2786/3000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 8.9357e-04 - val_loss: 0.0894\n",
      "Epoch 2787/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6452e-04 - val_loss: 0.0893\n",
      "Epoch 2788/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.1452e-04 - val_loss: 0.0897\n",
      "Epoch 2789/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8090e-04 - val_loss: 0.0897\n",
      "Epoch 2790/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.6977e-04 - val_loss: 0.0894\n",
      "Epoch 2791/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6872e-04 - val_loss: 0.0894\n",
      "Epoch 2792/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7635e-04 - val_loss: 0.0899\n",
      "Epoch 2793/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7579e-04 - val_loss: 0.0900\n",
      "Epoch 2794/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7709e-04 - val_loss: 0.0897\n",
      "Epoch 2795/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7664e-04 - val_loss: 0.0898\n",
      "Epoch 2796/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6633e-04 - val_loss: 0.0901\n",
      "Epoch 2797/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9674e-04 - val_loss: 0.0898\n",
      "Epoch 2798/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.6345e-04 - val_loss: 0.0895\n",
      "Epoch 2799/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9629e-04 - val_loss: 0.0898\n",
      "Epoch 2800/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6688e-04 - val_loss: 0.0900\n",
      "Epoch 2801/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6677e-04 - val_loss: 0.0900\n",
      "Epoch 2802/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6096e-04 - val_loss: 0.0900\n",
      "Epoch 2803/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8139e-04 - val_loss: 0.0902\n",
      "Epoch 2804/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8395e-04 - val_loss: 0.0897\n",
      "Epoch 2805/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6427e-04 - val_loss: 0.0893\n",
      "Epoch 2806/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8115e-04 - val_loss: 0.0895\n",
      "Epoch 2807/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.7243e-04 - val_loss: 0.0900\n",
      "Epoch 2808/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7047e-04 - val_loss: 0.0899\n",
      "Epoch 2809/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5963e-04 - val_loss: 0.0898\n",
      "Epoch 2810/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7172e-04 - val_loss: 0.0900\n",
      "Epoch 2811/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8164e-04 - val_loss: 0.0898\n",
      "Epoch 2812/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6057e-04 - val_loss: 0.0900\n",
      "Epoch 2813/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7273e-04 - val_loss: 0.0902\n",
      "Epoch 2814/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6473e-04 - val_loss: 0.0899\n",
      "Epoch 2815/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6846e-04 - val_loss: 0.0897\n",
      "Epoch 2816/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5886e-04 - val_loss: 0.0899\n",
      "Epoch 2817/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7022e-04 - val_loss: 0.0903\n",
      "Epoch 2818/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7451e-04 - val_loss: 0.0901\n",
      "Epoch 2819/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7026e-04 - val_loss: 0.0895\n",
      "Epoch 2820/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7387e-04 - val_loss: 0.0896\n",
      "Epoch 2821/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6806e-04 - val_loss: 0.0901\n",
      "Epoch 2822/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.5520e-04 - val_loss: 0.0904\n",
      "Epoch 2823/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8027e-04 - val_loss: 0.0897\n",
      "Epoch 2824/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7302e-04 - val_loss: 0.0892\n",
      "Epoch 2825/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6976e-04 - val_loss: 0.0896\n",
      "Epoch 2826/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1378e-04 - val_loss: 0.0897\n",
      "Epoch 2827/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.6858e-04 - val_loss: 0.0899\n",
      "Epoch 2828/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9357e-04 - val_loss: 0.0904\n",
      "Epoch 2829/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9966e-04 - val_loss: 0.0897\n",
      "Epoch 2830/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7122e-04 - val_loss: 0.0889\n",
      "Epoch 2831/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0048e-04 - val_loss: 0.0898\n",
      "Epoch 2832/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9061e-04 - val_loss: 0.0903\n",
      "Epoch 2833/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9030e-04 - val_loss: 0.0895\n",
      "Epoch 2834/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 9.2570e-04 - val_loss: 0.0891\n",
      "Epoch 2835/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8178e-04 - val_loss: 0.0892\n",
      "Epoch 2836/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8084e-04 - val_loss: 0.0891\n",
      "Epoch 2837/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8716e-04 - val_loss: 0.0895\n",
      "Epoch 2838/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8168e-04 - val_loss: 0.0901\n",
      "Epoch 2839/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8778e-04 - val_loss: 0.0899\n",
      "Epoch 2840/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6630e-04 - val_loss: 0.0893\n",
      "Epoch 2841/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8703e-04 - val_loss: 0.0890\n",
      "Epoch 2842/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8987e-04 - val_loss: 0.0895\n",
      "Epoch 2843/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.7547e-04 - val_loss: 0.0898\n",
      "Epoch 2844/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9735e-04 - val_loss: 0.0894\n",
      "Epoch 2845/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6799e-04 - val_loss: 0.0888\n",
      "Epoch 2846/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7810e-04 - val_loss: 0.0885\n",
      "Epoch 2847/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9269e-04 - val_loss: 0.0884\n",
      "Epoch 2848/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7614e-04 - val_loss: 0.0888\n",
      "Epoch 2849/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0343e-04 - val_loss: 0.0895\n",
      "Epoch 2850/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8408e-04 - val_loss: 0.0891\n",
      "Epoch 2851/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7285e-04 - val_loss: 0.0883\n",
      "Epoch 2852/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8377e-04 - val_loss: 0.0886\n",
      "Epoch 2853/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7194e-04 - val_loss: 0.0894\n",
      "Epoch 2854/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6854e-04 - val_loss: 0.0895\n",
      "Epoch 2855/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7972e-04 - val_loss: 0.0888\n",
      "Epoch 2856/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7587e-04 - val_loss: 0.0885\n",
      "Epoch 2857/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7893e-04 - val_loss: 0.0886\n",
      "Epoch 2858/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7101e-04 - val_loss: 0.0892\n",
      "Epoch 2859/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6670e-04 - val_loss: 0.0896\n",
      "Epoch 2860/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7754e-04 - val_loss: 0.0895\n",
      "Epoch 2861/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8057e-04 - val_loss: 0.0889\n",
      "Epoch 2862/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7561e-04 - val_loss: 0.0884\n",
      "Epoch 2863/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8686e-04 - val_loss: 0.0889\n",
      "Epoch 2864/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5787e-04 - val_loss: 0.0895\n",
      "Epoch 2865/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6727e-04 - val_loss: 0.0895\n",
      "Epoch 2866/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7849e-04 - val_loss: 0.0896\n",
      "Epoch 2867/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.5304e-04 - val_loss: 0.0895\n",
      "Epoch 2868/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7006e-04 - val_loss: 0.0894\n",
      "Epoch 2869/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7607e-04 - val_loss: 0.0893\n",
      "Epoch 2870/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7235e-04 - val_loss: 0.0898\n",
      "Epoch 2871/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8646e-04 - val_loss: 0.0902\n",
      "Epoch 2872/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5208e-04 - val_loss: 0.0900\n",
      "Epoch 2873/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6419e-04 - val_loss: 0.0899\n",
      "Epoch 2874/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6583e-04 - val_loss: 0.0901\n",
      "Epoch 2875/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.5731e-04 - val_loss: 0.0898\n",
      "Epoch 2876/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6226e-04 - val_loss: 0.0894\n",
      "Epoch 2877/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6925e-04 - val_loss: 0.0893\n",
      "Epoch 2878/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7294e-04 - val_loss: 0.0896\n",
      "Epoch 2879/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8009e-04 - val_loss: 0.0895\n",
      "Epoch 2880/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7573e-04 - val_loss: 0.0895\n",
      "Epoch 2881/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8450e-04 - val_loss: 0.0900\n",
      "Epoch 2882/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5535e-04 - val_loss: 0.0902\n",
      "Epoch 2883/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8806e-04 - val_loss: 0.0899\n",
      "Epoch 2884/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7727e-04 - val_loss: 0.0903\n",
      "Epoch 2885/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6181e-04 - val_loss: 0.0909\n",
      "Epoch 2886/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 9.0294e-04 - val_loss: 0.0899\n",
      "Epoch 2887/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8106e-04 - val_loss: 0.0890\n",
      "Epoch 2888/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7135e-04 - val_loss: 0.0892\n",
      "Epoch 2889/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8457e-04 - val_loss: 0.0897\n",
      "Epoch 2890/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7567e-04 - val_loss: 0.0901\n",
      "Epoch 2891/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7840e-04 - val_loss: 0.0900\n",
      "Epoch 2892/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.6756e-04 - val_loss: 0.0896\n",
      "Epoch 2893/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7020e-04 - val_loss: 0.0891\n",
      "Epoch 2894/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.6355e-04 - val_loss: 0.0891\n",
      "Epoch 2895/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7342e-04 - val_loss: 0.0899\n",
      "Epoch 2896/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7056e-04 - val_loss: 0.0904\n",
      "Epoch 2897/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7480e-04 - val_loss: 0.0901\n",
      "Epoch 2898/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8423e-04 - val_loss: 0.0895\n",
      "Epoch 2899/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.8066e-04 - val_loss: 0.0896\n",
      "Epoch 2900/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7866e-04 - val_loss: 0.0899\n",
      "Epoch 2901/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.5718e-04 - val_loss: 0.0900\n",
      "Epoch 2902/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7484e-04 - val_loss: 0.0901\n",
      "Epoch 2903/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9171e-04 - val_loss: 0.0901\n",
      "Epoch 2904/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step - loss: 9.0147e-04 - val_loss: 0.0898\n",
      "Epoch 2905/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6037e-04 - val_loss: 0.0903\n",
      "Epoch 2906/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.8668e-04 - val_loss: 0.0906\n",
      "Epoch 2907/3000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.9142e-04 - val_loss: 0.0903\n",
      "Epoch 2908/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.7324e-04 - val_loss: 0.0894\n",
      "Epoch 2909/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.8974e-04 - val_loss: 0.0889\n",
      "Epoch 2910/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.7409e-04 - val_loss: 0.0890\n",
      "Epoch 2911/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 9.2203e-04 - val_loss: 0.0893\n",
      "Epoch 2912/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6821e-04 - val_loss: 0.0897\n",
      "Epoch 2913/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 9.3723e-04 - val_loss: 0.0894\n",
      "Epoch 2914/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.9715e-04 - val_loss: 0.0886\n",
      "Epoch 2915/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.7733e-04 - val_loss: 0.0884\n",
      "Epoch 2916/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 9.0838e-04 - val_loss: 0.0887\n",
      "Epoch 2917/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.5787e-04 - val_loss: 0.0893\n",
      "Epoch 2918/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 9.3085e-04 - val_loss: 0.0888\n",
      "Epoch 2919/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.7799e-04 - val_loss: 0.0890\n",
      "Epoch 2920/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.9709e-04 - val_loss: 0.0900\n",
      "Epoch 2921/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8243e-04 - val_loss: 0.0903\n",
      "Epoch 2922/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8454e-04 - val_loss: 0.0891\n",
      "Epoch 2923/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.1246e-04 - val_loss: 0.0892\n",
      "Epoch 2924/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7969e-04 - val_loss: 0.0894\n",
      "Epoch 2925/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.9611e-04 - val_loss: 0.0895\n",
      "Epoch 2926/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.6623e-04 - val_loss: 0.0893\n",
      "Epoch 2927/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.8443e-04 - val_loss: 0.0893\n",
      "Epoch 2928/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8417e-04 - val_loss: 0.0894\n",
      "Epoch 2929/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.8444e-04 - val_loss: 0.0894\n",
      "Epoch 2930/3000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 8.8553e-04 - val_loss: 0.0898\n",
      "Epoch 2931/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.5770e-04 - val_loss: 0.0901\n",
      "Epoch 2932/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.6294e-04 - val_loss: 0.0895\n",
      "Epoch 2933/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7424e-04 - val_loss: 0.0886\n",
      "Epoch 2934/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7344e-04 - val_loss: 0.0890\n",
      "Epoch 2935/3000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 8.7636e-04 - val_loss: 0.0897\n",
      "Epoch 2936/3000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 8.8611e-04 - val_loss: 0.0902\n",
      "Epoch 2937/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7464e-04 - val_loss: 0.0900\n",
      "Epoch 2938/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7840e-04 - val_loss: 0.0892\n",
      "Epoch 2939/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7736e-04 - val_loss: 0.0897\n",
      "Epoch 2940/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7575e-04 - val_loss: 0.0905\n",
      "Epoch 2941/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8845e-04 - val_loss: 0.0903\n",
      "Epoch 2942/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7581e-04 - val_loss: 0.0902\n",
      "Epoch 2943/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.6917e-04 - val_loss: 0.0901\n",
      "Epoch 2944/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0680e-04 - val_loss: 0.0902\n",
      "Epoch 2945/3000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 8.7781e-04 - val_loss: 0.0909\n",
      "Epoch 2946/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.7111e-04 - val_loss: 0.0905\n",
      "Epoch 2947/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.9616e-04 - val_loss: 0.0902\n",
      "Epoch 2948/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8820e-04 - val_loss: 0.0896\n",
      "Epoch 2949/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8072e-04 - val_loss: 0.0897\n",
      "Epoch 2950/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8031e-04 - val_loss: 0.0905\n",
      "Epoch 2951/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9288e-04 - val_loss: 0.0900\n",
      "Epoch 2952/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6860e-04 - val_loss: 0.0897\n",
      "Epoch 2953/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8588e-04 - val_loss: 0.0898\n",
      "Epoch 2954/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8295e-04 - val_loss: 0.0894\n",
      "Epoch 2955/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.8644e-04 - val_loss: 0.0890\n",
      "Epoch 2956/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.9360e-04 - val_loss: 0.0898\n",
      "Epoch 2957/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.6871e-04 - val_loss: 0.0907\n",
      "Epoch 2958/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 9.0466e-04 - val_loss: 0.0898\n",
      "Epoch 2959/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.8051e-04 - val_loss: 0.0894\n",
      "Epoch 2960/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7144e-04 - val_loss: 0.0896\n",
      "Epoch 2961/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.8850e-04 - val_loss: 0.0902\n",
      "Epoch 2962/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.9831e-04 - val_loss: 0.0900\n",
      "Epoch 2963/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.1436e-04 - val_loss: 0.0904\n",
      "Epoch 2964/3000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 8.7165e-04 - val_loss: 0.0906\n",
      "Epoch 2965/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 9.0183e-04 - val_loss: 0.0897\n",
      "Epoch 2966/3000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 8.5942e-04 - val_loss: 0.0895\n",
      "Epoch 2967/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8593e-04 - val_loss: 0.0901\n",
      "Epoch 2968/3000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 8.9891e-04 - val_loss: 0.0902\n",
      "Epoch 2969/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9708e-04 - val_loss: 0.0898\n",
      "Epoch 2970/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7666e-04 - val_loss: 0.0897\n",
      "Epoch 2971/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.7201e-04 - val_loss: 0.0901\n",
      "Epoch 2972/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.8425e-04 - val_loss: 0.0899\n",
      "Epoch 2973/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.7042e-04 - val_loss: 0.0896\n",
      "Epoch 2974/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.8024e-04 - val_loss: 0.0901\n",
      "Epoch 2975/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.9122e-04 - val_loss: 0.0899\n",
      "Epoch 2976/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.5975e-04 - val_loss: 0.0899\n",
      "Epoch 2977/3000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 8.8409e-04 - val_loss: 0.0904\n",
      "Epoch 2978/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.7357e-04 - val_loss: 0.0904\n",
      "Epoch 2979/3000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 8.8064e-04 - val_loss: 0.0902\n",
      "Epoch 2980/3000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 8.9625e-04 - val_loss: 0.0901\n",
      "Epoch 2981/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.6785e-04 - val_loss: 0.0901\n",
      "Epoch 2982/3000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 8.7665e-04 - val_loss: 0.0895\n",
      "Epoch 2983/3000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.7288e-04 - val_loss: 0.0893\n",
      "Epoch 2984/3000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 8.7353e-04 - val_loss: 0.0898\n",
      "Epoch 2985/3000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 8.7317e-04 - val_loss: 0.0905\n",
      "Epoch 2986/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8676e-04 - val_loss: 0.0902\n",
      "Epoch 2987/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.9852e-04 - val_loss: 0.0896\n",
      "Epoch 2988/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6669e-04 - val_loss: 0.0899\n",
      "Epoch 2989/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 9.1915e-04 - val_loss: 0.0897\n",
      "Epoch 2990/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.6505e-04 - val_loss: 0.0897\n",
      "Epoch 2991/3000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 8.9161e-04 - val_loss: 0.0907\n",
      "Epoch 2992/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.6786e-04 - val_loss: 0.0907\n",
      "Epoch 2993/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.9485e-04 - val_loss: 0.0903\n",
      "Epoch 2994/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.8289e-04 - val_loss: 0.0902\n",
      "Epoch 2995/3000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 8.6657e-04 - val_loss: 0.0904\n",
      "Epoch 2996/3000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 8.7922e-04 - val_loss: 0.0905\n",
      "Epoch 2997/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6096e-04 - val_loss: 0.0902\n",
      "Epoch 2998/3000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.8225e-04 - val_loss: 0.0905\n",
      "Epoch 2999/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.5399e-04 - val_loss: 0.0904\n",
      "Epoch 3000/3000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 8.6582e-04 - val_loss: 0.0901\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, batch_size = 1000, epochs = 3000,verbose=1,validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f03faa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#512 'tanh'  batch_size = 1000, epochs = 2000\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a98f8eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#batch_size = 2000, epochs = 3000, 2048 'tanh'\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28f59903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#batch_size = 1000, epochs = 3000, 2048 'tanh'\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50676283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#batch_size = 1000, epochs = 3000, 512+64 'tanh'\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff6f9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aef3eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 3)\n",
      "(320, 64, 64, 1)\n",
      "(80, 64, 64, 1)\n",
      "(320, 3, 1)\n",
      "(80, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f63560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plot\n",
    "from numpy import asarray\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d404837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.0813181606366196\n",
      "RMSE =  0.28516339287611864\n"
     ]
    }
   ],
   "source": [
    "#2048 tanh\n",
    "m = mean_squared_error(y_test,y_pred)\n",
    "r = math.sqrt(m)\n",
    "print('MSE = ',m)\n",
    "print('RMSE = ',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35850ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.10657376513939691\n",
      "RMSE =  0.3264563755532995\n"
     ]
    }
   ],
   "source": [
    "#512+64 tanh\n",
    "m = mean_squared_error(y_test,y_pred)\n",
    "r = math.sqrt(m)\n",
    "print('MSE of CNN : ',m)\n",
    "print('RMSE of CNN = ',r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846ba3bf",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d123b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc8e2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_X = np.zeros((320,64,64,3))\n",
    "for i in range(0,len(array_X)):\n",
    "    array_X[i] = X_train[i]\n",
    "array_X_test = np.zeros((80,64,64,3))\n",
    "for k in range(0,len(array_X_test)):\n",
    "    array_X_test[k] = X_test[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87b589ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(array_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40c9122a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 23,727,491\n",
      "Trainable params: 135,555\n",
      "Non-trainable params: 23,591,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "restnet = ResNet50(include_top=False,\n",
    "                  input_shape=(64,64,3),\n",
    "                  pooling='avg',classes=5,\n",
    "                  weights = 'imagenet')\n",
    "for layer in restnet.layers:\n",
    "    layer.trainable=False\n",
    "model1.add(restnet)\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(64, activation='tanh'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(3, activation='softmax'))\n",
    "model1.compile(loss='mse',\n",
    "              optimizer='adam')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f7dfb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1448 - val_loss: 0.0887\n",
      "Epoch 2/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1208 - val_loss: 0.0902\n",
      "Epoch 3/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1104 - val_loss: 0.0897\n",
      "Epoch 4/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1075 - val_loss: 0.0914\n",
      "Epoch 5/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1067 - val_loss: 0.0943\n",
      "Epoch 6/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0982 - val_loss: 0.0964\n",
      "Epoch 7/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0959 - val_loss: 0.0979\n",
      "Epoch 8/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0955 - val_loss: 0.0987\n",
      "Epoch 9/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0887 - val_loss: 0.0996\n",
      "Epoch 10/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0928 - val_loss: 0.1001\n",
      "Epoch 11/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - val_loss: 0.1004\n",
      "Epoch 12/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0790 - val_loss: 0.1011\n",
      "Epoch 13/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0843 - val_loss: 0.1020\n",
      "Epoch 14/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 0.1029\n",
      "Epoch 15/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0791 - val_loss: 0.1040\n",
      "Epoch 16/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0887 - val_loss: 0.1049\n",
      "Epoch 17/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0833 - val_loss: 0.1055\n",
      "Epoch 18/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0742 - val_loss: 0.1054\n",
      "Epoch 19/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0759 - val_loss: 0.1063\n",
      "Epoch 20/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0682 - val_loss: 0.1082\n",
      "Epoch 21/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0680 - val_loss: 0.1110\n",
      "Epoch 22/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0677 - val_loss: 0.1143\n",
      "Epoch 23/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0774 - val_loss: 0.1170\n",
      "Epoch 24/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0676 - val_loss: 0.1184\n",
      "Epoch 25/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0664 - val_loss: 0.1188\n",
      "Epoch 26/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0684 - val_loss: 0.1171\n",
      "Epoch 27/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0657 - val_loss: 0.1142\n",
      "Epoch 28/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0611 - val_loss: 0.1114\n",
      "Epoch 29/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0717 - val_loss: 0.1085\n",
      "Epoch 30/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0648 - val_loss: 0.1066\n",
      "Epoch 31/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0644 - val_loss: 0.1057\n",
      "Epoch 32/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0581 - val_loss: 0.1060\n",
      "Epoch 33/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0641 - val_loss: 0.1063\n",
      "Epoch 34/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0698 - val_loss: 0.1065\n",
      "Epoch 35/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0551 - val_loss: 0.1067\n",
      "Epoch 36/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0566 - val_loss: 0.1065\n",
      "Epoch 37/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0594 - val_loss: 0.1058\n",
      "Epoch 38/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0622 - val_loss: 0.1043\n",
      "Epoch 39/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0565 - val_loss: 0.1031\n",
      "Epoch 40/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0617 - val_loss: 0.1023\n",
      "Epoch 41/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0601 - val_loss: 0.1017\n",
      "Epoch 42/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0616 - val_loss: 0.1017\n",
      "Epoch 43/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0577 - val_loss: 0.1014\n",
      "Epoch 44/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0571 - val_loss: 0.1009\n",
      "Epoch 45/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0537 - val_loss: 0.1003\n",
      "Epoch 46/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - val_loss: 0.0999\n",
      "Epoch 47/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0605 - val_loss: 0.0997\n",
      "Epoch 48/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0559 - val_loss: 0.1004\n",
      "Epoch 49/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0522 - val_loss: 0.1017\n",
      "Epoch 50/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0617 - val_loss: 0.1033\n",
      "Epoch 51/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0578 - val_loss: 0.1054\n",
      "Epoch 52/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0501 - val_loss: 0.1066\n",
      "Epoch 53/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0560 - val_loss: 0.1080\n",
      "Epoch 54/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0525 - val_loss: 0.1084\n",
      "Epoch 55/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0492 - val_loss: 0.1070\n",
      "Epoch 56/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0494 - val_loss: 0.1059\n",
      "Epoch 57/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0513 - val_loss: 0.1052\n",
      "Epoch 58/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0481 - val_loss: 0.1047\n",
      "Epoch 59/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0495 - val_loss: 0.1052\n",
      "Epoch 60/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0464 - val_loss: 0.1060\n",
      "Epoch 61/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0489 - val_loss: 0.1079\n",
      "Epoch 62/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0466 - val_loss: 0.1097\n",
      "Epoch 63/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0493 - val_loss: 0.1103\n",
      "Epoch 64/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0450 - val_loss: 0.1097\n",
      "Epoch 65/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0511 - val_loss: 0.1085\n",
      "Epoch 66/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0454 - val_loss: 0.1063\n",
      "Epoch 67/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0457 - val_loss: 0.1039\n",
      "Epoch 68/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0452 - val_loss: 0.1020\n",
      "Epoch 69/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0457 - val_loss: 0.1008\n",
      "Epoch 70/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0473 - val_loss: 0.0992\n",
      "Epoch 71/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0451 - val_loss: 0.0984\n",
      "Epoch 72/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0455 - val_loss: 0.0989\n",
      "Epoch 73/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0444 - val_loss: 0.1012\n",
      "Epoch 74/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0422 - val_loss: 0.1061\n",
      "Epoch 75/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0455 - val_loss: 0.1107\n",
      "Epoch 76/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0415 - val_loss: 0.1128\n",
      "Epoch 77/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0431 - val_loss: 0.1146\n",
      "Epoch 78/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0453 - val_loss: 0.1164\n",
      "Epoch 79/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0416 - val_loss: 0.1185\n",
      "Epoch 80/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0435 - val_loss: 0.1187\n",
      "Epoch 81/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0438 - val_loss: 0.1191\n",
      "Epoch 82/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0404 - val_loss: 0.1185\n",
      "Epoch 83/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0391 - val_loss: 0.1179\n",
      "Epoch 84/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0362 - val_loss: 0.1175\n",
      "Epoch 85/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0359 - val_loss: 0.1172\n",
      "Epoch 86/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0418 - val_loss: 0.1165\n",
      "Epoch 87/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0436 - val_loss: 0.1192\n",
      "Epoch 88/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0379 - val_loss: 0.1216\n",
      "Epoch 89/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0376 - val_loss: 0.1230\n",
      "Epoch 90/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0403 - val_loss: 0.1241\n",
      "Epoch 91/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0390 - val_loss: 0.1243\n",
      "Epoch 92/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0388 - val_loss: 0.1230\n",
      "Epoch 93/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0343 - val_loss: 0.1187\n",
      "Epoch 94/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0378 - val_loss: 0.1142\n",
      "Epoch 95/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0360 - val_loss: 0.1100\n",
      "Epoch 96/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0363 - val_loss: 0.1071\n",
      "Epoch 97/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0340 - val_loss: 0.1056\n",
      "Epoch 98/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0352 - val_loss: 0.1046\n",
      "Epoch 99/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0372 - val_loss: 0.1049\n",
      "Epoch 100/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0373 - val_loss: 0.1058\n",
      "Epoch 101/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0344 - val_loss: 0.1077\n",
      "Epoch 102/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0331 - val_loss: 0.1098\n",
      "Epoch 103/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0362 - val_loss: 0.1121\n",
      "Epoch 104/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0352 - val_loss: 0.1149\n",
      "Epoch 105/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0349 - val_loss: 0.1169\n",
      "Epoch 106/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0336 - val_loss: 0.1185\n",
      "Epoch 107/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0337 - val_loss: 0.1205\n",
      "Epoch 108/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0329 - val_loss: 0.1208\n",
      "Epoch 109/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0321 - val_loss: 0.1213\n",
      "Epoch 110/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0329 - val_loss: 0.1196\n",
      "Epoch 111/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0299 - val_loss: 0.1183\n",
      "Epoch 112/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0323 - val_loss: 0.1164\n",
      "Epoch 113/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0315 - val_loss: 0.1146\n",
      "Epoch 114/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0310 - val_loss: 0.1141\n",
      "Epoch 115/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0318 - val_loss: 0.1133\n",
      "Epoch 116/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0330 - val_loss: 0.1128\n",
      "Epoch 117/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0310 - val_loss: 0.1128\n",
      "Epoch 118/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0324 - val_loss: 0.1133\n",
      "Epoch 119/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0356 - val_loss: 0.1151\n",
      "Epoch 120/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0309 - val_loss: 0.1165\n",
      "Epoch 121/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0323 - val_loss: 0.1166\n",
      "Epoch 122/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0331 - val_loss: 0.1170\n",
      "Epoch 123/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0314 - val_loss: 0.1176\n",
      "Epoch 124/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0273 - val_loss: 0.1188\n",
      "Epoch 125/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0296 - val_loss: 0.1204\n",
      "Epoch 126/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0267 - val_loss: 0.1203\n",
      "Epoch 127/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0318 - val_loss: 0.1189\n",
      "Epoch 128/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0316 - val_loss: 0.1170\n",
      "Epoch 129/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0301 - val_loss: 0.1144\n",
      "Epoch 130/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0296 - val_loss: 0.1119\n",
      "Epoch 131/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0261 - val_loss: 0.1095\n",
      "Epoch 132/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0270 - val_loss: 0.1076\n",
      "Epoch 133/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0262 - val_loss: 0.1063\n",
      "Epoch 134/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0304 - val_loss: 0.1055\n",
      "Epoch 135/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0273 - val_loss: 0.1046\n",
      "Epoch 136/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0287 - val_loss: 0.1040\n",
      "Epoch 137/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0293 - val_loss: 0.1034\n",
      "Epoch 138/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0279 - val_loss: 0.1030\n",
      "Epoch 139/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0291 - val_loss: 0.1031\n",
      "Epoch 140/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0257 - val_loss: 0.1033\n",
      "Epoch 141/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0279 - val_loss: 0.1040\n",
      "Epoch 142/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0279 - val_loss: 0.1048\n",
      "Epoch 143/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0266 - val_loss: 0.1058\n",
      "Epoch 144/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0230 - val_loss: 0.1069\n",
      "Epoch 145/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0273 - val_loss: 0.1082\n",
      "Epoch 146/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0284 - val_loss: 0.1089\n",
      "Epoch 147/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0263 - val_loss: 0.1093\n",
      "Epoch 148/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0269 - val_loss: 0.1093\n",
      "Epoch 149/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0237 - val_loss: 0.1096\n",
      "Epoch 150/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0246 - val_loss: 0.1097\n",
      "Epoch 151/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0253 - val_loss: 0.1090\n",
      "Epoch 152/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0268 - val_loss: 0.1082\n",
      "Epoch 153/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0258 - val_loss: 0.1081\n",
      "Epoch 154/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0279 - val_loss: 0.1083\n",
      "Epoch 155/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0263 - val_loss: 0.1090\n",
      "Epoch 156/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0270 - val_loss: 0.1106\n",
      "Epoch 157/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0269 - val_loss: 0.1117\n",
      "Epoch 158/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0249 - val_loss: 0.1124\n",
      "Epoch 159/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0250 - val_loss: 0.1133\n",
      "Epoch 160/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0247 - val_loss: 0.1141\n",
      "Epoch 161/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0295 - val_loss: 0.1146\n",
      "Epoch 162/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0233 - val_loss: 0.1155\n",
      "Epoch 163/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0251 - val_loss: 0.1161\n",
      "Epoch 164/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0256 - val_loss: 0.1166\n",
      "Epoch 165/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0240 - val_loss: 0.1167\n",
      "Epoch 166/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0218 - val_loss: 0.1166\n",
      "Epoch 167/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0236 - val_loss: 0.1161\n",
      "Epoch 168/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0254 - val_loss: 0.1158\n",
      "Epoch 169/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0230 - val_loss: 0.1165\n",
      "Epoch 170/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0262 - val_loss: 0.1171\n",
      "Epoch 171/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0242 - val_loss: 0.1177\n",
      "Epoch 172/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 0.1177\n",
      "Epoch 173/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0227 - val_loss: 0.1173\n",
      "Epoch 174/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0232 - val_loss: 0.1164\n",
      "Epoch 175/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0217 - val_loss: 0.1160\n",
      "Epoch 176/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0261 - val_loss: 0.1160\n",
      "Epoch 177/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0237 - val_loss: 0.1158\n",
      "Epoch 178/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0241 - val_loss: 0.1150\n",
      "Epoch 179/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0234 - val_loss: 0.1146\n",
      "Epoch 180/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0252 - val_loss: 0.1135\n",
      "Epoch 181/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0225 - val_loss: 0.1127\n",
      "Epoch 182/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0243 - val_loss: 0.1119\n",
      "Epoch 183/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0220 - val_loss: 0.1113\n",
      "Epoch 184/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0208 - val_loss: 0.1109\n",
      "Epoch 185/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0225 - val_loss: 0.1106\n",
      "Epoch 186/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0226 - val_loss: 0.1102\n",
      "Epoch 187/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0224 - val_loss: 0.1102\n",
      "Epoch 188/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 0.1101\n",
      "Epoch 189/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0232 - val_loss: 0.1096\n",
      "Epoch 190/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0220 - val_loss: 0.1089\n",
      "Epoch 191/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 0.1080\n",
      "Epoch 192/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0238 - val_loss: 0.1072\n",
      "Epoch 193/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0244 - val_loss: 0.1063\n",
      "Epoch 194/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0220 - val_loss: 0.1052\n",
      "Epoch 195/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0242 - val_loss: 0.1044\n",
      "Epoch 196/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0217 - val_loss: 0.1045\n",
      "Epoch 197/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - val_loss: 0.1045\n",
      "Epoch 198/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0212 - val_loss: 0.1044\n",
      "Epoch 199/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0209 - val_loss: 0.1044\n",
      "Epoch 200/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0204 - val_loss: 0.1043\n",
      "Epoch 201/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0216 - val_loss: 0.1039\n",
      "Epoch 202/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0216 - val_loss: 0.1034\n",
      "Epoch 203/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0222 - val_loss: 0.1033\n",
      "Epoch 204/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0227 - val_loss: 0.1034\n",
      "Epoch 205/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0223 - val_loss: 0.1034\n",
      "Epoch 206/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0197 - val_loss: 0.1039\n",
      "Epoch 207/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0206 - val_loss: 0.1043\n",
      "Epoch 208/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0178 - val_loss: 0.1048\n",
      "Epoch 209/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0199 - val_loss: 0.1051\n",
      "Epoch 210/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0199 - val_loss: 0.1052\n",
      "Epoch 211/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0180 - val_loss: 0.1052\n",
      "Epoch 212/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0186 - val_loss: 0.1054\n",
      "Epoch 213/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0206 - val_loss: 0.1055\n",
      "Epoch 214/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0192 - val_loss: 0.1057\n",
      "Epoch 215/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0198 - val_loss: 0.1059\n",
      "Epoch 216/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0202 - val_loss: 0.1068\n",
      "Epoch 217/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0209 - val_loss: 0.1077\n",
      "Epoch 218/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0229 - val_loss: 0.1083\n",
      "Epoch 219/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0191 - val_loss: 0.1087\n",
      "Epoch 220/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0172 - val_loss: 0.1093\n",
      "Epoch 221/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0201 - val_loss: 0.1096\n",
      "Epoch 222/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0191 - val_loss: 0.1099\n",
      "Epoch 223/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0197 - val_loss: 0.1100\n",
      "Epoch 224/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0181 - val_loss: 0.1096\n",
      "Epoch 225/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - val_loss: 0.1090\n",
      "Epoch 226/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0199 - val_loss: 0.1085\n",
      "Epoch 227/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0189 - val_loss: 0.1078\n",
      "Epoch 228/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - val_loss: 0.1072\n",
      "Epoch 229/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0204 - val_loss: 0.1061\n",
      "Epoch 230/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0152 - val_loss: 0.1049\n",
      "Epoch 231/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0175 - val_loss: 0.1041\n",
      "Epoch 232/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0209 - val_loss: 0.1036\n",
      "Epoch 233/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0188 - val_loss: 0.1036\n",
      "Epoch 234/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0195 - val_loss: 0.1042\n",
      "Epoch 235/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0208 - val_loss: 0.1048\n",
      "Epoch 236/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0190 - val_loss: 0.1055\n",
      "Epoch 237/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0177 - val_loss: 0.1060\n",
      "Epoch 238/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - val_loss: 0.1063\n",
      "Epoch 239/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0189 - val_loss: 0.1063\n",
      "Epoch 240/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0189 - val_loss: 0.1062\n",
      "Epoch 241/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1061\n",
      "Epoch 242/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0166 - val_loss: 0.1063\n",
      "Epoch 243/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0175 - val_loss: 0.1065\n",
      "Epoch 244/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0194 - val_loss: 0.1066\n",
      "Epoch 245/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0194 - val_loss: 0.1065\n",
      "Epoch 246/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0184 - val_loss: 0.1062\n",
      "Epoch 247/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0169 - val_loss: 0.1054\n",
      "Epoch 248/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0184 - val_loss: 0.1047\n",
      "Epoch 249/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0197 - val_loss: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1035\n",
      "Epoch 251/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0198 - val_loss: 0.1030\n",
      "Epoch 252/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 0.1027\n",
      "Epoch 253/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0183 - val_loss: 0.1029\n",
      "Epoch 254/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0189 - val_loss: 0.1033\n",
      "Epoch 255/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0192 - val_loss: 0.1040\n",
      "Epoch 256/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 0.1047\n",
      "Epoch 257/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0181 - val_loss: 0.1051\n",
      "Epoch 258/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0202 - val_loss: 0.1057\n",
      "Epoch 259/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0174 - val_loss: 0.1057\n",
      "Epoch 260/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0175 - val_loss: 0.1053\n",
      "Epoch 261/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0168 - val_loss: 0.1045\n",
      "Epoch 262/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0165 - val_loss: 0.1035\n",
      "Epoch 263/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0164 - val_loss: 0.1027\n",
      "Epoch 264/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0178 - val_loss: 0.1021\n",
      "Epoch 265/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0178 - val_loss: 0.1018\n",
      "Epoch 266/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0162 - val_loss: 0.1012\n",
      "Epoch 267/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0161 - val_loss: 0.1008\n",
      "Epoch 268/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0171 - val_loss: 0.1004\n",
      "Epoch 269/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0169 - val_loss: 0.1000\n",
      "Epoch 270/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0195 - val_loss: 0.0998\n",
      "Epoch 271/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0161 - val_loss: 0.1000\n",
      "Epoch 272/3000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.0165 - val_loss: 0.1005\n",
      "Epoch 273/3000\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0179 - val_loss: 0.1013\n",
      "Epoch 274/3000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.0164 - val_loss: 0.1020\n",
      "Epoch 275/3000\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.0181 - val_loss: 0.1025\n",
      "Epoch 276/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0164 - val_loss: 0.1027\n",
      "Epoch 277/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0171 - val_loss: 0.1030\n",
      "Epoch 278/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0177 - val_loss: 0.1035\n",
      "Epoch 279/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0169 - val_loss: 0.1040\n",
      "Epoch 280/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0149 - val_loss: 0.1042\n",
      "Epoch 281/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0157 - val_loss: 0.1041\n",
      "Epoch 282/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0172 - val_loss: 0.1043\n",
      "Epoch 283/3000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.0179 - val_loss: 0.1045\n",
      "Epoch 284/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0168 - val_loss: 0.1046\n",
      "Epoch 285/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0186 - val_loss: 0.1042\n",
      "Epoch 286/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0175 - val_loss: 0.1034\n",
      "Epoch 287/3000\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0176 - val_loss: 0.1024\n",
      "Epoch 288/3000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0168 - val_loss: 0.1010\n",
      "Epoch 289/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0155 - val_loss: 0.0999\n",
      "Epoch 290/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0147 - val_loss: 0.0992\n",
      "Epoch 291/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0165 - val_loss: 0.0986\n",
      "Epoch 292/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0161 - val_loss: 0.0983\n",
      "Epoch 293/3000\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.0166 - val_loss: 0.0983\n",
      "Epoch 294/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0176 - val_loss: 0.0983\n",
      "Epoch 295/3000\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.0153 - val_loss: 0.0983\n",
      "Epoch 296/3000\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0152 - val_loss: 0.0979\n",
      "Epoch 297/3000\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0140 - val_loss: 0.0978\n",
      "Epoch 298/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0169 - val_loss: 0.0977\n",
      "Epoch 299/3000\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.0145 - val_loss: 0.0975\n",
      "Epoch 300/3000\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 0.0178 - val_loss: 0.0968\n",
      "Epoch 301/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0150 - val_loss: 0.0963\n",
      "Epoch 302/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0136 - val_loss: 0.0959\n",
      "Epoch 303/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0170 - val_loss: 0.0956\n",
      "Epoch 304/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0156 - val_loss: 0.0948\n",
      "Epoch 305/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0156 - val_loss: 0.0938\n",
      "Epoch 306/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0159 - val_loss: 0.0928\n",
      "Epoch 307/3000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.0152 - val_loss: 0.0922\n",
      "Epoch 308/3000\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.0171 - val_loss: 0.0922\n",
      "Epoch 309/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0166 - val_loss: 0.0923\n",
      "Epoch 310/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0167 - val_loss: 0.0923\n",
      "Epoch 311/3000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.0163 - val_loss: 0.0923\n",
      "Epoch 312/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0145 - val_loss: 0.0924\n",
      "Epoch 313/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0172 - val_loss: 0.0927\n",
      "Epoch 314/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0169 - val_loss: 0.0927\n",
      "Epoch 315/3000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.0134 - val_loss: 0.0928\n",
      "Epoch 316/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0163 - val_loss: 0.0928\n",
      "Epoch 317/3000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.0172 - val_loss: 0.0929\n",
      "Epoch 318/3000\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0138 - val_loss: 0.0930\n",
      "Epoch 319/3000\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0158 - val_loss: 0.0930\n",
      "Epoch 320/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0161 - val_loss: 0.0932\n",
      "Epoch 321/3000\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.0153 - val_loss: 0.0937\n",
      "Epoch 322/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0153 - val_loss: 0.0941\n",
      "Epoch 323/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0153 - val_loss: 0.0944\n",
      "Epoch 324/3000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.0137 - val_loss: 0.0944\n",
      "Epoch 325/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0161 - val_loss: 0.0944\n",
      "Epoch 326/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0148 - val_loss: 0.0945\n",
      "Epoch 327/3000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0163 - val_loss: 0.0944\n",
      "Epoch 328/3000\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0157 - val_loss: 0.0945\n",
      "Epoch 329/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0125 - val_loss: 0.0943\n",
      "Epoch 330/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0157 - val_loss: 0.0938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0147 - val_loss: 0.0935\n",
      "Epoch 332/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0150 - val_loss: 0.0935\n",
      "Epoch 333/3000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.0136 - val_loss: 0.0934\n",
      "Epoch 334/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0163 - val_loss: 0.0935\n",
      "Epoch 335/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0140 - val_loss: 0.0935\n",
      "Epoch 336/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0147 - val_loss: 0.0935\n",
      "Epoch 337/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0159 - val_loss: 0.0938\n",
      "Epoch 338/3000\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.0144 - val_loss: 0.0939\n",
      "Epoch 339/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0135 - val_loss: 0.0938\n",
      "Epoch 340/3000\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.0146 - val_loss: 0.0940\n",
      "Epoch 341/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0127 - val_loss: 0.0942\n",
      "Epoch 342/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0139 - val_loss: 0.0944\n",
      "Epoch 343/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0146 - val_loss: 0.0946\n",
      "Epoch 344/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0162 - val_loss: 0.0946\n",
      "Epoch 345/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0125 - val_loss: 0.0946\n",
      "Epoch 346/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0144 - val_loss: 0.0945\n",
      "Epoch 347/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0153 - val_loss: 0.0946\n",
      "Epoch 348/3000\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.0147 - val_loss: 0.0946\n",
      "Epoch 349/3000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.0153 - val_loss: 0.0944\n",
      "Epoch 350/3000\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0137 - val_loss: 0.0942\n",
      "Epoch 351/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0150 - val_loss: 0.0938\n",
      "Epoch 352/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0144 - val_loss: 0.0932\n",
      "Epoch 353/3000\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 0.0137 - val_loss: 0.0927\n",
      "Epoch 354/3000\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.0153 - val_loss: 0.0922\n",
      "Epoch 355/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0141 - val_loss: 0.0915\n",
      "Epoch 356/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0128 - val_loss: 0.0913\n",
      "Epoch 357/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0148 - val_loss: 0.0915\n",
      "Epoch 358/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0144 - val_loss: 0.0915\n",
      "Epoch 359/3000\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.0158 - val_loss: 0.0914\n",
      "Epoch 360/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0139 - val_loss: 0.0913\n",
      "Epoch 361/3000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.0138 - val_loss: 0.0912\n",
      "Epoch 362/3000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.0148 - val_loss: 0.0913\n",
      "Epoch 363/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0127 - val_loss: 0.0912\n",
      "Epoch 364/3000\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.0120 - val_loss: 0.0910\n",
      "Epoch 365/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0126 - val_loss: 0.0909\n",
      "Epoch 366/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0148 - val_loss: 0.0909\n",
      "Epoch 367/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0131 - val_loss: 0.0907\n",
      "Epoch 368/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0133 - val_loss: 0.0907\n",
      "Epoch 369/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0130 - val_loss: 0.0906\n",
      "Epoch 370/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0140 - val_loss: 0.0906\n",
      "Epoch 371/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0140 - val_loss: 0.0903\n",
      "Epoch 372/3000\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0138 - val_loss: 0.0900\n",
      "Epoch 373/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0134 - val_loss: 0.0899\n",
      "Epoch 374/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0138 - val_loss: 0.0900\n",
      "Epoch 375/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0142 - val_loss: 0.0903\n",
      "Epoch 376/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0134 - val_loss: 0.0906\n",
      "Epoch 377/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0138 - val_loss: 0.0906\n",
      "Epoch 378/3000\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.0126 - val_loss: 0.0907\n",
      "Epoch 379/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0132 - val_loss: 0.0904\n",
      "Epoch 380/3000\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.0114 - val_loss: 0.0901\n",
      "Epoch 381/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0131 - val_loss: 0.0899\n",
      "Epoch 382/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0141 - val_loss: 0.0899\n",
      "Epoch 383/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0132 - val_loss: 0.0903\n",
      "Epoch 384/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0128 - val_loss: 0.0908\n",
      "Epoch 385/3000\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.0148 - val_loss: 0.0914\n",
      "Epoch 386/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0142 - val_loss: 0.0921\n",
      "Epoch 387/3000\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.0144 - val_loss: 0.0927\n",
      "Epoch 388/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0141 - val_loss: 0.0929\n",
      "Epoch 389/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0127 - val_loss: 0.0928\n",
      "Epoch 390/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0129 - val_loss: 0.0927\n",
      "Epoch 391/3000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.0147 - val_loss: 0.0925\n",
      "Epoch 392/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0137 - val_loss: 0.0920\n",
      "Epoch 393/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0124 - val_loss: 0.0912\n",
      "Epoch 394/3000\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.0148 - val_loss: 0.0907\n",
      "Epoch 395/3000\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0150 - val_loss: 0.0902\n",
      "Epoch 396/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0143 - val_loss: 0.0896\n",
      "Epoch 397/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0136 - val_loss: 0.0892\n",
      "Epoch 398/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0133 - val_loss: 0.0890\n",
      "Epoch 399/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0145 - val_loss: 0.0893\n",
      "Epoch 400/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0132 - val_loss: 0.0895\n",
      "Epoch 401/3000\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.0115 - val_loss: 0.0901\n",
      "Epoch 402/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0135 - val_loss: 0.0905\n",
      "Epoch 403/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0122 - val_loss: 0.0908\n",
      "Epoch 404/3000\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.0132 - val_loss: 0.0911\n",
      "Epoch 405/3000\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.0150 - val_loss: 0.0913\n",
      "Epoch 406/3000\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.0128 - val_loss: 0.0913\n",
      "Epoch 407/3000\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 0.0150 - val_loss: 0.0913\n",
      "Epoch 408/3000\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0134 - val_loss: 0.0914\n",
      "Epoch 409/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0129 - val_loss: 0.0913\n",
      "Epoch 410/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0144 - val_loss: 0.0917\n",
      "Epoch 411/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0123 - val_loss: 0.0917\n",
      "Epoch 412/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0128 - val_loss: 0.0919\n",
      "Epoch 413/3000\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0125 - val_loss: 0.0922\n",
      "Epoch 414/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0127 - val_loss: 0.0924\n",
      "Epoch 415/3000\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0149 - val_loss: 0.0926\n",
      "Epoch 416/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0122 - val_loss: 0.0926\n",
      "Epoch 417/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0143 - val_loss: 0.0928\n",
      "Epoch 418/3000\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.0131 - val_loss: 0.0934\n",
      "Epoch 419/3000\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0148 - val_loss: 0.0943\n",
      "Epoch 420/3000\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.0115 - val_loss: 0.0955\n",
      "Epoch 421/3000\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.0121 - val_loss: 0.0968\n",
      "Epoch 422/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0125 - val_loss: 0.0980\n",
      "Epoch 423/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0134 - val_loss: 0.0989\n",
      "Epoch 424/3000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.0128 - val_loss: 0.0988\n",
      "Epoch 425/3000\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.0142 - val_loss: 0.0980\n",
      "Epoch 426/3000\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 0.0134 - val_loss: 0.0972\n",
      "Epoch 427/3000\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.0126 - val_loss: 0.0960\n",
      "Epoch 428/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0124 - val_loss: 0.0948\n",
      "Epoch 429/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0146 - val_loss: 0.0941\n",
      "Epoch 430/3000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0128 - val_loss: 0.0934\n",
      "Epoch 431/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0131 - val_loss: 0.0929\n",
      "Epoch 432/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0132 - val_loss: 0.0924\n",
      "Epoch 433/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0122 - val_loss: 0.0921\n",
      "Epoch 434/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0133 - val_loss: 0.0918\n",
      "Epoch 435/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0130 - val_loss: 0.0916\n",
      "Epoch 436/3000\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.0121 - val_loss: 0.0912\n",
      "Epoch 437/3000\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.0116 - val_loss: 0.0909\n",
      "Epoch 438/3000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.0124 - val_loss: 0.0907\n",
      "Epoch 439/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0134 - val_loss: 0.0906\n",
      "Epoch 440/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0118 - val_loss: 0.0901\n",
      "Epoch 441/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0124 - val_loss: 0.0899\n",
      "Epoch 442/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0126 - val_loss: 0.0896\n",
      "Epoch 443/3000\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0112 - val_loss: 0.0894\n",
      "Epoch 444/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0112 - val_loss: 0.0891\n",
      "Epoch 445/3000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0139 - val_loss: 0.0889\n",
      "Epoch 446/3000\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 0.0127 - val_loss: 0.0887\n",
      "Epoch 447/3000\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.0123 - val_loss: 0.0885\n",
      "Epoch 448/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0141 - val_loss: 0.0886\n",
      "Epoch 449/3000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.0109 - val_loss: 0.0888\n",
      "Epoch 450/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0117 - val_loss: 0.0889\n",
      "Epoch 451/3000\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.0124 - val_loss: 0.0889\n",
      "Epoch 452/3000\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0118 - val_loss: 0.0889\n",
      "Epoch 453/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0136 - val_loss: 0.0887\n",
      "Epoch 454/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0132 - val_loss: 0.0882\n",
      "Epoch 455/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0119 - val_loss: 0.0879\n",
      "Epoch 456/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0134 - val_loss: 0.0879\n",
      "Epoch 457/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0137 - val_loss: 0.0881\n",
      "Epoch 458/3000\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.0131 - val_loss: 0.0882\n",
      "Epoch 459/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0118 - val_loss: 0.0880\n",
      "Epoch 460/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0113 - val_loss: 0.0880\n",
      "Epoch 461/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0123 - val_loss: 0.0882\n",
      "Epoch 462/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0108 - val_loss: 0.0883\n",
      "Epoch 463/3000\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.0123 - val_loss: 0.0886\n",
      "Epoch 464/3000\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.0123 - val_loss: 0.0889\n",
      "Epoch 465/3000\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.0116 - val_loss: 0.0894\n",
      "Epoch 466/3000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.0116 - val_loss: 0.0898\n",
      "Epoch 467/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0109 - val_loss: 0.0903\n",
      "Epoch 468/3000\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.0127 - val_loss: 0.0905\n",
      "Epoch 469/3000\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.0126 - val_loss: 0.0905\n",
      "Epoch 470/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0115 - val_loss: 0.0905\n",
      "Epoch 471/3000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.0107 - val_loss: 0.0902\n",
      "Epoch 472/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0117 - val_loss: 0.0901\n",
      "Epoch 473/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0123 - val_loss: 0.0899\n",
      "Epoch 474/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0116 - val_loss: 0.0899\n",
      "Epoch 475/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0118 - val_loss: 0.0900\n",
      "Epoch 476/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0114 - val_loss: 0.0904\n",
      "Epoch 477/3000\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.0110 - val_loss: 0.0908\n",
      "Epoch 478/3000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.0108 - val_loss: 0.0914\n",
      "Epoch 479/3000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.0101 - val_loss: 0.0920\n",
      "Epoch 480/3000\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0099 - val_loss: 0.0927\n",
      "Epoch 481/3000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.0129 - val_loss: 0.0936\n",
      "Epoch 482/3000\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0117 - val_loss: 0.0940\n",
      "Epoch 483/3000\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.0123 - val_loss: 0.0941\n",
      "Epoch 484/3000\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.0116 - val_loss: 0.0941\n",
      "Epoch 485/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0112 - val_loss: 0.0943\n",
      "Epoch 486/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0118 - val_loss: 0.0941\n",
      "Epoch 487/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0120 - val_loss: 0.0941\n",
      "Epoch 488/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0103 - val_loss: 0.0941\n",
      "Epoch 489/3000\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0125 - val_loss: 0.0940\n",
      "Epoch 490/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0125 - val_loss: 0.0936\n",
      "Epoch 491/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0116 - val_loss: 0.0931\n",
      "Epoch 492/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0107 - val_loss: 0.0930\n",
      "Epoch 493/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0124 - val_loss: 0.0928\n",
      "Epoch 494/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0102 - val_loss: 0.0924\n",
      "Epoch 495/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0113 - val_loss: 0.0921\n",
      "Epoch 496/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0116 - val_loss: 0.0920\n",
      "Epoch 497/3000\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.0126 - val_loss: 0.0921\n",
      "Epoch 498/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0111 - val_loss: 0.0921\n",
      "Epoch 499/3000\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.0095 - val_loss: 0.0919\n",
      "Epoch 500/3000\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.0114 - val_loss: 0.0916\n",
      "Epoch 501/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0109 - val_loss: 0.0913\n",
      "Epoch 502/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0124 - val_loss: 0.0909\n",
      "Epoch 503/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0098 - val_loss: 0.0905\n",
      "Epoch 504/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0092 - val_loss: 0.0905\n",
      "Epoch 505/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0098 - val_loss: 0.0905\n",
      "Epoch 506/3000\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.0108 - val_loss: 0.0904\n",
      "Epoch 507/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0121 - val_loss: 0.0903\n",
      "Epoch 508/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0102 - val_loss: 0.0905\n",
      "Epoch 509/3000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.0109 - val_loss: 0.0906\n",
      "Epoch 510/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0116 - val_loss: 0.0908\n",
      "Epoch 511/3000\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0108 - val_loss: 0.0909\n",
      "Epoch 512/3000\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 0.0111 - val_loss: 0.0909\n",
      "Epoch 513/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0113 - val_loss: 0.0908\n",
      "Epoch 514/3000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0102 - val_loss: 0.0908\n",
      "Epoch 515/3000\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 0.0104 - val_loss: 0.0909\n",
      "Epoch 516/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0118 - val_loss: 0.0910\n",
      "Epoch 517/3000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0104 - val_loss: 0.0909\n",
      "Epoch 518/3000\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0107 - val_loss: 0.0912\n",
      "Epoch 519/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0113 - val_loss: 0.0917\n",
      "Epoch 520/3000\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0101 - val_loss: 0.0919\n",
      "Epoch 521/3000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.0103 - val_loss: 0.0920\n",
      "Epoch 522/3000\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.0103 - val_loss: 0.0917\n",
      "Epoch 523/3000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.0098 - val_loss: 0.0916\n",
      "Epoch 524/3000\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.0100 - val_loss: 0.0914\n",
      "Epoch 525/3000\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 0.0103 - val_loss: 0.0916\n",
      "Epoch 526/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0112 - val_loss: 0.0918\n",
      "Epoch 527/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0116 - val_loss: 0.0921\n",
      "Epoch 528/3000\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 0.0110 - val_loss: 0.0924\n",
      "Epoch 529/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0121 - val_loss: 0.0926\n",
      "Epoch 530/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0106 - val_loss: 0.0929\n",
      "Epoch 531/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0102 - val_loss: 0.0931\n",
      "Epoch 532/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0095 - val_loss: 0.0934\n",
      "Epoch 533/3000\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0107 - val_loss: 0.0937\n",
      "Epoch 534/3000\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.0106 - val_loss: 0.0940\n",
      "Epoch 535/3000\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0105 - val_loss: 0.0940\n",
      "Epoch 536/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0100 - val_loss: 0.0938\n",
      "Epoch 537/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0123 - val_loss: 0.0935\n",
      "Epoch 538/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0106 - val_loss: 0.0933\n",
      "Epoch 539/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0115 - val_loss: 0.0935\n",
      "Epoch 540/3000\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0126 - val_loss: 0.0933\n",
      "Epoch 541/3000\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.0095 - val_loss: 0.0931\n",
      "Epoch 542/3000\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.0093 - val_loss: 0.0932\n",
      "Epoch 543/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0109 - val_loss: 0.0935\n",
      "Epoch 544/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0108 - val_loss: 0.0939\n",
      "Epoch 545/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0108 - val_loss: 0.0941\n",
      "Epoch 546/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0106 - val_loss: 0.0942\n",
      "Epoch 547/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0104 - val_loss: 0.0943\n",
      "Epoch 548/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0110 - val_loss: 0.0945\n",
      "Epoch 549/3000\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.0111 - val_loss: 0.0948\n",
      "Epoch 550/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0102 - val_loss: 0.0951\n",
      "Epoch 551/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0102 - val_loss: 0.0952\n",
      "Epoch 552/3000\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0105 - val_loss: 0.0951\n",
      "Epoch 553/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0106 - val_loss: 0.0949\n",
      "Epoch 554/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0093 - val_loss: 0.0948\n",
      "Epoch 555/3000\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.0103 - val_loss: 0.0951\n",
      "Epoch 556/3000\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.0105 - val_loss: 0.0954\n",
      "Epoch 557/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0121 - val_loss: 0.0950\n",
      "Epoch 558/3000\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.0096 - val_loss: 0.0948\n",
      "Epoch 559/3000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0092 - val_loss: 0.0946\n",
      "Epoch 560/3000\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.0108 - val_loss: 0.0946\n",
      "Epoch 561/3000\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0121 - val_loss: 0.0942\n",
      "Epoch 562/3000\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.0103 - val_loss: 0.0941\n",
      "Epoch 563/3000\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.0100 - val_loss: 0.0939\n",
      "Epoch 564/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0100 - val_loss: 0.0940\n",
      "Epoch 565/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0091 - val_loss: 0.0943\n",
      "Epoch 566/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0101 - val_loss: 0.0949\n",
      "Epoch 567/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0104 - val_loss: 0.0952\n",
      "Epoch 568/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0109 - val_loss: 0.0952\n",
      "Epoch 569/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0102 - val_loss: 0.0948\n",
      "Epoch 570/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0102 - val_loss: 0.0942\n",
      "Epoch 571/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0102 - val_loss: 0.0939\n",
      "Epoch 572/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0103 - val_loss: 0.0941\n",
      "Epoch 573/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0092 - val_loss: 0.0944\n",
      "Epoch 574/3000\n",
      "1/1 [==============================] - 1s 812ms/step - loss: 0.0090 - val_loss: 0.0946\n",
      "Epoch 575/3000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.0105 - val_loss: 0.0947\n",
      "Epoch 576/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0096 - val_loss: 0.0949\n",
      "Epoch 577/3000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.0091 - val_loss: 0.0951\n",
      "Epoch 578/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0090 - val_loss: 0.0953\n",
      "Epoch 579/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0093 - val_loss: 0.0954\n",
      "Epoch 580/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0093 - val_loss: 0.0951\n",
      "Epoch 581/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0100 - val_loss: 0.0952\n",
      "Epoch 582/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0108 - val_loss: 0.0954\n",
      "Epoch 583/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0104 - val_loss: 0.0956\n",
      "Epoch 584/3000\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0106 - val_loss: 0.0955\n",
      "Epoch 585/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0095 - val_loss: 0.0959\n",
      "Epoch 586/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0105 - val_loss: 0.0965\n",
      "Epoch 587/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0100 - val_loss: 0.0969\n",
      "Epoch 588/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0101 - val_loss: 0.0970\n",
      "Epoch 589/3000\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.0114 - val_loss: 0.0968\n",
      "Epoch 590/3000\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0105 - val_loss: 0.0962\n",
      "Epoch 591/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0102 - val_loss: 0.0959\n",
      "Epoch 592/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0106 - val_loss: 0.0962\n",
      "Epoch 593/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0092 - val_loss: 0.0966\n",
      "Epoch 594/3000\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.0093 - val_loss: 0.0973\n",
      "Epoch 595/3000\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.0111 - val_loss: 0.0979\n",
      "Epoch 596/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0099 - val_loss: 0.0980\n",
      "Epoch 597/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0094 - val_loss: 0.0983\n",
      "Epoch 598/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0091 - val_loss: 0.0981\n",
      "Epoch 599/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0094 - val_loss: 0.0978\n",
      "Epoch 600/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0096 - val_loss: 0.0976\n",
      "Epoch 601/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0094 - val_loss: 0.0974\n",
      "Epoch 602/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0107 - val_loss: 0.0972\n",
      "Epoch 603/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0098 - val_loss: 0.0971\n",
      "Epoch 604/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0107 - val_loss: 0.0976\n",
      "Epoch 605/3000\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0091 - val_loss: 0.0980\n",
      "Epoch 606/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0108 - val_loss: 0.0976\n",
      "Epoch 607/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0080 - val_loss: 0.0971\n",
      "Epoch 608/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0102 - val_loss: 0.0967\n",
      "Epoch 609/3000\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0094 - val_loss: 0.0971\n",
      "Epoch 610/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0110 - val_loss: 0.0979\n",
      "Epoch 611/3000\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0103 - val_loss: 0.0985\n",
      "Epoch 612/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0092 - val_loss: 0.0990\n",
      "Epoch 613/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0108 - val_loss: 0.0996\n",
      "Epoch 614/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0100 - val_loss: 0.1005\n",
      "Epoch 615/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0104 - val_loss: 0.1012\n",
      "Epoch 616/3000\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.0096 - val_loss: 0.1020\n",
      "Epoch 617/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0089 - val_loss: 0.1026\n",
      "Epoch 618/3000\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.0098 - val_loss: 0.1031\n",
      "Epoch 619/3000\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0093 - val_loss: 0.1036\n",
      "Epoch 620/3000\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0110 - val_loss: 0.1037\n",
      "Epoch 621/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0103 - val_loss: 0.1038\n",
      "Epoch 622/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0096 - val_loss: 0.1041\n",
      "Epoch 623/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0090 - val_loss: 0.1043\n",
      "Epoch 624/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0086 - val_loss: 0.1046\n",
      "Epoch 625/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0088 - val_loss: 0.1048\n",
      "Epoch 626/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0100 - val_loss: 0.1045\n",
      "Epoch 627/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0085 - val_loss: 0.1038\n",
      "Epoch 628/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0096 - val_loss: 0.1037\n",
      "Epoch 629/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0095 - val_loss: 0.1039\n",
      "Epoch 630/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0101 - val_loss: 0.1034\n",
      "Epoch 631/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0097 - val_loss: 0.1028\n",
      "Epoch 632/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0094 - val_loss: 0.1016\n",
      "Epoch 633/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0087 - val_loss: 0.1005\n",
      "Epoch 634/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0088 - val_loss: 0.1001\n",
      "Epoch 635/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0092 - val_loss: 0.1004\n",
      "Epoch 636/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0099 - val_loss: 0.1012\n",
      "Epoch 637/3000\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0096 - val_loss: 0.1024\n",
      "Epoch 638/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0094 - val_loss: 0.1033\n",
      "Epoch 639/3000\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.0093 - val_loss: 0.1038\n",
      "Epoch 640/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0119 - val_loss: 0.1035\n",
      "Epoch 641/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0094 - val_loss: 0.1035\n",
      "Epoch 642/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0094 - val_loss: 0.1039\n",
      "Epoch 643/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0098 - val_loss: 0.1040\n",
      "Epoch 644/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0093 - val_loss: 0.1039\n",
      "Epoch 645/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0089 - val_loss: 0.1037\n",
      "Epoch 646/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0110 - val_loss: 0.1035\n",
      "Epoch 647/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0107 - val_loss: 0.1030\n",
      "Epoch 648/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0100 - val_loss: 0.1023\n",
      "Epoch 649/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0101 - val_loss: 0.1023\n",
      "Epoch 650/3000\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0092 - val_loss: 0.1023\n",
      "Epoch 651/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0088 - val_loss: 0.1028\n",
      "Epoch 652/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0099 - val_loss: 0.1038\n",
      "Epoch 653/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0098 - val_loss: 0.1052\n",
      "Epoch 654/3000\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.0081 - val_loss: 0.1066\n",
      "Epoch 655/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0094 - val_loss: 0.1071\n",
      "Epoch 656/3000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.0096 - val_loss: 0.1073\n",
      "Epoch 657/3000\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0097 - val_loss: 0.1072\n",
      "Epoch 658/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0086 - val_loss: 0.1066\n",
      "Epoch 659/3000\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.0086 - val_loss: 0.1064\n",
      "Epoch 660/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0084 - val_loss: 0.1056\n",
      "Epoch 661/3000\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.0086 - val_loss: 0.1049\n",
      "Epoch 662/3000\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.0096 - val_loss: 0.1047\n",
      "Epoch 663/3000\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.0091 - val_loss: 0.1049\n",
      "Epoch 664/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0095 - val_loss: 0.1052\n",
      "Epoch 665/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0090 - val_loss: 0.1054\n",
      "Epoch 666/3000\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.0085 - val_loss: 0.1056\n",
      "Epoch 667/3000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.0103 - val_loss: 0.1060\n",
      "Epoch 668/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0095 - val_loss: 0.1063\n",
      "Epoch 669/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0089 - val_loss: 0.1067\n",
      "Epoch 670/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0100 - val_loss: 0.1082\n",
      "Epoch 671/3000\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.0089 - val_loss: 0.1089\n",
      "Epoch 672/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0093 - val_loss: 0.1088\n",
      "Epoch 673/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0086 - val_loss: 0.1081\n",
      "Epoch 674/3000\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.0094 - val_loss: 0.1066\n",
      "Epoch 675/3000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.0085 - val_loss: 0.1059\n",
      "Epoch 676/3000\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.0089 - val_loss: 0.1057\n",
      "Epoch 677/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0094 - val_loss: 0.1065\n",
      "Epoch 678/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0091 - val_loss: 0.1075\n",
      "Epoch 679/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0088 - val_loss: 0.1085\n",
      "Epoch 680/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0083 - val_loss: 0.1092\n",
      "Epoch 681/3000\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.0099 - val_loss: 0.1095\n",
      "Epoch 682/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0097 - val_loss: 0.1097\n",
      "Epoch 683/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0080 - val_loss: 0.1102\n",
      "Epoch 684/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0095 - val_loss: 0.1106\n",
      "Epoch 685/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0078 - val_loss: 0.1105\n",
      "Epoch 686/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0088 - val_loss: 0.1104\n",
      "Epoch 687/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0094 - val_loss: 0.1107\n",
      "Epoch 688/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0085 - val_loss: 0.1104\n",
      "Epoch 689/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0092 - val_loss: 0.1098\n",
      "Epoch 690/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0070 - val_loss: 0.1088\n",
      "Epoch 691/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0092 - val_loss: 0.1076\n",
      "Epoch 692/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0088 - val_loss: 0.1070\n",
      "Epoch 693/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0092 - val_loss: 0.1069\n",
      "Epoch 694/3000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.0085 - val_loss: 0.1070\n",
      "Epoch 695/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0095 - val_loss: 0.1067\n",
      "Epoch 696/3000\n",
      "1/1 [==============================] - 1s 830ms/step - loss: 0.0095 - val_loss: 0.1066\n",
      "Epoch 697/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0084 - val_loss: 0.1069\n",
      "Epoch 698/3000\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 0.0081 - val_loss: 0.1076\n",
      "Epoch 699/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0089 - val_loss: 0.1086\n",
      "Epoch 700/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0089 - val_loss: 0.1093\n",
      "Epoch 701/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0088 - val_loss: 0.1100\n",
      "Epoch 702/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0083 - val_loss: 0.1106\n",
      "Epoch 703/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0087 - val_loss: 0.1102\n",
      "Epoch 704/3000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.0081 - val_loss: 0.1098\n",
      "Epoch 705/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0089 - val_loss: 0.1089\n",
      "Epoch 706/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0090 - val_loss: 0.1084\n",
      "Epoch 707/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0091 - val_loss: 0.1084\n",
      "Epoch 708/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0085 - val_loss: 0.1087\n",
      "Epoch 709/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0100 - val_loss: 0.1093\n",
      "Epoch 710/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0096 - val_loss: 0.1107\n",
      "Epoch 711/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0097 - val_loss: 0.1122\n",
      "Epoch 712/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0094 - val_loss: 0.1137\n",
      "Epoch 713/3000\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0099 - val_loss: 0.1140\n",
      "Epoch 714/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0094 - val_loss: 0.1137\n",
      "Epoch 715/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0082 - val_loss: 0.1128\n",
      "Epoch 716/3000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.0080 - val_loss: 0.1122\n",
      "Epoch 717/3000\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.0088 - val_loss: 0.1117\n",
      "Epoch 718/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0088 - val_loss: 0.1114\n",
      "Epoch 719/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0084 - val_loss: 0.1111\n",
      "Epoch 720/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0086 - val_loss: 0.1111\n",
      "Epoch 721/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0082 - val_loss: 0.1106\n",
      "Epoch 722/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0089 - val_loss: 0.1106\n",
      "Epoch 723/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0084 - val_loss: 0.1109\n",
      "Epoch 724/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0090 - val_loss: 0.1116\n",
      "Epoch 725/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0106 - val_loss: 0.1126\n",
      "Epoch 726/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0091 - val_loss: 0.1137\n",
      "Epoch 727/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0100 - val_loss: 0.1151\n",
      "Epoch 728/3000\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.0080 - val_loss: 0.1157\n",
      "Epoch 729/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0094 - val_loss: 0.1162\n",
      "Epoch 730/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0090 - val_loss: 0.1165\n",
      "Epoch 731/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0091 - val_loss: 0.1165\n",
      "Epoch 732/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0089 - val_loss: 0.1161\n",
      "Epoch 733/3000\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.0085 - val_loss: 0.1159\n",
      "Epoch 734/3000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.0089 - val_loss: 0.1158\n",
      "Epoch 735/3000\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.0079 - val_loss: 0.1157\n",
      "Epoch 736/3000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.0077 - val_loss: 0.1155\n",
      "Epoch 737/3000\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0081 - val_loss: 0.1153\n",
      "Epoch 738/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0082 - val_loss: 0.1156\n",
      "Epoch 739/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0080 - val_loss: 0.1161\n",
      "Epoch 740/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0095 - val_loss: 0.1168\n",
      "Epoch 741/3000\n",
      "1/1 [==============================] - 1s 836ms/step - loss: 0.0095 - val_loss: 0.1175\n",
      "Epoch 742/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0082 - val_loss: 0.1184\n",
      "Epoch 743/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0094 - val_loss: 0.1183\n",
      "Epoch 744/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0078 - val_loss: 0.1179\n",
      "Epoch 745/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0091 - val_loss: 0.1174\n",
      "Epoch 746/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0100 - val_loss: 0.1170\n",
      "Epoch 747/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0088 - val_loss: 0.1174\n",
      "Epoch 748/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0088 - val_loss: 0.1173\n",
      "Epoch 749/3000\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.0073 - val_loss: 0.1165\n",
      "Epoch 750/3000\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0074 - val_loss: 0.1158\n",
      "Epoch 751/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0083 - val_loss: 0.1158\n",
      "Epoch 752/3000\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.0085 - val_loss: 0.1160\n",
      "Epoch 753/3000\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 0.0078 - val_loss: 0.1168\n",
      "Epoch 754/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0081 - val_loss: 0.1175\n",
      "Epoch 755/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0084 - val_loss: 0.1181\n",
      "Epoch 756/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0081 - val_loss: 0.1181\n",
      "Epoch 757/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0083 - val_loss: 0.1184\n",
      "Epoch 758/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0090 - val_loss: 0.1189\n",
      "Epoch 759/3000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.0087 - val_loss: 0.1199\n",
      "Epoch 760/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0078 - val_loss: 0.1206\n",
      "Epoch 761/3000\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.0087 - val_loss: 0.1209\n",
      "Epoch 762/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0078 - val_loss: 0.1212\n",
      "Epoch 763/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0082 - val_loss: 0.1210\n",
      "Epoch 764/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0077 - val_loss: 0.1202\n",
      "Epoch 765/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0089 - val_loss: 0.1193\n",
      "Epoch 766/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0077 - val_loss: 0.1181\n",
      "Epoch 767/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0079 - val_loss: 0.1170\n",
      "Epoch 768/3000\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.0084 - val_loss: 0.1160\n",
      "Epoch 769/3000\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 0.0077 - val_loss: 0.1150\n",
      "Epoch 770/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0081 - val_loss: 0.1138\n",
      "Epoch 771/3000\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.0078 - val_loss: 0.1129\n",
      "Epoch 772/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0088 - val_loss: 0.1130\n",
      "Epoch 773/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0082 - val_loss: 0.1134\n",
      "Epoch 774/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0067 - val_loss: 0.1140\n",
      "Epoch 775/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0081 - val_loss: 0.1150\n",
      "Epoch 776/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0074 - val_loss: 0.1152\n",
      "Epoch 777/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0088 - val_loss: 0.1153\n",
      "Epoch 778/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0072 - val_loss: 0.1161\n",
      "Epoch 779/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0084 - val_loss: 0.1171\n",
      "Epoch 780/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0079 - val_loss: 0.1180\n",
      "Epoch 781/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0092 - val_loss: 0.1192\n",
      "Epoch 782/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0082 - val_loss: 0.1189\n",
      "Epoch 783/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0093 - val_loss: 0.1182\n",
      "Epoch 784/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0075 - val_loss: 0.1172\n",
      "Epoch 785/3000\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.0072 - val_loss: 0.1170\n",
      "Epoch 786/3000\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.0080 - val_loss: 0.1175\n",
      "Epoch 787/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0085 - val_loss: 0.1184\n",
      "Epoch 788/3000\n",
      "1/1 [==============================] - 1s 883ms/step - loss: 0.0079 - val_loss: 0.1196\n",
      "Epoch 789/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0083 - val_loss: 0.1202\n",
      "Epoch 790/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0076 - val_loss: 0.1211\n",
      "Epoch 791/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0070 - val_loss: 0.1227\n",
      "Epoch 792/3000\n",
      "1/1 [==============================] - 1s 838ms/step - loss: 0.0091 - val_loss: 0.1236\n",
      "Epoch 793/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0079 - val_loss: 0.1233\n",
      "Epoch 794/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0085 - val_loss: 0.1221\n",
      "Epoch 795/3000\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.0080 - val_loss: 0.1206\n",
      "Epoch 796/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0061 - val_loss: 0.1193\n",
      "Epoch 797/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0069 - val_loss: 0.1186\n",
      "Epoch 798/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0074 - val_loss: 0.1182\n",
      "Epoch 799/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0088 - val_loss: 0.1184\n",
      "Epoch 800/3000\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0084 - val_loss: 0.1191\n",
      "Epoch 801/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0083 - val_loss: 0.1202\n",
      "Epoch 802/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0085 - val_loss: 0.1208\n",
      "Epoch 803/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0080 - val_loss: 0.1216\n",
      "Epoch 804/3000\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0074 - val_loss: 0.1216\n",
      "Epoch 805/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0080 - val_loss: 0.1220\n",
      "Epoch 806/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0085 - val_loss: 0.1220\n",
      "Epoch 807/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0074 - val_loss: 0.1216\n",
      "Epoch 808/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0079 - val_loss: 0.1202\n",
      "Epoch 809/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0085 - val_loss: 0.1194\n",
      "Epoch 810/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0076 - val_loss: 0.1177\n",
      "Epoch 811/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0080 - val_loss: 0.1167\n",
      "Epoch 812/3000\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0085 - val_loss: 0.1163\n",
      "Epoch 813/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0078 - val_loss: 0.1164\n",
      "Epoch 814/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0081 - val_loss: 0.1169\n",
      "Epoch 815/3000\n",
      "1/1 [==============================] - 1s 832ms/step - loss: 0.0090 - val_loss: 0.1175\n",
      "Epoch 816/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0080 - val_loss: 0.1185\n",
      "Epoch 817/3000\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0079 - val_loss: 0.1198\n",
      "Epoch 818/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0078 - val_loss: 0.1206\n",
      "Epoch 819/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0084 - val_loss: 0.1205\n",
      "Epoch 820/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0074 - val_loss: 0.1206\n",
      "Epoch 821/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0074 - val_loss: 0.1204\n",
      "Epoch 822/3000\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.0077 - val_loss: 0.1205\n",
      "Epoch 823/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0082 - val_loss: 0.1200\n",
      "Epoch 824/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0082 - val_loss: 0.1199\n",
      "Epoch 825/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0075 - val_loss: 0.1192\n",
      "Epoch 826/3000\n",
      "1/1 [==============================] - 1s 810ms/step - loss: 0.0068 - val_loss: 0.1178\n",
      "Epoch 827/3000\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0092 - val_loss: 0.1167\n",
      "Epoch 828/3000\n",
      "1/1 [==============================] - 1s 815ms/step - loss: 0.0085 - val_loss: 0.1164\n",
      "Epoch 829/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0078 - val_loss: 0.1173\n",
      "Epoch 830/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0072 - val_loss: 0.1186\n",
      "Epoch 831/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0073 - val_loss: 0.1205\n",
      "Epoch 832/3000\n",
      "1/1 [==============================] - 1s 824ms/step - loss: 0.0075 - val_loss: 0.1224\n",
      "Epoch 833/3000\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.0097 - val_loss: 0.1232\n",
      "Epoch 834/3000\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.0071 - val_loss: 0.1236\n",
      "Epoch 835/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0091 - val_loss: 0.1232\n",
      "Epoch 836/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0079 - val_loss: 0.1235\n",
      "Epoch 837/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0067 - val_loss: 0.1240\n",
      "Epoch 838/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0087 - val_loss: 0.1239\n",
      "Epoch 839/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0086 - val_loss: 0.1226\n",
      "Epoch 840/3000\n",
      "1/1 [==============================] - 1s 820ms/step - loss: 0.0071 - val_loss: 0.1210\n",
      "Epoch 841/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0081 - val_loss: 0.1198\n",
      "Epoch 842/3000\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 0.0076 - val_loss: 0.1195\n",
      "Epoch 843/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0070 - val_loss: 0.1190\n",
      "Epoch 844/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0072 - val_loss: 0.1195\n",
      "Epoch 845/3000\n",
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0085 - val_loss: 0.1209\n",
      "Epoch 846/3000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.0069 - val_loss: 0.1225\n",
      "Epoch 847/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0077 - val_loss: 0.1226\n",
      "Epoch 848/3000\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.0087 - val_loss: 0.1229\n",
      "Epoch 849/3000\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0079 - val_loss: 0.1229\n",
      "Epoch 850/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0072 - val_loss: 0.1228\n",
      "Epoch 851/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0088 - val_loss: 0.1229\n",
      "Epoch 852/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0067 - val_loss: 0.1227\n",
      "Epoch 853/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0078 - val_loss: 0.1226\n",
      "Epoch 854/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0080 - val_loss: 0.1227\n",
      "Epoch 855/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0084 - val_loss: 0.1222\n",
      "Epoch 856/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0079 - val_loss: 0.1216\n",
      "Epoch 857/3000\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.0070 - val_loss: 0.1208\n",
      "Epoch 858/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0083 - val_loss: 0.1208\n",
      "Epoch 859/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0069 - val_loss: 0.1215\n",
      "Epoch 860/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0069 - val_loss: 0.1225\n",
      "Epoch 861/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0083 - val_loss: 0.1237\n",
      "Epoch 862/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0068 - val_loss: 0.1238\n",
      "Epoch 863/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0089 - val_loss: 0.1228\n",
      "Epoch 864/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0073 - val_loss: 0.1213\n",
      "Epoch 865/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0085 - val_loss: 0.1200\n",
      "Epoch 866/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0075 - val_loss: 0.1195\n",
      "Epoch 867/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0069 - val_loss: 0.1196\n",
      "Epoch 868/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0072 - val_loss: 0.1196\n",
      "Epoch 869/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0069 - val_loss: 0.1203\n",
      "Epoch 870/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0082 - val_loss: 0.1212\n",
      "Epoch 871/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0071 - val_loss: 0.1223\n",
      "Epoch 872/3000\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0066 - val_loss: 0.1234\n",
      "Epoch 873/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0073 - val_loss: 0.1247\n",
      "Epoch 874/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0083 - val_loss: 0.1263\n",
      "Epoch 875/3000\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0076 - val_loss: 0.1274\n",
      "Epoch 876/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0078 - val_loss: 0.1278\n",
      "Epoch 877/3000\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.0067 - val_loss: 0.1273\n",
      "Epoch 878/3000\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0080 - val_loss: 0.1264\n",
      "Epoch 879/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0070 - val_loss: 0.1250\n",
      "Epoch 880/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0072 - val_loss: 0.1243\n",
      "Epoch 881/3000\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0068 - val_loss: 0.1238\n",
      "Epoch 882/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0074 - val_loss: 0.1230\n",
      "Epoch 883/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0069 - val_loss: 0.1214\n",
      "Epoch 884/3000\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.0068 - val_loss: 0.1198\n",
      "Epoch 885/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0069 - val_loss: 0.1193\n",
      "Epoch 886/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0075 - val_loss: 0.1197\n",
      "Epoch 887/3000\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0081 - val_loss: 0.1206\n",
      "Epoch 888/3000\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.0071 - val_loss: 0.1216\n",
      "Epoch 889/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0080 - val_loss: 0.1226\n",
      "Epoch 890/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0072 - val_loss: 0.1238\n",
      "Epoch 891/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0088 - val_loss: 0.1261\n",
      "Epoch 892/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0078 - val_loss: 0.1272\n",
      "Epoch 893/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0076 - val_loss: 0.1275\n",
      "Epoch 894/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0066 - val_loss: 0.1266\n",
      "Epoch 895/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0073 - val_loss: 0.1253\n",
      "Epoch 896/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0074 - val_loss: 0.1239\n",
      "Epoch 897/3000\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0078 - val_loss: 0.1223\n",
      "Epoch 898/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0086 - val_loss: 0.1220\n",
      "Epoch 899/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0076 - val_loss: 0.1231\n",
      "Epoch 900/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0062 - val_loss: 0.1244\n",
      "Epoch 901/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0072 - val_loss: 0.1262\n",
      "Epoch 902/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0081 - val_loss: 0.1270\n",
      "Epoch 903/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0072 - val_loss: 0.1265\n",
      "Epoch 904/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0067 - val_loss: 0.1262\n",
      "Epoch 905/3000\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 0.0067 - val_loss: 0.1263\n",
      "Epoch 906/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0085 - val_loss: 0.1262\n",
      "Epoch 907/3000\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0064 - val_loss: 0.1267\n",
      "Epoch 908/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0072 - val_loss: 0.1262\n",
      "Epoch 909/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0071 - val_loss: 0.1252\n",
      "Epoch 910/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0068 - val_loss: 0.1242\n",
      "Epoch 911/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0077 - val_loss: 0.1232\n",
      "Epoch 912/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0079 - val_loss: 0.1222\n",
      "Epoch 913/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0079 - val_loss: 0.1218\n",
      "Epoch 914/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0069 - val_loss: 0.1219\n",
      "Epoch 915/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0072 - val_loss: 0.1226\n",
      "Epoch 916/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0057 - val_loss: 0.1237\n",
      "Epoch 917/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0061 - val_loss: 0.1248\n",
      "Epoch 918/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0073 - val_loss: 0.1258\n",
      "Epoch 919/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0065 - val_loss: 0.1262\n",
      "Epoch 920/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0066 - val_loss: 0.1268\n",
      "Epoch 921/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0078 - val_loss: 0.1265\n",
      "Epoch 922/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0078 - val_loss: 0.1261\n",
      "Epoch 923/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0062 - val_loss: 0.1254\n",
      "Epoch 924/3000\n",
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0063 - val_loss: 0.1250\n",
      "Epoch 925/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0084 - val_loss: 0.1250\n",
      "Epoch 926/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0066 - val_loss: 0.1244\n",
      "Epoch 927/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0070 - val_loss: 0.1236\n",
      "Epoch 928/3000\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.0065 - val_loss: 0.1226\n",
      "Epoch 929/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0073 - val_loss: 0.1220\n",
      "Epoch 930/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0068 - val_loss: 0.1211\n",
      "Epoch 931/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0063 - val_loss: 0.1213\n",
      "Epoch 932/3000\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.0070 - val_loss: 0.1222\n",
      "Epoch 933/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0067 - val_loss: 0.1240\n",
      "Epoch 934/3000\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0089 - val_loss: 0.1255\n",
      "Epoch 935/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0082 - val_loss: 0.1269\n",
      "Epoch 936/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0072 - val_loss: 0.1273\n",
      "Epoch 937/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0062 - val_loss: 0.1274\n",
      "Epoch 938/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0076 - val_loss: 0.1270\n",
      "Epoch 939/3000\n",
      "1/1 [==============================] - 1s 816ms/step - loss: 0.0074 - val_loss: 0.1259\n",
      "Epoch 940/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0061 - val_loss: 0.1247\n",
      "Epoch 941/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0068 - val_loss: 0.1239\n",
      "Epoch 942/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0066 - val_loss: 0.1237\n",
      "Epoch 943/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0079 - val_loss: 0.1242\n",
      "Epoch 944/3000\n",
      "1/1 [==============================] - 1s 828ms/step - loss: 0.0070 - val_loss: 0.1254\n",
      "Epoch 945/3000\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.0076 - val_loss: 0.1273\n",
      "Epoch 946/3000\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0064 - val_loss: 0.1283\n",
      "Epoch 947/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0076 - val_loss: 0.1298\n",
      "Epoch 948/3000\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.0077 - val_loss: 0.1310\n",
      "Epoch 949/3000\n",
      "1/1 [==============================] - 1s 999ms/step - loss: 0.0074 - val_loss: 0.1310\n",
      "Epoch 950/3000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0082 - val_loss: 0.1294\n",
      "Epoch 951/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0062 - val_loss: 0.1266\n",
      "Epoch 952/3000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.0056 - val_loss: 0.1251\n",
      "Epoch 953/3000\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.0081 - val_loss: 0.1240\n",
      "Epoch 954/3000\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.0066 - val_loss: 0.1234\n",
      "Epoch 955/3000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.0082 - val_loss: 0.1237\n",
      "Epoch 956/3000\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 0.0067 - val_loss: 0.1254\n",
      "Epoch 957/3000\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0058 - val_loss: 0.1269\n",
      "Epoch 958/3000\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0081 - val_loss: 0.1272\n",
      "Epoch 959/3000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0074 - val_loss: 0.1274\n",
      "Epoch 960/3000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.0066 - val_loss: 0.1278\n",
      "Epoch 961/3000\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0069 - val_loss: 0.1283\n",
      "Epoch 962/3000\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.0068 - val_loss: 0.1281\n",
      "Epoch 963/3000\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.0076 - val_loss: 0.1281\n",
      "Epoch 964/3000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.0069 - val_loss: 0.1278\n",
      "Epoch 965/3000\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0082 - val_loss: 0.1271\n",
      "Epoch 966/3000\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.0059 - val_loss: 0.1263\n",
      "Epoch 967/3000\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.0061 - val_loss: 0.1252\n",
      "Epoch 968/3000\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.0071 - val_loss: 0.1247\n",
      "Epoch 969/3000\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0064 - val_loss: 0.1243\n",
      "Epoch 970/3000\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.0067 - val_loss: 0.1248\n",
      "Epoch 971/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 917ms/step - loss: 0.0065 - val_loss: 0.1253\n",
      "Epoch 972/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0069 - val_loss: 0.1256\n",
      "Epoch 973/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0064 - val_loss: 0.1255\n",
      "Epoch 974/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0064 - val_loss: 0.1257\n",
      "Epoch 975/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0068 - val_loss: 0.1269\n",
      "Epoch 976/3000\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.0072 - val_loss: 0.1280\n",
      "Epoch 977/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0061 - val_loss: 0.1287\n",
      "Epoch 978/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0068 - val_loss: 0.1291\n",
      "Epoch 979/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0073 - val_loss: 0.1280\n",
      "Epoch 980/3000\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.0068 - val_loss: 0.1262\n",
      "Epoch 981/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0083 - val_loss: 0.1244\n",
      "Epoch 982/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0063 - val_loss: 0.1230\n",
      "Epoch 983/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0069 - val_loss: 0.1225\n",
      "Epoch 984/3000\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 0.0066 - val_loss: 0.1226\n",
      "Epoch 985/3000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0070 - val_loss: 0.1234\n",
      "Epoch 986/3000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.0066 - val_loss: 0.1236\n",
      "Epoch 987/3000\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0061 - val_loss: 0.1242\n",
      "Epoch 988/3000\n",
      "1/1 [==============================] - 1s 892ms/step - loss: 0.0068 - val_loss: 0.1252\n",
      "Epoch 989/3000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0067 - val_loss: 0.1264\n",
      "Epoch 990/3000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0056 - val_loss: 0.1270\n",
      "Epoch 991/3000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.0075 - val_loss: 0.1280\n",
      "Epoch 992/3000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.0074 - val_loss: 0.1290\n",
      "Epoch 993/3000\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.0068 - val_loss: 0.1296\n",
      "Epoch 994/3000\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.0062 - val_loss: 0.1280\n",
      "Epoch 995/3000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.0056 - val_loss: 0.1261\n",
      "Epoch 996/3000\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0068 - val_loss: 0.1239\n",
      "Epoch 997/3000\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0058 - val_loss: 0.1221\n",
      "Epoch 998/3000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0062 - val_loss: 0.1213\n",
      "Epoch 999/3000\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.0068 - val_loss: 0.1215\n",
      "Epoch 1000/3000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0068 - val_loss: 0.1222\n",
      "Epoch 1001/3000\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.0066 - val_loss: 0.1236\n",
      "Epoch 1002/3000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.0074 - val_loss: 0.1251\n",
      "Epoch 1003/3000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.0064 - val_loss: 0.1270\n",
      "Epoch 1004/3000\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0062 - val_loss: 0.1279\n",
      "Epoch 1005/3000\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 0.0073 - val_loss: 0.1290\n",
      "Epoch 1006/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0080 - val_loss: 0.1298\n",
      "Epoch 1007/3000\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 0.0062 - val_loss: 0.1298\n",
      "Epoch 1008/3000\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 0.0071 - val_loss: 0.1298\n",
      "Epoch 1009/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0076 - val_loss: 0.1293\n",
      "Epoch 1010/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0065 - val_loss: 0.1285\n",
      "Epoch 1011/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054 - val_loss: 0.1278\n",
      "Epoch 1012/3000\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0070 - val_loss: 0.1273\n",
      "Epoch 1013/3000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0070 - val_loss: 0.1265\n",
      "Epoch 1014/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0066 - val_loss: 0.1262\n",
      "Epoch 1015/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0066 - val_loss: 0.1255\n",
      "Epoch 1016/3000\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.0066 - val_loss: 0.1248\n",
      "Epoch 1017/3000\n",
      "1/1 [==============================] - 1s 837ms/step - loss: 0.0065 - val_loss: 0.1239\n",
      "Epoch 1018/3000\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.0062 - val_loss: 0.1233\n",
      "Epoch 1019/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0058 - val_loss: 0.1237\n",
      "Epoch 1020/3000\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 0.0067 - val_loss: 0.1243\n",
      "Epoch 1021/3000\n",
      "1/1 [==============================] - 1s 852ms/step - loss: 0.0072 - val_loss: 0.1245\n",
      "Epoch 1022/3000\n",
      "1/1 [==============================] - 1s 840ms/step - loss: 0.0068 - val_loss: 0.1246\n",
      "Epoch 1023/3000\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.0056 - val_loss: 0.1242\n",
      "Epoch 1024/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0063 - val_loss: 0.1228\n",
      "Epoch 1025/3000\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.0071 - val_loss: 0.1218\n",
      "Epoch 1026/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0065 - val_loss: 0.1211\n",
      "Epoch 1027/3000\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.0066 - val_loss: 0.1205\n",
      "Epoch 1028/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0063 - val_loss: 0.1198\n",
      "Epoch 1029/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0080 - val_loss: 0.1200\n",
      "Epoch 1030/3000\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 0.0063 - val_loss: 0.1208\n",
      "Epoch 1031/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0059 - val_loss: 0.1213\n",
      "Epoch 1032/3000\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.0058 - val_loss: 0.1223\n",
      "Epoch 1033/3000\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.0068 - val_loss: 0.1241\n",
      "Epoch 1034/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0063 - val_loss: 0.1259\n",
      "Epoch 1035/3000\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.0058 - val_loss: 0.1276\n",
      "Epoch 1036/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0070 - val_loss: 0.1287\n",
      "Epoch 1037/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0061 - val_loss: 0.1281\n",
      "Epoch 1038/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0062 - val_loss: 0.1274\n",
      "Epoch 1039/3000\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.0060 - val_loss: 0.1266\n",
      "Epoch 1040/3000\n",
      "1/1 [==============================] - 1s 845ms/step - loss: 0.0073 - val_loss: 0.1263\n",
      "Epoch 1041/3000\n",
      "1/1 [==============================] - 1s 879ms/step - loss: 0.0068 - val_loss: 0.1260\n",
      "Epoch 1042/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0061 - val_loss: 0.1258\n",
      "Epoch 1043/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0063 - val_loss: 0.1257\n",
      "Epoch 1044/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0063 - val_loss: 0.1260\n",
      "Epoch 1045/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0066 - val_loss: 0.1259\n",
      "Epoch 1046/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0071 - val_loss: 0.1259\n",
      "Epoch 1047/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0066 - val_loss: 0.1258\n",
      "Epoch 1048/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0061 - val_loss: 0.1262\n",
      "Epoch 1049/3000\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.0063 - val_loss: 0.1271\n",
      "Epoch 1050/3000\n",
      "1/1 [==============================] - 1s 822ms/step - loss: 0.0068 - val_loss: 0.1283\n",
      "Epoch 1051/3000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0065 - val_loss: 0.1289\n",
      "Epoch 1052/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0064 - val_loss: 0.1291\n",
      "Epoch 1053/3000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0067 - val_loss: 0.1287\n",
      "Epoch 1054/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0065 - val_loss: 0.1281\n",
      "Epoch 1055/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0060 - val_loss: 0.1273\n",
      "Epoch 1056/3000\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.0052 - val_loss: 0.1266\n",
      "Epoch 1057/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0059 - val_loss: 0.1270\n",
      "Epoch 1058/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0066 - val_loss: 0.1272\n",
      "Epoch 1059/3000\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.0057 - val_loss: 0.1275\n",
      "Epoch 1060/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0064 - val_loss: 0.1276\n",
      "Epoch 1061/3000\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.0066 - val_loss: 0.1277\n",
      "Epoch 1062/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0060 - val_loss: 0.1277\n",
      "Epoch 1063/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0067 - val_loss: 0.1274\n",
      "Epoch 1064/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0065 - val_loss: 0.1276\n",
      "Epoch 1065/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0068 - val_loss: 0.1283\n",
      "Epoch 1066/3000\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0066 - val_loss: 0.1281\n",
      "Epoch 1067/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0076 - val_loss: 0.1275\n",
      "Epoch 1068/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0060 - val_loss: 0.1269\n",
      "Epoch 1069/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0059 - val_loss: 0.1268\n",
      "Epoch 1070/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0061 - val_loss: 0.1271\n",
      "Epoch 1071/3000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.0058 - val_loss: 0.1281\n",
      "Epoch 1072/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0072 - val_loss: 0.1296\n",
      "Epoch 1073/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0066 - val_loss: 0.1307\n",
      "Epoch 1074/3000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0063 - val_loss: 0.1302\n",
      "Epoch 1075/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0067 - val_loss: 0.1290\n",
      "Epoch 1076/3000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.0064 - val_loss: 0.1270\n",
      "Epoch 1077/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0068 - val_loss: 0.1252\n",
      "Epoch 1078/3000\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.0056 - val_loss: 0.1239\n",
      "Epoch 1079/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0055 - val_loss: 0.1231\n",
      "Epoch 1080/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0059 - val_loss: 0.1228\n",
      "Epoch 1081/3000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.0049 - val_loss: 0.1228\n",
      "Epoch 1082/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0058 - val_loss: 0.1234\n",
      "Epoch 1083/3000\n",
      "1/1 [==============================] - 1s 847ms/step - loss: 0.0068 - val_loss: 0.1243\n",
      "Epoch 1084/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0064 - val_loss: 0.1255\n",
      "Epoch 1085/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0066 - val_loss: 0.1268\n",
      "Epoch 1086/3000\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 0.0062 - val_loss: 0.1274\n",
      "Epoch 1087/3000\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0056 - val_loss: 0.1286\n",
      "Epoch 1088/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0061 - val_loss: 0.1285\n",
      "Epoch 1089/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0054 - val_loss: 0.1281\n",
      "Epoch 1090/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0069 - val_loss: 0.1280\n",
      "Epoch 1091/3000\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.0060 - val_loss: 0.1275\n",
      "Epoch 1092/3000\n",
      "1/1 [==============================] - 1s 856ms/step - loss: 0.0060 - val_loss: 0.1263\n",
      "Epoch 1093/3000\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.0056 - val_loss: 0.1248\n",
      "Epoch 1094/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0057 - val_loss: 0.1235\n",
      "Epoch 1095/3000\n",
      "1/1 [==============================] - 1s 851ms/step - loss: 0.0059 - val_loss: 0.1222\n",
      "Epoch 1096/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0055 - val_loss: 0.1219\n",
      "Epoch 1097/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0063 - val_loss: 0.1212\n",
      "Epoch 1098/3000\n",
      "1/1 [==============================] - 1s 849ms/step - loss: 0.0070 - val_loss: 0.1208\n",
      "Epoch 1099/3000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0062 - val_loss: 0.1213\n",
      "Epoch 1100/3000\n",
      "1/1 [==============================] - 1s 819ms/step - loss: 0.0068 - val_loss: 0.1217\n",
      "Epoch 1101/3000\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 0.0060 - val_loss: 0.1229\n",
      "Epoch 1102/3000\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 0.0064 - val_loss: 0.1248\n",
      "Epoch 1103/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060 - val_loss: 0.1267\n",
      "Epoch 1104/3000\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.0076 - val_loss: 0.1278\n",
      "Epoch 1105/3000\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0066 - val_loss: 0.1287\n",
      "Epoch 1106/3000\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0065 - val_loss: 0.1281\n",
      "Epoch 1107/3000\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.0062 - val_loss: 0.1274\n",
      "Epoch 1108/3000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.0069 - val_loss: 0.1265\n",
      "Epoch 1109/3000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.0063 - val_loss: 0.1253\n",
      "Epoch 1110/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0055 - val_loss: 0.1241\n",
      "Epoch 1111/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0061 - val_loss: 0.1235\n",
      "Epoch 1112/3000\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.0069 - val_loss: 0.1239\n",
      "Epoch 1113/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0056 - val_loss: 0.1245\n",
      "Epoch 1114/3000\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 0.0060 - val_loss: 0.1256\n",
      "Epoch 1115/3000\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0053 - val_loss: 0.1266\n",
      "Epoch 1116/3000\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.0071 - val_loss: 0.1282\n",
      "Epoch 1117/3000\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0068 - val_loss: 0.1294\n",
      "Epoch 1118/3000\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0057 - val_loss: 0.1309\n",
      "Epoch 1119/3000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.0064 - val_loss: 0.1304\n",
      "Epoch 1120/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0064 - val_loss: 0.1281\n",
      "Epoch 1121/3000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.0063 - val_loss: 0.1256\n",
      "Epoch 1122/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0060 - val_loss: 0.1240\n",
      "Epoch 1123/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0062 - val_loss: 0.1237\n",
      "Epoch 1124/3000\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0059 - val_loss: 0.1247\n",
      "Epoch 1125/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0056 - val_loss: 0.1257\n",
      "Epoch 1126/3000\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.0046 - val_loss: 0.1268\n",
      "Epoch 1127/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0060 - val_loss: 0.1275\n",
      "Epoch 1128/3000\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.0055 - val_loss: 0.1274\n",
      "Epoch 1129/3000\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 0.0069 - val_loss: 0.1281\n",
      "Epoch 1130/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0052 - val_loss: 0.1290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1131/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0061 - val_loss: 0.1293\n",
      "Epoch 1132/3000\n",
      "1/1 [==============================] - 1s 853ms/step - loss: 0.0064 - val_loss: 0.1292\n",
      "Epoch 1133/3000\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 0.0063 - val_loss: 0.1287\n",
      "Epoch 1134/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0062 - val_loss: 0.1277\n",
      "Epoch 1135/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0060 - val_loss: 0.1271\n",
      "Epoch 1136/3000\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.0055 - val_loss: 0.1272\n",
      "Epoch 1137/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0064 - val_loss: 0.1269\n",
      "Epoch 1138/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0059 - val_loss: 0.1262\n",
      "Epoch 1139/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0063 - val_loss: 0.1260\n",
      "Epoch 1140/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0052 - val_loss: 0.1257\n",
      "Epoch 1141/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0063 - val_loss: 0.1252\n",
      "Epoch 1142/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0057 - val_loss: 0.1250\n",
      "Epoch 1143/3000\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 0.0059 - val_loss: 0.1250\n",
      "Epoch 1144/3000\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0053 - val_loss: 0.1245\n",
      "Epoch 1145/3000\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.0054 - val_loss: 0.1236\n",
      "Epoch 1146/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0070 - val_loss: 0.1235\n",
      "Epoch 1147/3000\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.0055 - val_loss: 0.1234\n",
      "Epoch 1148/3000\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.0057 - val_loss: 0.1239\n",
      "Epoch 1149/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0056 - val_loss: 0.1242\n",
      "Epoch 1150/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0065 - val_loss: 0.1246\n",
      "Epoch 1151/3000\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.0058 - val_loss: 0.1250\n",
      "Epoch 1152/3000\n",
      "1/1 [==============================] - 1s 866ms/step - loss: 0.0062 - val_loss: 0.1255\n",
      "Epoch 1153/3000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0053 - val_loss: 0.1266\n",
      "Epoch 1154/3000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.0066 - val_loss: 0.1277\n",
      "Epoch 1155/3000\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.0059 - val_loss: 0.1287\n",
      "Epoch 1156/3000\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 0.0055 - val_loss: 0.1293\n",
      "Epoch 1157/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054 - val_loss: 0.1295\n",
      "Epoch 1158/3000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0061 - val_loss: 0.1300\n",
      "Epoch 1159/3000\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 0.0053 - val_loss: 0.1286\n",
      "Epoch 1160/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0063 - val_loss: 0.1268\n",
      "Epoch 1161/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0063 - val_loss: 0.1265\n",
      "Epoch 1162/3000\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.0049 - val_loss: 0.1270\n",
      "Epoch 1163/3000\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.0053 - val_loss: 0.1276\n",
      "Epoch 1164/3000\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 0.0056 - val_loss: 0.1281\n",
      "Epoch 1165/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0056 - val_loss: 0.1283\n",
      "Epoch 1166/3000\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 0.0055 - val_loss: 0.1281\n",
      "Epoch 1167/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060 - val_loss: 0.1276\n",
      "Epoch 1168/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0063 - val_loss: 0.1263\n",
      "Epoch 1169/3000\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.0065 - val_loss: 0.1256\n",
      "Epoch 1170/3000\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.0062 - val_loss: 0.1255\n",
      "Epoch 1171/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0064 - val_loss: 0.1256\n",
      "Epoch 1172/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0068 - val_loss: 0.1259\n",
      "Epoch 1173/3000\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 0.0059 - val_loss: 0.1257\n",
      "Epoch 1174/3000\n",
      "1/1 [==============================] - 1s 863ms/step - loss: 0.0053 - val_loss: 0.1255\n",
      "Epoch 1175/3000\n",
      "1/1 [==============================] - 1s 865ms/step - loss: 0.0063 - val_loss: 0.1251\n",
      "Epoch 1176/3000\n",
      "1/1 [==============================] - 1s 871ms/step - loss: 0.0050 - val_loss: 0.1252\n",
      "Epoch 1177/3000\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.0055 - val_loss: 0.1256\n",
      "Epoch 1178/3000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0055 - val_loss: 0.1257\n",
      "Epoch 1179/3000\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0049 - val_loss: 0.1257\n",
      "Epoch 1180/3000\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 0.0063 - val_loss: 0.1257\n",
      "Epoch 1181/3000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.0049 - val_loss: 0.1256\n",
      "Epoch 1182/3000\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.0052 - val_loss: 0.1255\n",
      "Epoch 1183/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0063 - val_loss: 0.1258\n",
      "Epoch 1184/3000\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.0054 - val_loss: 0.1264\n",
      "Epoch 1185/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0059 - val_loss: 0.1265\n",
      "Epoch 1186/3000\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0057 - val_loss: 0.1266\n",
      "Epoch 1187/3000\n",
      "1/1 [==============================] - 1s 1000ms/step - loss: 0.0052 - val_loss: 0.1263\n",
      "Epoch 1188/3000\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.0053 - val_loss: 0.1270\n",
      "Epoch 1189/3000\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.0054 - val_loss: 0.1273\n",
      "Epoch 1190/3000\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.0058 - val_loss: 0.1273\n",
      "Epoch 1191/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0055 - val_loss: 0.1270\n",
      "Epoch 1192/3000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0062 - val_loss: 0.1271\n",
      "Epoch 1193/3000\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0056 - val_loss: 0.1272\n",
      "Epoch 1194/3000\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0056 - val_loss: 0.1274\n",
      "Epoch 1195/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0057 - val_loss: 0.1275\n",
      "Epoch 1196/3000\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 0.0047 - val_loss: 0.1272\n",
      "Epoch 1197/3000\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0051 - val_loss: 0.1266\n",
      "Epoch 1198/3000\n",
      "1/1 [==============================] - 1s 993ms/step - loss: 0.0058 - val_loss: 0.1249\n",
      "Epoch 1199/3000\n",
      "1/1 [==============================] - 1s 927ms/step - loss: 0.0057 - val_loss: 0.1235\n",
      "Epoch 1200/3000\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0054 - val_loss: 0.1223\n",
      "Epoch 1201/3000\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.0061 - val_loss: 0.1222\n",
      "Epoch 1202/3000\n",
      "1/1 [==============================] - 1s 986ms/step - loss: 0.0052 - val_loss: 0.1228\n",
      "Epoch 1203/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0057 - val_loss: 0.1234\n",
      "Epoch 1204/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0052 - val_loss: 0.1245\n",
      "Epoch 1205/3000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0052 - val_loss: 0.1265\n",
      "Epoch 1206/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0053 - val_loss: 0.1275\n",
      "Epoch 1207/3000\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0051 - val_loss: 0.1278\n",
      "Epoch 1208/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0052 - val_loss: 0.1282\n",
      "Epoch 1209/3000\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.0059 - val_loss: 0.1282\n",
      "Epoch 1210/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0052 - val_loss: 0.1278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1211/3000\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.0058 - val_loss: 0.1270\n",
      "Epoch 1212/3000\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0063 - val_loss: 0.1258\n",
      "Epoch 1213/3000\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0062 - val_loss: 0.1249\n",
      "Epoch 1214/3000\n",
      "1/1 [==============================] - 1s 886ms/step - loss: 0.0064 - val_loss: 0.1245\n",
      "Epoch 1215/3000\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.0052 - val_loss: 0.1238\n",
      "Epoch 1216/3000\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.0058 - val_loss: 0.1233\n",
      "Epoch 1217/3000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.0061 - val_loss: 0.1236\n",
      "Epoch 1218/3000\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 0.0062 - val_loss: 0.1259\n",
      "Epoch 1219/3000\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.0061 - val_loss: 0.1281\n",
      "Epoch 1220/3000\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 0.0051 - val_loss: 0.1297\n",
      "Epoch 1221/3000\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.0051 - val_loss: 0.1305\n",
      "Epoch 1222/3000\n",
      "1/1 [==============================] - 1s 897ms/step - loss: 0.0061 - val_loss: 0.1304\n",
      "Epoch 1223/3000\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.0052 - val_loss: 0.1300\n",
      "Epoch 1224/3000\n",
      "1/1 [==============================] - 1s 862ms/step - loss: 0.0059 - val_loss: 0.1289\n",
      "Epoch 1225/3000\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.0049 - val_loss: 0.1273\n",
      "Epoch 1226/3000\n",
      "1/1 [==============================] - 1s 873ms/step - loss: 0.0055 - val_loss: 0.1255\n",
      "Epoch 1227/3000\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.0059 - val_loss: 0.1237\n",
      "Epoch 1228/3000\n",
      "1/1 [==============================] - 1s 993ms/step - loss: 0.0055 - val_loss: 0.1234\n",
      "Epoch 1229/3000\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0060 - val_loss: 0.1243\n",
      "Epoch 1230/3000\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.0054 - val_loss: 0.1262\n",
      "Epoch 1231/3000\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 0.0065 - val_loss: 0.1289\n",
      "Epoch 1232/3000\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 0.0051 - val_loss: 0.1311\n",
      "Epoch 1233/3000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0059 - val_loss: 0.1316\n",
      "Epoch 1234/3000\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0055 - val_loss: 0.1309\n",
      "Epoch 1235/3000\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0055 - val_loss: 0.1287\n",
      "Epoch 1236/3000\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.0051 - val_loss: 0.1267\n",
      "Epoch 1237/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060 - val_loss: 0.1253\n",
      "Epoch 1238/3000\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.0052 - val_loss: 0.1243\n",
      "Epoch 1239/3000\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0060 - val_loss: 0.1240\n",
      "Epoch 1240/3000\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.0054 - val_loss: 0.1238\n",
      "Epoch 1241/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0059 - val_loss: 0.1236\n",
      "Epoch 1242/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0055 - val_loss: 0.1238\n",
      "Epoch 1243/3000\n",
      "1/1 [==============================] - 1s 864ms/step - loss: 0.0054 - val_loss: 0.1241\n",
      "Epoch 1244/3000\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.0057 - val_loss: 0.1252\n",
      "Epoch 1245/3000\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.0060 - val_loss: 0.1267\n",
      "Epoch 1246/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0056 - val_loss: 0.1282\n",
      "Epoch 1247/3000\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.0055 - val_loss: 0.1293\n",
      "Epoch 1248/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0060 - val_loss: 0.1296\n",
      "Epoch 1249/3000\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.0045 - val_loss: 0.1293\n",
      "Epoch 1250/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0061 - val_loss: 0.1290\n",
      "Epoch 1251/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0054 - val_loss: 0.1281\n",
      "Epoch 1252/3000\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0053 - val_loss: 0.1273\n",
      "Epoch 1253/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0053 - val_loss: 0.1262\n",
      "Epoch 1254/3000\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.0059 - val_loss: 0.1258\n",
      "Epoch 1255/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0061 - val_loss: 0.1262\n",
      "Epoch 1256/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0058 - val_loss: 0.1270\n",
      "Epoch 1257/3000\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.0057 - val_loss: 0.1281\n",
      "Epoch 1258/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0062 - val_loss: 0.1293\n",
      "Epoch 1259/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0050 - val_loss: 0.1301\n",
      "Epoch 1260/3000\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 0.0056 - val_loss: 0.1307\n",
      "Epoch 1261/3000\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.0051 - val_loss: 0.1303\n",
      "Epoch 1262/3000\n",
      "1/1 [==============================] - 1s 776ms/step - loss: 0.0056 - val_loss: 0.1304\n",
      "Epoch 1263/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0056 - val_loss: 0.1301\n",
      "Epoch 1264/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0055 - val_loss: 0.1293\n",
      "Epoch 1265/3000\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.0048 - val_loss: 0.1284\n",
      "Epoch 1266/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0061 - val_loss: 0.1274\n",
      "Epoch 1267/3000\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.0051 - val_loss: 0.1263\n",
      "Epoch 1268/3000\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.0055 - val_loss: 0.1256\n",
      "Epoch 1269/3000\n",
      "1/1 [==============================] - 1s 781ms/step - loss: 0.0061 - val_loss: 0.1257\n",
      "Epoch 1270/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0051 - val_loss: 0.1261\n",
      "Epoch 1271/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0051 - val_loss: 0.1258\n",
      "Epoch 1272/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0058 - val_loss: 0.1259\n",
      "Epoch 1273/3000\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 0.0060 - val_loss: 0.1264\n",
      "Epoch 1274/3000\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.0049 - val_loss: 0.1270\n",
      "Epoch 1275/3000\n",
      "1/1 [==============================] - 1s 783ms/step - loss: 0.0053 - val_loss: 0.1280\n",
      "Epoch 1276/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0062 - val_loss: 0.1296\n",
      "Epoch 1277/3000\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 0.0046 - val_loss: 0.1313\n",
      "Epoch 1278/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0057 - val_loss: 0.1325\n",
      "Epoch 1279/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0050 - val_loss: 0.1327\n",
      "Epoch 1280/3000\n",
      "1/1 [==============================] - 1s 787ms/step - loss: 0.0058 - val_loss: 0.1319\n",
      "Epoch 1281/3000\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.0049 - val_loss: 0.1313\n",
      "Epoch 1282/3000\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.0045 - val_loss: 0.1299\n",
      "Epoch 1283/3000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.0056 - val_loss: 0.1271\n",
      "Epoch 1284/3000\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.0059 - val_loss: 0.1240\n",
      "Epoch 1285/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0047 - val_loss: 0.1219\n",
      "Epoch 1286/3000\n",
      "1/1 [==============================] - 1s 817ms/step - loss: 0.0061 - val_loss: 0.1215\n",
      "Epoch 1287/3000\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.0059 - val_loss: 0.1220\n",
      "Epoch 1288/3000\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.0051 - val_loss: 0.1238\n",
      "Epoch 1289/3000\n",
      "1/1 [==============================] - 1s 778ms/step - loss: 0.0058 - val_loss: 0.1257\n",
      "Epoch 1290/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0055 - val_loss: 0.1283\n",
      "Epoch 1291/3000\n",
      "1/1 [==============================] - 1s 780ms/step - loss: 0.0055 - val_loss: 0.1302\n",
      "Epoch 1292/3000\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.0050 - val_loss: 0.1316\n",
      "Epoch 1293/3000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0050 - val_loss: 0.1329\n",
      "Epoch 1294/3000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0059 - val_loss: 0.1336\n",
      "Epoch 1295/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0049 - val_loss: 0.1326\n",
      "Epoch 1296/3000\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0054 - val_loss: 0.1314\n",
      "Epoch 1297/3000\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 0.0051 - val_loss: 0.1290\n",
      "Epoch 1298/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0050 - val_loss: 0.1270\n",
      "Epoch 1299/3000\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 0.0049 - val_loss: 0.1263\n",
      "Epoch 1300/3000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0048 - val_loss: 0.1264\n",
      "Epoch 1301/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0059 - val_loss: 0.1266\n",
      "Epoch 1302/3000\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0048 - val_loss: 0.1266\n",
      "Epoch 1303/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0055 - val_loss: 0.1263\n",
      "Epoch 1304/3000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0046 - val_loss: 0.1257\n",
      "Epoch 1305/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0050 - val_loss: 0.1247\n",
      "Epoch 1306/3000\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0052 - val_loss: 0.1249\n",
      "Epoch 1307/3000\n",
      "1/1 [==============================] - 1s 929ms/step - loss: 0.0045 - val_loss: 0.1250\n",
      "Epoch 1308/3000\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0050 - val_loss: 0.1260\n",
      "Epoch 1309/3000\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0066 - val_loss: 0.1270\n",
      "Epoch 1310/3000\n",
      "1/1 [==============================] - 1s 983ms/step - loss: 0.0058 - val_loss: 0.1279\n",
      "Epoch 1311/3000\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.0051 - val_loss: 0.1277\n",
      "Epoch 1312/3000\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.0047 - val_loss: 0.1281\n",
      "Epoch 1313/3000\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.0048 - val_loss: 0.1285\n",
      "Epoch 1314/3000\n",
      "1/1 [==============================] - 1s 859ms/step - loss: 0.0052 - val_loss: 0.1289\n",
      "Epoch 1315/3000\n",
      "1/1 [==============================] - 1s 881ms/step - loss: 0.0049 - val_loss: 0.1290\n",
      "Epoch 1316/3000\n",
      "1/1 [==============================] - 1s 870ms/step - loss: 0.0048 - val_loss: 0.1285\n",
      "Epoch 1317/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0060 - val_loss: 0.1276\n",
      "Epoch 1318/3000\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.0059 - val_loss: 0.1264\n",
      "Epoch 1319/3000\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 0.0059 - val_loss: 0.1252\n",
      "Epoch 1320/3000\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.0053 - val_loss: 0.1245\n",
      "Epoch 1321/3000\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.0050 - val_loss: 0.1247\n",
      "Epoch 1322/3000\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.0047 - val_loss: 0.1250\n",
      "Epoch 1323/3000\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0043 - val_loss: 0.1258\n",
      "Epoch 1324/3000\n",
      "1/1 [==============================] - 1s 988ms/step - loss: 0.0050 - val_loss: 0.1270\n",
      "Epoch 1325/3000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0053 - val_loss: 0.1277\n",
      "Epoch 1326/3000\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.0053 - val_loss: 0.1271\n",
      "Epoch 1327/3000\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 0.0049 - val_loss: 0.1269\n",
      "Epoch 1328/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0051 - val_loss: 0.1272\n",
      "Epoch 1329/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0052 - val_loss: 0.1274\n",
      "Epoch 1330/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0052 - val_loss: 0.1277\n",
      "Epoch 1331/3000\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0053 - val_loss: 0.1280\n",
      "Epoch 1332/3000\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.0054 - val_loss: 0.1288\n",
      "Epoch 1333/3000\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0054 - val_loss: 0.1297\n",
      "Epoch 1334/3000\n",
      "1/1 [==============================] - 1s 997ms/step - loss: 0.0048 - val_loss: 0.1302\n",
      "Epoch 1335/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054 - val_loss: 0.1294\n",
      "Epoch 1336/3000\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0054 - val_loss: 0.1273\n",
      "Epoch 1337/3000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0049 - val_loss: 0.1249\n",
      "Epoch 1338/3000\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.0052 - val_loss: 0.1238\n",
      "Epoch 1339/3000\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 0.0064 - val_loss: 0.1234\n",
      "Epoch 1340/3000\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0049 - val_loss: 0.1239\n",
      "Epoch 1341/3000\n",
      "1/1 [==============================] - 1s 998ms/step - loss: 0.0049 - val_loss: 0.1250\n",
      "Epoch 1342/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0069 - val_loss: 0.1269\n",
      "Epoch 1343/3000\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0052 - val_loss: 0.1291\n",
      "Epoch 1344/3000\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0046 - val_loss: 0.1308\n",
      "Epoch 1345/3000\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0059 - val_loss: 0.1304\n",
      "Epoch 1346/3000\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 0.0056 - val_loss: 0.1295\n",
      "Epoch 1347/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0050 - val_loss: 0.1287\n",
      "Epoch 1348/3000\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0051 - val_loss: 0.1289\n",
      "Epoch 1349/3000\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0048 - val_loss: 0.1288\n",
      "Epoch 1350/3000\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.0051 - val_loss: 0.1281\n",
      "Epoch 1351/3000\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.0053 - val_loss: 0.1275\n",
      "Epoch 1352/3000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0054 - val_loss: 0.1270\n",
      "Epoch 1353/3000\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0056 - val_loss: 0.1262\n",
      "Epoch 1354/3000\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "history1 = model1.fit(array_X,y_train, batch_size = 1000, epochs = 3000,verbose=1,validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f3a6ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model loss of Resnet50')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7e396ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#round 2 \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model loss of Resnet50')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c8915b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.1403940080788417\n",
      "RMSE =  0.3746918841913202\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(array_X_test)\n",
    "m = mean_squared_error(y_test,y_pred)\n",
    "r = math.sqrt(m)\n",
    "print('MSE of Resnet50 : ',m)\n",
    "print('RMSE of Resnet50 : ',r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e7fde9",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b696d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef46c39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 512)               20024384  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 20,057,411\n",
      "Trainable params: 33,027\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "vgg_19 = VGG19(include_top=False,\n",
    "                  input_shape=(64,64,3),\n",
    "                  pooling='avg',classes=5,\n",
    "                  weights = 'imagenet')\n",
    "for layer in vgg_19.layers:\n",
    "    layer.trainable=False\n",
    "model2.add(vgg_19)\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='tanh'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "model2.compile(loss='mse',\n",
    "              optimizer='adam')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf39ae4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3349: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1035 - val_loss: 0.0847\n",
      "Epoch 2/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0937 - val_loss: 0.0869\n",
      "Epoch 3/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0955 - val_loss: 0.0999\n",
      "Epoch 4/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0877 - val_loss: 0.0989\n",
      "Epoch 5/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - val_loss: 0.0906\n",
      "Epoch 6/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0893 - val_loss: 0.0842\n",
      "Epoch 7/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0813 - val_loss: 0.0823\n",
      "Epoch 8/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0873 - val_loss: 0.0835\n",
      "Epoch 9/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0800 - val_loss: 0.0841\n",
      "Epoch 10/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0848 - val_loss: 0.0835\n",
      "Epoch 11/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0769 - val_loss: 0.0821\n",
      "Epoch 12/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0793 - val_loss: 0.0813\n",
      "Epoch 13/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0720 - val_loss: 0.0817\n",
      "Epoch 14/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0730 - val_loss: 0.0827\n",
      "Epoch 15/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0710 - val_loss: 0.0831\n",
      "Epoch 16/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0726 - val_loss: 0.0824\n",
      "Epoch 17/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0689 - val_loss: 0.0811\n",
      "Epoch 18/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0675 - val_loss: 0.0801\n",
      "Epoch 19/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0687 - val_loss: 0.0800\n",
      "Epoch 20/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0682 - val_loss: 0.0801\n",
      "Epoch 21/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0635 - val_loss: 0.0800\n",
      "Epoch 22/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0653 - val_loss: 0.0798\n",
      "Epoch 23/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0641 - val_loss: 0.0798\n",
      "Epoch 24/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0626 - val_loss: 0.0802\n",
      "Epoch 25/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0613 - val_loss: 0.0808\n",
      "Epoch 26/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0613 - val_loss: 0.0808\n",
      "Epoch 27/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0611 - val_loss: 0.0802\n",
      "Epoch 28/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0631 - val_loss: 0.0798\n",
      "Epoch 29/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0619 - val_loss: 0.0798\n",
      "Epoch 30/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0618 - val_loss: 0.0799\n",
      "Epoch 31/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0608 - val_loss: 0.0798\n",
      "Epoch 32/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0616 - val_loss: 0.0797\n",
      "Epoch 33/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0612 - val_loss: 0.0799\n",
      "Epoch 34/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0605 - val_loss: 0.0806\n",
      "Epoch 35/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0608 - val_loss: 0.0811\n",
      "Epoch 36/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0580 - val_loss: 0.0810\n",
      "Epoch 37/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0575 - val_loss: 0.0807\n",
      "Epoch 38/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0598 - val_loss: 0.0806\n",
      "Epoch 39/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0596 - val_loss: 0.0804\n",
      "Epoch 40/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0604 - val_loss: 0.0804\n",
      "Epoch 41/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0587 - val_loss: 0.0805\n",
      "Epoch 42/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0602 - val_loss: 0.0809\n",
      "Epoch 43/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0583 - val_loss: 0.0814\n",
      "Epoch 44/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0584 - val_loss: 0.0818\n",
      "Epoch 45/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0577 - val_loss: 0.0819\n",
      "Epoch 46/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0594 - val_loss: 0.0814\n",
      "Epoch 47/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0564 - val_loss: 0.0810\n",
      "Epoch 48/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0574 - val_loss: 0.0808\n",
      "Epoch 49/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0567 - val_loss: 0.0809\n",
      "Epoch 50/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0577 - val_loss: 0.0810\n",
      "Epoch 51/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0564 - val_loss: 0.0815\n",
      "Epoch 52/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0556 - val_loss: 0.0818\n",
      "Epoch 53/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0588 - val_loss: 0.0818\n",
      "Epoch 54/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0598 - val_loss: 0.0816\n",
      "Epoch 55/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0564 - val_loss: 0.0815\n",
      "Epoch 56/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0564 - val_loss: 0.0815\n",
      "Epoch 57/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0563 - val_loss: 0.0816\n",
      "Epoch 58/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0574 - val_loss: 0.0818\n",
      "Epoch 59/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0571 - val_loss: 0.0820\n",
      "Epoch 60/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0559 - val_loss: 0.0820\n",
      "Epoch 61/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0574 - val_loss: 0.0818\n",
      "Epoch 62/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0555 - val_loss: 0.0816\n",
      "Epoch 63/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0565 - val_loss: 0.0815\n",
      "Epoch 64/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0571 - val_loss: 0.0816\n",
      "Epoch 65/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0566 - val_loss: 0.0818\n",
      "Epoch 66/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0560 - val_loss: 0.0821\n",
      "Epoch 67/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0547 - val_loss: 0.0823\n",
      "Epoch 68/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0559 - val_loss: 0.0823\n",
      "Epoch 69/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0547 - val_loss: 0.0822\n",
      "Epoch 70/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0561 - val_loss: 0.0820\n",
      "Epoch 71/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0566 - val_loss: 0.0821\n",
      "Epoch 72/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0554 - val_loss: 0.0825\n",
      "Epoch 73/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0575 - val_loss: 0.0825\n",
      "Epoch 74/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0538 - val_loss: 0.0823\n",
      "Epoch 75/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0539 - val_loss: 0.0821\n",
      "Epoch 76/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0543 - val_loss: 0.0822\n",
      "Epoch 77/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0533 - val_loss: 0.0823\n",
      "Epoch 78/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0547 - val_loss: 0.0824\n",
      "Epoch 79/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0552 - val_loss: 0.0827\n",
      "Epoch 80/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0548 - val_loss: 0.0828\n",
      "Epoch 81/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0547 - val_loss: 0.0826\n",
      "Epoch 82/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0534 - val_loss: 0.0823\n",
      "Epoch 83/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0544 - val_loss: 0.0822\n",
      "Epoch 84/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0542 - val_loss: 0.0822\n",
      "Epoch 85/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0536 - val_loss: 0.0823\n",
      "Epoch 86/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0549 - val_loss: 0.0825\n",
      "Epoch 87/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0537 - val_loss: 0.0827\n",
      "Epoch 88/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0534 - val_loss: 0.0827\n",
      "Epoch 89/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0551 - val_loss: 0.0825\n",
      "Epoch 90/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0554 - val_loss: 0.0822\n",
      "Epoch 91/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0525 - val_loss: 0.0821\n",
      "Epoch 92/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0544 - val_loss: 0.0823\n",
      "Epoch 93/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0534 - val_loss: 0.0827\n",
      "Epoch 94/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0541 - val_loss: 0.0829\n",
      "Epoch 95/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0544 - val_loss: 0.0827\n",
      "Epoch 96/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0555 - val_loss: 0.0824\n",
      "Epoch 97/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0540 - val_loss: 0.0823\n",
      "Epoch 98/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0532 - val_loss: 0.0823\n",
      "Epoch 99/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0516 - val_loss: 0.0825\n",
      "Epoch 100/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0537 - val_loss: 0.0826\n",
      "Epoch 101/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0524 - val_loss: 0.0827\n",
      "Epoch 102/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0534 - val_loss: 0.0828\n",
      "Epoch 103/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0531 - val_loss: 0.0826\n",
      "Epoch 104/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0517 - val_loss: 0.0825\n",
      "Epoch 105/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0512 - val_loss: 0.0826\n",
      "Epoch 106/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0535 - val_loss: 0.0828\n",
      "Epoch 107/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0529 - val_loss: 0.0827\n",
      "Epoch 108/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0524 - val_loss: 0.0823\n",
      "Epoch 109/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0525 - val_loss: 0.0822\n",
      "Epoch 110/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0533 - val_loss: 0.0821\n",
      "Epoch 111/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0527 - val_loss: 0.0823\n",
      "Epoch 112/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0529 - val_loss: 0.0827\n",
      "Epoch 113/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0524 - val_loss: 0.0827\n",
      "Epoch 114/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0512 - val_loss: 0.0824\n",
      "Epoch 115/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0508 - val_loss: 0.0822\n",
      "Epoch 116/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0529 - val_loss: 0.0822\n",
      "Epoch 117/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0511 - val_loss: 0.0825\n",
      "Epoch 118/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0528 - val_loss: 0.0829\n",
      "Epoch 119/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0532 - val_loss: 0.0832\n",
      "Epoch 120/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0518 - val_loss: 0.0830\n",
      "Epoch 121/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0510 - val_loss: 0.0825\n",
      "Epoch 122/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0510 - val_loss: 0.0822\n",
      "Epoch 123/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0524 - val_loss: 0.0821\n",
      "Epoch 124/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0506 - val_loss: 0.0824\n",
      "Epoch 125/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0508 - val_loss: 0.0828\n",
      "Epoch 126/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0514 - val_loss: 0.0827\n",
      "Epoch 127/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0513 - val_loss: 0.0824\n",
      "Epoch 128/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0496 - val_loss: 0.0821\n",
      "Epoch 129/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0526 - val_loss: 0.0820\n",
      "Epoch 130/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0510 - val_loss: 0.0821\n",
      "Epoch 131/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0518 - val_loss: 0.0824\n",
      "Epoch 132/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0503 - val_loss: 0.0829\n",
      "Epoch 133/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0515 - val_loss: 0.0831\n",
      "Epoch 134/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0514 - val_loss: 0.0826\n",
      "Epoch 135/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0499 - val_loss: 0.0821\n",
      "Epoch 136/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0501 - val_loss: 0.0820\n",
      "Epoch 137/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0511 - val_loss: 0.0820\n",
      "Epoch 138/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0503 - val_loss: 0.0822\n",
      "Epoch 139/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0518 - val_loss: 0.0824\n",
      "Epoch 140/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0513 - val_loss: 0.0824\n",
      "Epoch 141/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0509 - val_loss: 0.0823\n",
      "Epoch 142/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0504 - val_loss: 0.0821\n",
      "Epoch 143/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0503 - val_loss: 0.0821\n",
      "Epoch 144/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0500 - val_loss: 0.0823\n",
      "Epoch 145/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0480 - val_loss: 0.0824\n",
      "Epoch 146/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0492 - val_loss: 0.0825\n",
      "Epoch 147/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0500 - val_loss: 0.0825\n",
      "Epoch 148/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0497 - val_loss: 0.0824\n",
      "Epoch 149/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0492 - val_loss: 0.0824\n",
      "Epoch 150/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0496 - val_loss: 0.0824\n",
      "Epoch 151/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0505 - val_loss: 0.0825\n",
      "Epoch 152/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0518 - val_loss: 0.0826\n",
      "Epoch 153/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0490 - val_loss: 0.0827\n",
      "Epoch 154/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0500 - val_loss: 0.0826\n",
      "Epoch 155/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0492 - val_loss: 0.0826\n",
      "Epoch 156/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0493 - val_loss: 0.0828\n",
      "Epoch 157/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0512 - val_loss: 0.0827\n",
      "Epoch 158/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0482 - val_loss: 0.0826\n",
      "Epoch 159/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0489 - val_loss: 0.0827\n",
      "Epoch 160/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0507 - val_loss: 0.0827\n",
      "Epoch 161/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0499 - val_loss: 0.0826\n",
      "Epoch 162/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0491 - val_loss: 0.0825\n",
      "Epoch 163/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0499 - val_loss: 0.0827\n",
      "Epoch 164/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0489 - val_loss: 0.0828\n",
      "Epoch 165/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0501 - val_loss: 0.0827\n",
      "Epoch 166/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0484 - val_loss: 0.0826\n",
      "Epoch 167/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0479 - val_loss: 0.0827\n",
      "Epoch 168/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0496 - val_loss: 0.0826\n",
      "Epoch 169/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0479 - val_loss: 0.0827\n",
      "Epoch 170/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0496 - val_loss: 0.0829\n",
      "Epoch 171/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0489 - val_loss: 0.0828\n",
      "Epoch 172/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0486 - val_loss: 0.0826\n",
      "Epoch 173/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0494 - val_loss: 0.0827\n",
      "Epoch 174/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0477 - val_loss: 0.0827\n",
      "Epoch 175/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0481 - val_loss: 0.0829\n",
      "Epoch 176/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0487 - val_loss: 0.0830\n",
      "Epoch 177/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0489 - val_loss: 0.0828\n",
      "Epoch 178/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0476 - val_loss: 0.0827\n",
      "Epoch 179/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0477 - val_loss: 0.0827\n",
      "Epoch 180/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0480 - val_loss: 0.0828\n",
      "Epoch 181/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0476 - val_loss: 0.0830\n",
      "Epoch 182/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0479 - val_loss: 0.0830\n",
      "Epoch 183/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0474 - val_loss: 0.0829\n",
      "Epoch 184/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0479 - val_loss: 0.0829\n",
      "Epoch 185/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0472 - val_loss: 0.0829\n",
      "Epoch 186/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0480 - val_loss: 0.0827\n",
      "Epoch 187/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0492 - val_loss: 0.0828\n",
      "Epoch 188/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0456 - val_loss: 0.0831\n",
      "Epoch 189/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0485 - val_loss: 0.0830\n",
      "Epoch 190/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0480 - val_loss: 0.0829\n",
      "Epoch 191/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0492 - val_loss: 0.0828\n",
      "Epoch 192/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0488 - val_loss: 0.0828\n",
      "Epoch 193/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0470 - val_loss: 0.0829\n",
      "Epoch 194/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0477 - val_loss: 0.0829\n",
      "Epoch 195/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0475 - val_loss: 0.0828\n",
      "Epoch 196/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0472 - val_loss: 0.0829\n",
      "Epoch 197/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0460 - val_loss: 0.0829\n",
      "Epoch 198/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0470 - val_loss: 0.0829\n",
      "Epoch 199/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0460 - val_loss: 0.0828\n",
      "Epoch 200/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0477 - val_loss: 0.0830\n",
      "Epoch 201/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0459 - val_loss: 0.0830\n",
      "Epoch 202/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0478 - val_loss: 0.0830\n",
      "Epoch 203/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0461 - val_loss: 0.0831\n",
      "Epoch 204/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0473 - val_loss: 0.0831\n",
      "Epoch 205/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0449 - val_loss: 0.0831\n",
      "Epoch 206/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0457 - val_loss: 0.0830\n",
      "Epoch 207/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - val_loss: 0.0832\n",
      "Epoch 208/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0462 - val_loss: 0.0833\n",
      "Epoch 209/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0475 - val_loss: 0.0832\n",
      "Epoch 210/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0451 - val_loss: 0.0830\n",
      "Epoch 211/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0468 - val_loss: 0.0830\n",
      "Epoch 212/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0462 - val_loss: 0.0831\n",
      "Epoch 213/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0463 - val_loss: 0.0836\n",
      "Epoch 214/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0468 - val_loss: 0.0837\n",
      "Epoch 215/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0461 - val_loss: 0.0832\n",
      "Epoch 216/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0457 - val_loss: 0.0831\n",
      "Epoch 217/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0465 - val_loss: 0.0831\n",
      "Epoch 218/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0455 - val_loss: 0.0833\n",
      "Epoch 219/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0457 - val_loss: 0.0839\n",
      "Epoch 220/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0455 - val_loss: 0.0838\n",
      "Epoch 221/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0469 - val_loss: 0.0832\n",
      "Epoch 222/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0454 - val_loss: 0.0831\n",
      "Epoch 223/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0463 - val_loss: 0.0831\n",
      "Epoch 224/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0459 - val_loss: 0.0833\n",
      "Epoch 225/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0474 - val_loss: 0.0838\n",
      "Epoch 226/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0447 - val_loss: 0.0835\n",
      "Epoch 227/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0458 - val_loss: 0.0832\n",
      "Epoch 228/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0459 - val_loss: 0.0832\n",
      "Epoch 229/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0464 - val_loss: 0.0833\n",
      "Epoch 230/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0442 - val_loss: 0.0835\n",
      "Epoch 231/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - val_loss: 0.0838\n",
      "Epoch 232/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - val_loss: 0.0836\n",
      "Epoch 233/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0437 - val_loss: 0.0832\n",
      "Epoch 234/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - val_loss: 0.0833\n",
      "Epoch 235/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0460 - val_loss: 0.0834\n",
      "Epoch 236/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0444 - val_loss: 0.0837\n",
      "Epoch 237/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0454 - val_loss: 0.0840\n",
      "Epoch 238/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - val_loss: 0.0835\n",
      "Epoch 239/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0458 - val_loss: 0.0835\n",
      "Epoch 240/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0460 - val_loss: 0.0835\n",
      "Epoch 241/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0463 - val_loss: 0.0834\n",
      "Epoch 242/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0454 - val_loss: 0.0841\n",
      "Epoch 243/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0442 - val_loss: 0.0840\n",
      "Epoch 244/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0463 - val_loss: 0.0835\n",
      "Epoch 245/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0439 - val_loss: 0.0835\n",
      "Epoch 246/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0460 - val_loss: 0.0835\n",
      "Epoch 247/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0454 - val_loss: 0.0836\n",
      "Epoch 248/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0447 - val_loss: 0.0837\n",
      "Epoch 249/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0460 - val_loss: 0.0837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - val_loss: 0.0837\n",
      "Epoch 251/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0443 - val_loss: 0.0837\n",
      "Epoch 252/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0434 - val_loss: 0.0836\n",
      "Epoch 253/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0448 - val_loss: 0.0837\n",
      "Epoch 254/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0452 - val_loss: 0.0838\n",
      "Epoch 255/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0432 - val_loss: 0.0839\n",
      "Epoch 256/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0446 - val_loss: 0.0838\n",
      "Epoch 257/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0438 - val_loss: 0.0838\n",
      "Epoch 258/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0431 - val_loss: 0.0839\n",
      "Epoch 259/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0437 - val_loss: 0.0839\n",
      "Epoch 260/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - val_loss: 0.0842\n",
      "Epoch 261/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0447 - val_loss: 0.0841\n",
      "Epoch 262/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0434 - val_loss: 0.0839\n",
      "Epoch 263/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0432 - val_loss: 0.0840\n",
      "Epoch 264/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - val_loss: 0.0841\n",
      "Epoch 265/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0446 - val_loss: 0.0841\n",
      "Epoch 266/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0437 - val_loss: 0.0841\n",
      "Epoch 267/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - val_loss: 0.0841\n",
      "Epoch 268/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0445 - val_loss: 0.0841\n",
      "Epoch 269/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0430 - val_loss: 0.0841\n",
      "Epoch 270/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0430 - val_loss: 0.0843\n",
      "Epoch 271/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0420 - val_loss: 0.0843\n",
      "Epoch 272/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0425 - val_loss: 0.0843\n",
      "Epoch 273/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0426 - val_loss: 0.0842\n",
      "Epoch 274/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0427 - val_loss: 0.0842\n",
      "Epoch 275/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0843\n",
      "Epoch 276/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0845\n",
      "Epoch 277/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - val_loss: 0.0844\n",
      "Epoch 278/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0845\n",
      "Epoch 279/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0429 - val_loss: 0.0845\n",
      "Epoch 280/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0846\n",
      "Epoch 281/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0411 - val_loss: 0.0847\n",
      "Epoch 282/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0424 - val_loss: 0.0847\n",
      "Epoch 283/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0408 - val_loss: 0.0847\n",
      "Epoch 284/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0417 - val_loss: 0.0846\n",
      "Epoch 285/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0407 - val_loss: 0.0848\n",
      "Epoch 286/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0848\n",
      "Epoch 287/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0426 - val_loss: 0.0847\n",
      "Epoch 288/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0431 - val_loss: 0.0847\n",
      "Epoch 289/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0435 - val_loss: 0.0847\n",
      "Epoch 290/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0399 - val_loss: 0.0848\n",
      "Epoch 291/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0413 - val_loss: 0.0849\n",
      "Epoch 292/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0848\n",
      "Epoch 293/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0441 - val_loss: 0.0849\n",
      "Epoch 294/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0430 - val_loss: 0.0848\n",
      "Epoch 295/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0432 - val_loss: 0.0848\n",
      "Epoch 296/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0849\n",
      "Epoch 297/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0425 - val_loss: 0.0849\n",
      "Epoch 298/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0417 - val_loss: 0.0850\n",
      "Epoch 299/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0410 - val_loss: 0.0850\n",
      "Epoch 300/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0419 - val_loss: 0.0852\n",
      "Epoch 301/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0428 - val_loss: 0.0851\n",
      "Epoch 302/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0410 - val_loss: 0.0851\n",
      "Epoch 303/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0414 - val_loss: 0.0853\n",
      "Epoch 304/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0410 - val_loss: 0.0856\n",
      "Epoch 305/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0423 - val_loss: 0.0858\n",
      "Epoch 306/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0425 - val_loss: 0.0852\n",
      "Epoch 307/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0407 - val_loss: 0.0855\n",
      "Epoch 308/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0429 - val_loss: 0.0855\n",
      "Epoch 309/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0403 - val_loss: 0.0856\n",
      "Epoch 310/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0426 - val_loss: 0.0862\n",
      "Epoch 311/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0405 - val_loss: 0.0856\n",
      "Epoch 312/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0409 - val_loss: 0.0857\n",
      "Epoch 313/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0415 - val_loss: 0.0861\n",
      "Epoch 314/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0411 - val_loss: 0.0857\n",
      "Epoch 315/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0408 - val_loss: 0.0866\n",
      "Epoch 316/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0411 - val_loss: 0.0863\n",
      "Epoch 317/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0403 - val_loss: 0.0857\n",
      "Epoch 318/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0422 - val_loss: 0.0859\n",
      "Epoch 319/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0411 - val_loss: 0.0860\n",
      "Epoch 320/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0406 - val_loss: 0.0866\n",
      "Epoch 321/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0415 - val_loss: 0.0862\n",
      "Epoch 322/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0408 - val_loss: 0.0858\n",
      "Epoch 323/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0399 - val_loss: 0.0862\n",
      "Epoch 324/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0402 - val_loss: 0.0860\n",
      "Epoch 325/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0404 - val_loss: 0.0866\n",
      "Epoch 326/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0393 - val_loss: 0.0863\n",
      "Epoch 327/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0387 - val_loss: 0.0861\n",
      "Epoch 328/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0399 - val_loss: 0.0864\n",
      "Epoch 329/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0408 - val_loss: 0.0864\n",
      "Epoch 330/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0396 - val_loss: 0.0872\n",
      "Epoch 331/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0395 - val_loss: 0.0864\n",
      "Epoch 332/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0388 - val_loss: 0.0863\n",
      "Epoch 333/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0403 - val_loss: 0.0865\n",
      "Epoch 334/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0387 - val_loss: 0.0864\n",
      "Epoch 335/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0403 - val_loss: 0.0869\n",
      "Epoch 336/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0409 - val_loss: 0.0867\n",
      "Epoch 337/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0405 - val_loss: 0.0864\n",
      "Epoch 338/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0390 - val_loss: 0.0866\n",
      "Epoch 339/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0404 - val_loss: 0.0865\n",
      "Epoch 340/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0393 - val_loss: 0.0867\n",
      "Epoch 341/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0397 - val_loss: 0.0868\n",
      "Epoch 342/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0417 - val_loss: 0.0867\n",
      "Epoch 343/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0393 - val_loss: 0.0866\n",
      "Epoch 344/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0396 - val_loss: 0.0867\n",
      "Epoch 345/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0390 - val_loss: 0.0869\n",
      "Epoch 346/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0403 - val_loss: 0.0871\n",
      "Epoch 347/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - val_loss: 0.0867\n",
      "Epoch 348/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0382 - val_loss: 0.0867\n",
      "Epoch 349/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0388 - val_loss: 0.0869\n",
      "Epoch 350/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0381 - val_loss: 0.0870\n",
      "Epoch 351/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0404 - val_loss: 0.0874\n",
      "Epoch 352/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0406 - val_loss: 0.0869\n",
      "Epoch 353/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0417 - val_loss: 0.0870\n",
      "Epoch 354/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0394 - val_loss: 0.0875\n",
      "Epoch 355/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0399 - val_loss: 0.0871\n",
      "Epoch 356/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0393 - val_loss: 0.0881\n",
      "Epoch 357/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0404 - val_loss: 0.0877\n",
      "Epoch 358/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0386 - val_loss: 0.0872\n",
      "Epoch 359/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0407 - val_loss: 0.0877\n",
      "Epoch 360/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0400 - val_loss: 0.0872\n",
      "Epoch 361/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0382 - val_loss: 0.0880\n",
      "Epoch 362/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0391 - val_loss: 0.0881\n",
      "Epoch 363/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0396 - val_loss: 0.0873\n",
      "Epoch 364/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0401 - val_loss: 0.0873\n",
      "Epoch 365/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0394 - val_loss: 0.0872\n",
      "Epoch 366/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0394 - val_loss: 0.0876\n",
      "Epoch 367/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0376 - val_loss: 0.0880\n",
      "Epoch 368/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - val_loss: 0.0874\n",
      "Epoch 369/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0381 - val_loss: 0.0873\n",
      "Epoch 370/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0386 - val_loss: 0.0873\n",
      "Epoch 371/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0373 - val_loss: 0.0874\n",
      "Epoch 372/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0375 - val_loss: 0.0874\n",
      "Epoch 373/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - val_loss: 0.0875\n",
      "Epoch 374/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0381 - val_loss: 0.0875\n",
      "Epoch 375/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0376 - val_loss: 0.0874\n",
      "Epoch 376/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0375 - val_loss: 0.0874\n",
      "Epoch 377/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0375 - val_loss: 0.0875\n",
      "Epoch 378/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0365 - val_loss: 0.0876\n",
      "Epoch 379/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0379 - val_loss: 0.0877\n",
      "Epoch 380/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0384 - val_loss: 0.0877\n",
      "Epoch 381/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0376 - val_loss: 0.0877\n",
      "Epoch 382/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0394 - val_loss: 0.0876\n",
      "Epoch 383/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0361 - val_loss: 0.0876\n",
      "Epoch 384/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0378 - val_loss: 0.0880\n",
      "Epoch 385/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0389 - val_loss: 0.0879\n",
      "Epoch 386/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0361 - val_loss: 0.0879\n",
      "Epoch 387/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0367 - val_loss: 0.0880\n",
      "Epoch 388/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0385 - val_loss: 0.0879\n",
      "Epoch 389/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0375 - val_loss: 0.0883\n",
      "Epoch 390/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0381 - val_loss: 0.0881\n",
      "Epoch 391/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0370 - val_loss: 0.0882\n",
      "Epoch 392/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0363 - val_loss: 0.0881\n",
      "Epoch 393/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0378 - val_loss: 0.0885\n",
      "Epoch 394/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0406 - val_loss: 0.0887\n",
      "Epoch 395/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0367 - val_loss: 0.0884\n",
      "Epoch 396/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0373 - val_loss: 0.0883\n",
      "Epoch 397/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0368 - val_loss: 0.0883\n",
      "Epoch 398/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0376 - val_loss: 0.0887\n",
      "Epoch 399/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0387 - val_loss: 0.0888\n",
      "Epoch 400/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0376 - val_loss: 0.0889\n",
      "Epoch 401/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0377 - val_loss: 0.0885\n",
      "Epoch 402/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0375 - val_loss: 0.0885\n",
      "Epoch 403/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0365 - val_loss: 0.0887\n",
      "Epoch 404/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0365 - val_loss: 0.0890\n",
      "Epoch 405/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0351 - val_loss: 0.0893\n",
      "Epoch 406/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0367 - val_loss: 0.0889\n",
      "Epoch 407/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0348 - val_loss: 0.0887\n",
      "Epoch 408/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0377 - val_loss: 0.0888\n",
      "Epoch 409/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0370 - val_loss: 0.0892\n",
      "Epoch 410/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0360 - val_loss: 0.0898\n",
      "Epoch 411/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0373 - val_loss: 0.0892\n",
      "Epoch 412/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0355 - val_loss: 0.0892\n",
      "Epoch 413/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0362 - val_loss: 0.0891\n",
      "Epoch 414/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0363 - val_loss: 0.0896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0364 - val_loss: 0.0896\n",
      "Epoch 416/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0344 - val_loss: 0.0893\n",
      "Epoch 417/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0344 - val_loss: 0.0893\n",
      "Epoch 418/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0363 - val_loss: 0.0895\n",
      "Epoch 419/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0344 - val_loss: 0.0896\n",
      "Epoch 420/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0365 - val_loss: 0.0897\n",
      "Epoch 421/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0349 - val_loss: 0.0894\n",
      "Epoch 422/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0345 - val_loss: 0.0896\n",
      "Epoch 423/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - val_loss: 0.0899\n",
      "Epoch 424/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - val_loss: 0.0903\n",
      "Epoch 425/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0357 - val_loss: 0.0901\n",
      "Epoch 426/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0374 - val_loss: 0.0901\n",
      "Epoch 427/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0360 - val_loss: 0.0903\n",
      "Epoch 428/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - val_loss: 0.0904\n",
      "Epoch 429/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0345 - val_loss: 0.0908\n",
      "Epoch 430/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0372 - val_loss: 0.0906\n",
      "Epoch 431/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0346 - val_loss: 0.0906\n",
      "Epoch 432/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0362 - val_loss: 0.0904\n",
      "Epoch 433/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0339 - val_loss: 0.0906\n",
      "Epoch 434/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0363 - val_loss: 0.0907\n",
      "Epoch 435/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0341 - val_loss: 0.0907\n",
      "Epoch 436/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0358 - val_loss: 0.0907\n",
      "Epoch 437/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0358 - val_loss: 0.0908\n",
      "Epoch 438/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0352 - val_loss: 0.0907\n",
      "Epoch 439/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - val_loss: 0.0905\n",
      "Epoch 440/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0350 - val_loss: 0.0906\n",
      "Epoch 441/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0344 - val_loss: 0.0912\n",
      "Epoch 442/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0353 - val_loss: 0.0918\n",
      "Epoch 443/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0360 - val_loss: 0.0911\n",
      "Epoch 444/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - val_loss: 0.0908\n",
      "Epoch 445/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0352 - val_loss: 0.0908\n",
      "Epoch 446/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0340 - val_loss: 0.0914\n",
      "Epoch 447/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0350 - val_loss: 0.0917\n",
      "Epoch 448/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0347 - val_loss: 0.0918\n",
      "Epoch 449/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - val_loss: 0.0908\n",
      "Epoch 450/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0362 - val_loss: 0.0913\n",
      "Epoch 451/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - val_loss: 0.0914\n",
      "Epoch 452/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0330 - val_loss: 0.0923\n",
      "Epoch 453/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - val_loss: 0.0922\n",
      "Epoch 454/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0341 - val_loss: 0.0915\n",
      "Epoch 455/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0350 - val_loss: 0.0915\n",
      "Epoch 456/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0342 - val_loss: 0.0919\n",
      "Epoch 457/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0358 - val_loss: 0.0932\n",
      "Epoch 458/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0370 - val_loss: 0.0918\n",
      "Epoch 459/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0332 - val_loss: 0.0923\n",
      "Epoch 460/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0344 - val_loss: 0.0918\n",
      "Epoch 461/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - val_loss: 0.0936\n",
      "Epoch 462/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0352 - val_loss: 0.0928\n",
      "Epoch 463/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - val_loss: 0.0921\n",
      "Epoch 464/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - val_loss: 0.0920\n",
      "Epoch 465/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - val_loss: 0.0923\n",
      "Epoch 466/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - val_loss: 0.0942\n",
      "Epoch 467/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0364 - val_loss: 0.0930\n",
      "Epoch 468/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - val_loss: 0.0927\n",
      "Epoch 469/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0353 - val_loss: 0.0918\n",
      "Epoch 470/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0356 - val_loss: 0.0924\n",
      "Epoch 471/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0338 - val_loss: 0.0938\n",
      "Epoch 472/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0325 - val_loss: 0.0935\n",
      "Epoch 473/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0335 - val_loss: 0.0922\n",
      "Epoch 474/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0354 - val_loss: 0.0921\n",
      "Epoch 475/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0325 - val_loss: 0.0925\n",
      "Epoch 476/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0349 - val_loss: 0.0931\n",
      "Epoch 477/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0328 - val_loss: 0.0934\n",
      "Epoch 478/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0330 - val_loss: 0.0930\n",
      "Epoch 479/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - val_loss: 0.0925\n",
      "Epoch 480/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0332 - val_loss: 0.0925\n",
      "Epoch 481/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0342 - val_loss: 0.0929\n",
      "Epoch 482/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - val_loss: 0.0928\n",
      "Epoch 483/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0338 - val_loss: 0.0925\n",
      "Epoch 484/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0333 - val_loss: 0.0929\n",
      "Epoch 485/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0324 - val_loss: 0.0931\n",
      "Epoch 486/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0336 - val_loss: 0.0939\n",
      "Epoch 487/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0342 - val_loss: 0.0935\n",
      "Epoch 488/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0333 - val_loss: 0.0927\n",
      "Epoch 489/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - val_loss: 0.0930\n",
      "Epoch 490/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0332 - val_loss: 0.0936\n",
      "Epoch 491/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0331 - val_loss: 0.0941\n",
      "Epoch 492/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0343 - val_loss: 0.0932\n",
      "Epoch 493/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0322 - val_loss: 0.0930\n",
      "Epoch 494/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0342 - val_loss: 0.0934\n",
      "Epoch 495/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0329 - val_loss: 0.0935\n",
      "Epoch 496/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0348 - val_loss: 0.0941\n",
      "Epoch 497/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0350 - val_loss: 0.0934\n",
      "Epoch 498/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0340 - val_loss: 0.0935\n",
      "Epoch 499/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0314 - val_loss: 0.0932\n",
      "Epoch 500/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0326 - val_loss: 0.0937\n",
      "Epoch 501/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0334 - val_loss: 0.0939\n",
      "Epoch 502/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0325 - val_loss: 0.0935\n",
      "Epoch 503/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0328 - val_loss: 0.0935\n",
      "Epoch 504/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - val_loss: 0.0932\n",
      "Epoch 505/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0324 - val_loss: 0.0935\n",
      "Epoch 506/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0330 - val_loss: 0.0938\n",
      "Epoch 507/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0332 - val_loss: 0.0938\n",
      "Epoch 508/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0334 - val_loss: 0.0932\n",
      "Epoch 509/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0321 - val_loss: 0.0933\n",
      "Epoch 510/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0318 - val_loss: 0.0941\n",
      "Epoch 511/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0326 - val_loss: 0.0951\n",
      "Epoch 512/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0314 - val_loss: 0.0943\n",
      "Epoch 513/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - val_loss: 0.0937\n",
      "Epoch 514/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0322 - val_loss: 0.0939\n",
      "Epoch 515/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - val_loss: 0.0950\n",
      "Epoch 516/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0322 - val_loss: 0.0958\n",
      "Epoch 517/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0319 - val_loss: 0.0945\n",
      "Epoch 518/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0321 - val_loss: 0.0940\n",
      "Epoch 519/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0332 - val_loss: 0.0944\n",
      "Epoch 520/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0327 - val_loss: 0.0954\n",
      "Epoch 521/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0311 - val_loss: 0.0951\n",
      "Epoch 522/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0325 - val_loss: 0.0943\n",
      "Epoch 523/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0329 - val_loss: 0.0946\n",
      "Epoch 524/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0309 - val_loss: 0.0950\n",
      "Epoch 525/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - val_loss: 0.0953\n",
      "Epoch 526/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0329 - val_loss: 0.0947\n",
      "Epoch 527/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0324 - val_loss: 0.0944\n",
      "Epoch 528/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0320 - val_loss: 0.0946\n",
      "Epoch 529/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - val_loss: 0.0952\n",
      "Epoch 530/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0313 - val_loss: 0.0956\n",
      "Epoch 531/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - val_loss: 0.0947\n",
      "Epoch 532/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - val_loss: 0.0948\n",
      "Epoch 533/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0320 - val_loss: 0.0949\n",
      "Epoch 534/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0313 - val_loss: 0.0953\n",
      "Epoch 535/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - val_loss: 0.0955\n",
      "Epoch 536/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0316 - val_loss: 0.0958\n",
      "Epoch 537/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0310 - val_loss: 0.0949\n",
      "Epoch 538/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - val_loss: 0.0950\n",
      "Epoch 539/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0313 - val_loss: 0.0951\n",
      "Epoch 540/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0325 - val_loss: 0.0960\n",
      "Epoch 541/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0299 - val_loss: 0.0957\n",
      "Epoch 542/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0324 - val_loss: 0.0954\n",
      "Epoch 543/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0308 - val_loss: 0.0955\n",
      "Epoch 544/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0305 - val_loss: 0.0955\n",
      "Epoch 545/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0299 - val_loss: 0.0962\n",
      "Epoch 546/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - val_loss: 0.0961\n",
      "Epoch 547/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0335 - val_loss: 0.0960\n",
      "Epoch 548/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0322 - val_loss: 0.0956\n",
      "Epoch 549/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0310 - val_loss: 0.0959\n",
      "Epoch 550/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0315 - val_loss: 0.0966\n",
      "Epoch 551/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - val_loss: 0.0968\n",
      "Epoch 552/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0309 - val_loss: 0.0961\n",
      "Epoch 553/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0316 - val_loss: 0.0957\n",
      "Epoch 554/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0299 - val_loss: 0.0964\n",
      "Epoch 555/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0307 - val_loss: 0.0976\n",
      "Epoch 556/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0312 - val_loss: 0.0969\n",
      "Epoch 557/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0313 - val_loss: 0.0959\n",
      "Epoch 558/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0307 - val_loss: 0.0958\n",
      "Epoch 559/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0324 - val_loss: 0.0968\n",
      "Epoch 560/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0305 - val_loss: 0.0973\n",
      "Epoch 561/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - val_loss: 0.0965\n",
      "Epoch 562/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - val_loss: 0.0962\n",
      "Epoch 563/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0319 - val_loss: 0.0964\n",
      "Epoch 564/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - val_loss: 0.0974\n",
      "Epoch 565/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - val_loss: 0.0973\n",
      "Epoch 566/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - val_loss: 0.0978\n",
      "Epoch 567/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0307 - val_loss: 0.0966\n",
      "Epoch 568/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0305 - val_loss: 0.0970\n",
      "Epoch 569/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0296 - val_loss: 0.0978\n",
      "Epoch 570/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - val_loss: 0.0974\n",
      "Epoch 571/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - val_loss: 0.0971\n",
      "Epoch 572/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0287 - val_loss: 0.0965\n",
      "Epoch 573/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - val_loss: 0.0973\n",
      "Epoch 574/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0316 - val_loss: 0.0976\n",
      "Epoch 575/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0290 - val_loss: 0.0977\n",
      "Epoch 576/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0315 - val_loss: 0.0973\n",
      "Epoch 577/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0290 - val_loss: 0.0973\n",
      "Epoch 578/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0294 - val_loss: 0.0977\n",
      "Epoch 579/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0305 - val_loss: 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0297 - val_loss: 0.0974\n",
      "Epoch 581/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - val_loss: 0.0976\n",
      "Epoch 582/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0300 - val_loss: 0.0981\n",
      "Epoch 583/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - val_loss: 0.0987\n",
      "Epoch 584/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - val_loss: 0.0981\n",
      "Epoch 585/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - val_loss: 0.0977\n",
      "Epoch 586/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0306 - val_loss: 0.0982\n",
      "Epoch 587/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - val_loss: 0.0990\n",
      "Epoch 588/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0297 - val_loss: 0.0987\n",
      "Epoch 589/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0307 - val_loss: 0.0983\n",
      "Epoch 590/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - val_loss: 0.0985\n",
      "Epoch 591/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0284 - val_loss: 0.0989\n",
      "Epoch 592/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0290 - val_loss: 0.0985\n",
      "Epoch 593/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0292 - val_loss: 0.0983\n",
      "Epoch 594/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - val_loss: 0.0979\n",
      "Epoch 595/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0299 - val_loss: 0.0985\n",
      "Epoch 596/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0282 - val_loss: 0.0990\n",
      "Epoch 597/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0294 - val_loss: 0.0983\n",
      "Epoch 598/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0311 - val_loss: 0.0980\n",
      "Epoch 599/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - val_loss: 0.0984\n",
      "Epoch 600/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0293 - val_loss: 0.0992\n",
      "Epoch 601/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0296 - val_loss: 0.0986\n",
      "Epoch 602/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0280 - val_loss: 0.0983\n",
      "Epoch 603/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - val_loss: 0.0987\n",
      "Epoch 604/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0281 - val_loss: 0.0993\n",
      "Epoch 605/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0290 - val_loss: 0.0994\n",
      "Epoch 606/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0282 - val_loss: 0.0991\n",
      "Epoch 607/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0287 - val_loss: 0.0989\n",
      "Epoch 608/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - val_loss: 0.0987\n",
      "Epoch 609/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0297 - val_loss: 0.0998\n",
      "Epoch 610/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0279 - val_loss: 0.0997\n",
      "Epoch 611/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0288 - val_loss: 0.0990\n",
      "Epoch 612/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0281 - val_loss: 0.0987\n",
      "Epoch 613/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0298 - val_loss: 0.0988\n",
      "Epoch 614/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0280 - val_loss: 0.1001\n",
      "Epoch 615/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0280 - val_loss: 0.0996\n",
      "Epoch 616/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0293 - val_loss: 0.0986\n",
      "Epoch 617/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0298 - val_loss: 0.0992\n",
      "Epoch 618/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0301 - val_loss: 0.0996\n",
      "Epoch 619/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - val_loss: 0.1000\n",
      "Epoch 620/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0288 - val_loss: 0.0999\n",
      "Epoch 621/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0284 - val_loss: 0.1001\n",
      "Epoch 622/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0286 - val_loss: 0.0994\n",
      "Epoch 623/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0293 - val_loss: 0.0999\n",
      "Epoch 624/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0279 - val_loss: 0.1005\n",
      "Epoch 625/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0274 - val_loss: 0.1011\n",
      "Epoch 626/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - val_loss: 0.1002\n",
      "Epoch 627/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0273 - val_loss: 0.0999\n",
      "Epoch 628/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0271 - val_loss: 0.1002\n",
      "Epoch 629/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0275 - val_loss: 0.1013\n",
      "Epoch 630/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - val_loss: 0.1000\n",
      "Epoch 631/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0283 - val_loss: 0.1005\n",
      "Epoch 632/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0315 - val_loss: 0.1001\n",
      "Epoch 633/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0283 - val_loss: 0.1011\n",
      "Epoch 634/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0287 - val_loss: 0.1007\n",
      "Epoch 635/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0296 - val_loss: 0.1005\n",
      "Epoch 636/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - val_loss: 0.1011\n",
      "Epoch 637/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0303 - val_loss: 0.1015\n",
      "Epoch 638/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0275 - val_loss: 0.1013\n",
      "Epoch 639/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0276 - val_loss: 0.1001\n",
      "Epoch 640/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0292 - val_loss: 0.1019\n",
      "Epoch 641/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - val_loss: 0.1021\n",
      "Epoch 642/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0302 - val_loss: 0.1013\n",
      "Epoch 643/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0279 - val_loss: 0.1004\n",
      "Epoch 644/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0282 - val_loss: 0.1020\n",
      "Epoch 645/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0290 - val_loss: 0.1019\n",
      "Epoch 646/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0266 - val_loss: 0.1013\n",
      "Epoch 647/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0283 - val_loss: 0.1005\n",
      "Epoch 648/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0284 - val_loss: 0.1006\n",
      "Epoch 649/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - val_loss: 0.1012\n",
      "Epoch 650/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0288 - val_loss: 0.1020\n",
      "Epoch 651/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0272 - val_loss: 0.1009\n",
      "Epoch 652/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0276 - val_loss: 0.1008\n",
      "Epoch 653/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0264 - val_loss: 0.1011\n",
      "Epoch 654/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0271 - val_loss: 0.1026\n",
      "Epoch 655/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0293 - val_loss: 0.1023\n",
      "Epoch 656/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0268 - val_loss: 0.1011\n",
      "Epoch 657/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0276 - val_loss: 0.1008\n",
      "Epoch 658/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - val_loss: 0.1029\n",
      "Epoch 659/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0277 - val_loss: 0.1035\n",
      "Epoch 660/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0261 - val_loss: 0.1019\n",
      "Epoch 661/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0281 - val_loss: 0.1012\n",
      "Epoch 662/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0304 - val_loss: 0.1020\n",
      "Epoch 663/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0274 - val_loss: 0.1036\n",
      "Epoch 664/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0270 - val_loss: 0.1027\n",
      "Epoch 665/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - val_loss: 0.1011\n",
      "Epoch 666/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0278 - val_loss: 0.1014\n",
      "Epoch 667/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0262 - val_loss: 0.1031\n",
      "Epoch 668/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0277 - val_loss: 0.1030\n",
      "Epoch 669/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - val_loss: 0.1013\n",
      "Epoch 670/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0274 - val_loss: 0.1009\n",
      "Epoch 671/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0277 - val_loss: 0.1025\n",
      "Epoch 672/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0280 - val_loss: 0.1028\n",
      "Epoch 673/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - val_loss: 0.1023\n",
      "Epoch 674/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0292 - val_loss: 0.1016\n",
      "Epoch 675/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0276 - val_loss: 0.1030\n",
      "Epoch 676/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0281 - val_loss: 0.1038\n",
      "Epoch 677/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0289 - val_loss: 0.1041\n",
      "Epoch 678/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0283 - val_loss: 0.1019\n",
      "Epoch 679/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0255 - val_loss: 0.1039\n",
      "Epoch 680/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0292 - val_loss: 0.1034\n",
      "Epoch 681/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0264 - val_loss: 0.1042\n",
      "Epoch 682/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0282 - val_loss: 0.1019\n",
      "Epoch 683/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0259 - val_loss: 0.1038\n",
      "Epoch 684/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0283 - val_loss: 0.1031\n",
      "Epoch 685/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0278 - val_loss: 0.1048\n",
      "Epoch 686/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0284 - val_loss: 0.1030\n",
      "Epoch 687/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0268 - val_loss: 0.1043\n",
      "Epoch 688/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0278 - val_loss: 0.1022\n",
      "Epoch 689/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0272 - val_loss: 0.1045\n",
      "Epoch 690/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0291 - val_loss: 0.1037\n",
      "Epoch 691/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0278 - val_loss: 0.1045\n",
      "Epoch 692/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0282 - val_loss: 0.1025\n",
      "Epoch 693/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0285 - val_loss: 0.1038\n",
      "Epoch 694/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0270 - val_loss: 0.1034\n",
      "Epoch 695/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0259 - val_loss: 0.1041\n",
      "Epoch 696/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0269 - val_loss: 0.1029\n",
      "Epoch 697/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0273 - val_loss: 0.1036\n",
      "Epoch 698/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0300 - val_loss: 0.1032\n",
      "Epoch 699/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0260 - val_loss: 0.1044\n",
      "Epoch 700/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0283 - val_loss: 0.1035\n",
      "Epoch 701/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0253 - val_loss: 0.1028\n",
      "Epoch 702/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0262 - val_loss: 0.1035\n",
      "Epoch 703/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0247 - val_loss: 0.1045\n",
      "Epoch 704/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0265 - val_loss: 0.1035\n",
      "Epoch 705/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0270 - val_loss: 0.1033\n",
      "Epoch 706/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0250 - val_loss: 0.1037\n",
      "Epoch 707/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0255 - val_loss: 0.1036\n",
      "Epoch 708/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0265 - val_loss: 0.1031\n",
      "Epoch 709/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0270 - val_loss: 0.1031\n",
      "Epoch 710/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0273 - val_loss: 0.1039\n",
      "Epoch 711/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0277 - val_loss: 0.1044\n",
      "Epoch 712/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0266 - val_loss: 0.1042\n",
      "Epoch 713/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1030\n",
      "Epoch 714/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0267 - val_loss: 0.1031\n",
      "Epoch 715/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1042\n",
      "Epoch 716/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0266 - val_loss: 0.1040\n",
      "Epoch 717/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0249 - val_loss: 0.1034\n",
      "Epoch 718/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0264 - val_loss: 0.1037\n",
      "Epoch 719/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0243 - val_loss: 0.1039\n",
      "Epoch 720/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1040\n",
      "Epoch 721/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0254 - val_loss: 0.1039\n",
      "Epoch 722/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0257 - val_loss: 0.1045\n",
      "Epoch 723/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0261 - val_loss: 0.1041\n",
      "Epoch 724/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0261 - val_loss: 0.1041\n",
      "Epoch 725/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0259 - val_loss: 0.1038\n",
      "Epoch 726/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0265 - val_loss: 0.1042\n",
      "Epoch 727/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0265 - val_loss: 0.1050\n",
      "Epoch 728/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0234 - val_loss: 0.1046\n",
      "Epoch 729/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0254 - val_loss: 0.1040\n",
      "Epoch 730/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0258 - val_loss: 0.1042\n",
      "Epoch 731/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0263 - val_loss: 0.1048\n",
      "Epoch 732/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1051\n",
      "Epoch 733/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0262 - val_loss: 0.1046\n",
      "Epoch 734/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0265 - val_loss: 0.1049\n",
      "Epoch 735/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0263 - val_loss: 0.1048\n",
      "Epoch 736/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1051\n",
      "Epoch 737/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0267 - val_loss: 0.1047\n",
      "Epoch 738/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1052\n",
      "Epoch 739/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0243 - val_loss: 0.1057\n",
      "Epoch 740/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0263 - val_loss: 0.1054\n",
      "Epoch 741/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0251 - val_loss: 0.1048\n",
      "Epoch 742/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0274 - val_loss: 0.1054\n",
      "Epoch 743/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1064\n",
      "Epoch 744/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0260 - val_loss: 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1047\n",
      "Epoch 746/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0255 - val_loss: 0.1060\n",
      "Epoch 747/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0260 - val_loss: 0.1070\n",
      "Epoch 748/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0257 - val_loss: 0.1057\n",
      "Epoch 749/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1050\n",
      "Epoch 750/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1060\n",
      "Epoch 751/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0240 - val_loss: 0.1071\n",
      "Epoch 752/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0250 - val_loss: 0.1060\n",
      "Epoch 753/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1050\n",
      "Epoch 754/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0262 - val_loss: 0.1059\n",
      "Epoch 755/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0245 - val_loss: 0.1071\n",
      "Epoch 756/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1068\n",
      "Epoch 757/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1054\n",
      "Epoch 758/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1057\n",
      "Epoch 759/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0257 - val_loss: 0.1062\n",
      "Epoch 760/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0243 - val_loss: 0.1065\n",
      "Epoch 761/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0249 - val_loss: 0.1058\n",
      "Epoch 762/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0245 - val_loss: 0.1054\n",
      "Epoch 763/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1066\n",
      "Epoch 764/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0250 - val_loss: 0.1069\n",
      "Epoch 765/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0245 - val_loss: 0.1057\n",
      "Epoch 766/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0232 - val_loss: 0.1060\n",
      "Epoch 767/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0249 - val_loss: 0.1073\n",
      "Epoch 768/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0256 - val_loss: 0.1069\n",
      "Epoch 769/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0235 - val_loss: 0.1063\n",
      "Epoch 770/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1066\n",
      "Epoch 771/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1069\n",
      "Epoch 772/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0247 - val_loss: 0.1064\n",
      "Epoch 773/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0242 - val_loss: 0.1063\n",
      "Epoch 774/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1071\n",
      "Epoch 775/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0247 - val_loss: 0.1076\n",
      "Epoch 776/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1064\n",
      "Epoch 777/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0251 - val_loss: 0.1063\n",
      "Epoch 778/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0240 - val_loss: 0.1074\n",
      "Epoch 779/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0242 - val_loss: 0.1079\n",
      "Epoch 780/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1070\n",
      "Epoch 781/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0234 - val_loss: 0.1067\n",
      "Epoch 782/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0232 - val_loss: 0.1071\n",
      "Epoch 783/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1089\n",
      "Epoch 784/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1082\n",
      "Epoch 785/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1072\n",
      "Epoch 786/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0254 - val_loss: 0.1070\n",
      "Epoch 787/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0242 - val_loss: 0.1071\n",
      "Epoch 788/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0227 - val_loss: 0.1085\n",
      "Epoch 789/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1080\n",
      "Epoch 790/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0252 - val_loss: 0.1070\n",
      "Epoch 791/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0240 - val_loss: 0.1068\n",
      "Epoch 792/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0225 - val_loss: 0.1084\n",
      "Epoch 793/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1085\n",
      "Epoch 794/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0245 - val_loss: 0.1072\n",
      "Epoch 795/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0249 - val_loss: 0.1065\n",
      "Epoch 796/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1080\n",
      "Epoch 797/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0228 - val_loss: 0.1086\n",
      "Epoch 798/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1070\n",
      "Epoch 799/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0231 - val_loss: 0.1063\n",
      "Epoch 800/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0238 - val_loss: 0.1087\n",
      "Epoch 801/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1094\n",
      "Epoch 802/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0239 - val_loss: 0.1071\n",
      "Epoch 803/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1065\n",
      "Epoch 804/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0257 - val_loss: 0.1089\n",
      "Epoch 805/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1092\n",
      "Epoch 806/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0227 - val_loss: 0.1081\n",
      "Epoch 807/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0245 - val_loss: 0.1066\n",
      "Epoch 808/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0262 - val_loss: 0.1074\n",
      "Epoch 809/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0237 - val_loss: 0.1093\n",
      "Epoch 810/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0237 - val_loss: 0.1092\n",
      "Epoch 811/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0248 - val_loss: 0.1071\n",
      "Epoch 812/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1070\n",
      "Epoch 813/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0232 - val_loss: 0.1090\n",
      "Epoch 814/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0233 - val_loss: 0.1096\n",
      "Epoch 815/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1086\n",
      "Epoch 816/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0231 - val_loss: 0.1071\n",
      "Epoch 817/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1082\n",
      "Epoch 818/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0239 - val_loss: 0.1094\n",
      "Epoch 819/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1088\n",
      "Epoch 820/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0239 - val_loss: 0.1077\n",
      "Epoch 821/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1082\n",
      "Epoch 822/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1083\n",
      "Epoch 823/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0231 - val_loss: 0.1086\n",
      "Epoch 824/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1083\n",
      "Epoch 825/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1080\n",
      "Epoch 826/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0235 - val_loss: 0.1094\n",
      "Epoch 827/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1100\n",
      "Epoch 828/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0226 - val_loss: 0.1095\n",
      "Epoch 829/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0241 - val_loss: 0.1077\n",
      "Epoch 830/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1084\n",
      "Epoch 831/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0235 - val_loss: 0.1110\n",
      "Epoch 832/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0245 - val_loss: 0.1099\n",
      "Epoch 833/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1082\n",
      "Epoch 834/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0221 - val_loss: 0.1083\n",
      "Epoch 835/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0238 - val_loss: 0.1098\n",
      "Epoch 836/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1099\n",
      "Epoch 837/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1084\n",
      "Epoch 838/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0232 - val_loss: 0.1083\n",
      "Epoch 839/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1093\n",
      "Epoch 840/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0232 - val_loss: 0.1104\n",
      "Epoch 841/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0244 - val_loss: 0.1087\n",
      "Epoch 842/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0225 - val_loss: 0.1082\n",
      "Epoch 843/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0238 - val_loss: 0.1095\n",
      "Epoch 844/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0227 - val_loss: 0.1110\n",
      "Epoch 845/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0234 - val_loss: 0.1096\n",
      "Epoch 846/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0246 - val_loss: 0.1089\n",
      "Epoch 847/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0227 - val_loss: 0.1095\n",
      "Epoch 848/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0227 - val_loss: 0.1098\n",
      "Epoch 849/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0232 - val_loss: 0.1101\n",
      "Epoch 850/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1093\n",
      "Epoch 851/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1090\n",
      "Epoch 852/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1094\n",
      "Epoch 853/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1108\n",
      "Epoch 854/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0234 - val_loss: 0.1095\n",
      "Epoch 855/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0224 - val_loss: 0.1086\n",
      "Epoch 856/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1096\n",
      "Epoch 857/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1108\n",
      "Epoch 858/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0225 - val_loss: 0.1099\n",
      "Epoch 859/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0229 - val_loss: 0.1086\n",
      "Epoch 860/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0233 - val_loss: 0.1097\n",
      "Epoch 861/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - val_loss: 0.1108\n",
      "Epoch 862/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1114\n",
      "Epoch 863/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0237 - val_loss: 0.1099\n",
      "Epoch 864/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0237 - val_loss: 0.1093\n",
      "Epoch 865/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1105\n",
      "Epoch 866/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0231 - val_loss: 0.1112\n",
      "Epoch 867/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0221 - val_loss: 0.1102\n",
      "Epoch 868/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0228 - val_loss: 0.1104\n",
      "Epoch 869/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0226 - val_loss: 0.1108\n",
      "Epoch 870/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - val_loss: 0.1107\n",
      "Epoch 871/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1109\n",
      "Epoch 872/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1100\n",
      "Epoch 873/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1110\n",
      "Epoch 874/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0220 - val_loss: 0.1111\n",
      "Epoch 875/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1107\n",
      "Epoch 876/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0219 - val_loss: 0.1102\n",
      "Epoch 877/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0229 - val_loss: 0.1112\n",
      "Epoch 878/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1126\n",
      "Epoch 879/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0236 - val_loss: 0.1109\n",
      "Epoch 880/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0229 - val_loss: 0.1104\n",
      "Epoch 881/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0232 - val_loss: 0.1105\n",
      "Epoch 882/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0212 - val_loss: 0.1123\n",
      "Epoch 883/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1108\n",
      "Epoch 884/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1106\n",
      "Epoch 885/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0219 - val_loss: 0.1104\n",
      "Epoch 886/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0212 - val_loss: 0.1122\n",
      "Epoch 887/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0238 - val_loss: 0.1111\n",
      "Epoch 888/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1110\n",
      "Epoch 889/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1103\n",
      "Epoch 890/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1117\n",
      "Epoch 891/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - val_loss: 0.1113\n",
      "Epoch 892/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0212 - val_loss: 0.1104\n",
      "Epoch 893/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0228 - val_loss: 0.1113\n",
      "Epoch 894/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0210 - val_loss: 0.1117\n",
      "Epoch 895/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0213 - val_loss: 0.1106\n",
      "Epoch 896/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - val_loss: 0.1108\n",
      "Epoch 897/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0224 - val_loss: 0.1119\n",
      "Epoch 898/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0216 - val_loss: 0.1108\n",
      "Epoch 899/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0237 - val_loss: 0.1102\n",
      "Epoch 900/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0224 - val_loss: 0.1120\n",
      "Epoch 901/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0221 - val_loss: 0.1121\n",
      "Epoch 902/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1112\n",
      "Epoch 903/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1105\n",
      "Epoch 904/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0224 - val_loss: 0.1114\n",
      "Epoch 905/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1132\n",
      "Epoch 906/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0216 - val_loss: 0.1121\n",
      "Epoch 907/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0227 - val_loss: 0.1116\n",
      "Epoch 908/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0220 - val_loss: 0.1110\n",
      "Epoch 909/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 910/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1120\n",
      "Epoch 911/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0213 - val_loss: 0.1125\n",
      "Epoch 912/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0224 - val_loss: 0.1108\n",
      "Epoch 913/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1117\n",
      "Epoch 914/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - val_loss: 0.1123\n",
      "Epoch 915/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0205 - val_loss: 0.1123\n",
      "Epoch 916/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - val_loss: 0.1114\n",
      "Epoch 917/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0201 - val_loss: 0.1112\n",
      "Epoch 918/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1120\n",
      "Epoch 919/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0215 - val_loss: 0.1131\n",
      "Epoch 920/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0216 - val_loss: 0.1121\n",
      "Epoch 921/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0203 - val_loss: 0.1115\n",
      "Epoch 922/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - val_loss: 0.1125\n",
      "Epoch 923/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0216 - val_loss: 0.1128\n",
      "Epoch 924/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1127\n",
      "Epoch 925/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - val_loss: 0.1125\n",
      "Epoch 926/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0223 - val_loss: 0.1132\n",
      "Epoch 927/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0230 - val_loss: 0.1130\n",
      "Epoch 928/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1126\n",
      "Epoch 929/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1129\n",
      "Epoch 930/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0197 - val_loss: 0.1127\n",
      "Epoch 931/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1123\n",
      "Epoch 932/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1132\n",
      "Epoch 933/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0206 - val_loss: 0.1127\n",
      "Epoch 934/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0221 - val_loss: 0.1121\n",
      "Epoch 935/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1124\n",
      "Epoch 936/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - val_loss: 0.1132\n",
      "Epoch 937/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - val_loss: 0.1131\n",
      "Epoch 938/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0213 - val_loss: 0.1127\n",
      "Epoch 939/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - val_loss: 0.1124\n",
      "Epoch 940/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0210 - val_loss: 0.1131\n",
      "Epoch 941/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0219 - val_loss: 0.1131\n",
      "Epoch 942/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - val_loss: 0.1134\n",
      "Epoch 943/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1130\n",
      "Epoch 944/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1129\n",
      "Epoch 945/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1128\n",
      "Epoch 946/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1133\n",
      "Epoch 947/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0203 - val_loss: 0.1145\n",
      "Epoch 948/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0220 - val_loss: 0.1127\n",
      "Epoch 949/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - val_loss: 0.1121\n",
      "Epoch 950/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1137\n",
      "Epoch 951/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1144\n",
      "Epoch 952/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0219 - val_loss: 0.1131\n",
      "Epoch 953/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0205 - val_loss: 0.1127\n",
      "Epoch 954/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1135\n",
      "Epoch 955/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0216 - val_loss: 0.1147\n",
      "Epoch 956/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1139\n",
      "Epoch 957/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0213 - val_loss: 0.1127\n",
      "Epoch 958/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0210 - val_loss: 0.1143\n",
      "Epoch 959/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - val_loss: 0.1153\n",
      "Epoch 960/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1141\n",
      "Epoch 961/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1131\n",
      "Epoch 962/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0201 - val_loss: 0.1137\n",
      "Epoch 963/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1141\n",
      "Epoch 964/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0208 - val_loss: 0.1162\n",
      "Epoch 965/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0233 - val_loss: 0.1151\n",
      "Epoch 966/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1130\n",
      "Epoch 967/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0214 - val_loss: 0.1145\n",
      "Epoch 968/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1150\n",
      "Epoch 969/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0208 - val_loss: 0.1149\n",
      "Epoch 970/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0231 - val_loss: 0.1132\n",
      "Epoch 971/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1156\n",
      "Epoch 972/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0222 - val_loss: 0.1152\n",
      "Epoch 973/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0210 - val_loss: 0.1141\n",
      "Epoch 974/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1134\n",
      "Epoch 975/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0206 - val_loss: 0.1151\n",
      "Epoch 976/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - val_loss: 0.1160\n",
      "Epoch 977/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0220 - val_loss: 0.1136\n",
      "Epoch 978/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - val_loss: 0.1144\n",
      "Epoch 979/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0218 - val_loss: 0.1147\n",
      "Epoch 980/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1151\n",
      "Epoch 981/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0205 - val_loss: 0.1136\n",
      "Epoch 982/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0205 - val_loss: 0.1134\n",
      "Epoch 983/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0206 - val_loss: 0.1145\n",
      "Epoch 984/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1144\n",
      "Epoch 985/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - val_loss: 0.1137\n",
      "Epoch 986/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0212 - val_loss: 0.1132\n",
      "Epoch 987/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0200 - val_loss: 0.1140\n",
      "Epoch 988/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1149\n",
      "Epoch 989/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1142\n",
      "Epoch 990/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1131\n",
      "Epoch 991/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1140\n",
      "Epoch 992/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1146\n",
      "Epoch 993/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1144\n",
      "Epoch 994/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1147\n",
      "Epoch 995/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0203 - val_loss: 0.1142\n",
      "Epoch 996/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - val_loss: 0.1144\n",
      "Epoch 997/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1150\n",
      "Epoch 998/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1149\n",
      "Epoch 999/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0211 - val_loss: 0.1145\n",
      "Epoch 1000/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1158\n",
      "Epoch 1001/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0203 - val_loss: 0.1152\n",
      "Epoch 1002/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1147\n",
      "Epoch 1003/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1149\n",
      "Epoch 1004/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1162\n",
      "Epoch 1005/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1158\n",
      "Epoch 1006/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1146\n",
      "Epoch 1007/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1154\n",
      "Epoch 1008/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1161\n",
      "Epoch 1009/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1149\n",
      "Epoch 1010/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1150\n",
      "Epoch 1011/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1164\n",
      "Epoch 1012/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1161\n",
      "Epoch 1013/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1146\n",
      "Epoch 1014/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1157\n",
      "Epoch 1015/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - val_loss: 0.1166\n",
      "Epoch 1016/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - val_loss: 0.1157\n",
      "Epoch 1017/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1151\n",
      "Epoch 1018/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - val_loss: 0.1152\n",
      "Epoch 1019/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1164\n",
      "Epoch 1020/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0206 - val_loss: 0.1166\n",
      "Epoch 1021/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1157\n",
      "Epoch 1022/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0207 - val_loss: 0.1149\n",
      "Epoch 1023/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1159\n",
      "Epoch 1024/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1160\n",
      "Epoch 1025/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1156\n",
      "Epoch 1026/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1152\n",
      "Epoch 1027/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - val_loss: 0.1165\n",
      "Epoch 1028/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0197 - val_loss: 0.1169\n",
      "Epoch 1029/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1153\n",
      "Epoch 1030/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - val_loss: 0.1153\n",
      "Epoch 1031/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1167\n",
      "Epoch 1032/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - val_loss: 0.1169\n",
      "Epoch 1033/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1155\n",
      "Epoch 1034/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1153\n",
      "Epoch 1035/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0203 - val_loss: 0.1167\n",
      "Epoch 1036/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1174\n",
      "Epoch 1037/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1160\n",
      "Epoch 1038/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1158\n",
      "Epoch 1039/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1166\n",
      "Epoch 1040/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1166\n",
      "Epoch 1041/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - val_loss: 0.1165\n",
      "Epoch 1042/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1162\n",
      "Epoch 1043/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0196 - val_loss: 0.1159\n",
      "Epoch 1044/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1168\n",
      "Epoch 1045/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1170\n",
      "Epoch 1046/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1166\n",
      "Epoch 1047/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0205 - val_loss: 0.1161\n",
      "Epoch 1048/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1171\n",
      "Epoch 1049/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1168\n",
      "Epoch 1050/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1163\n",
      "Epoch 1051/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0181 - val_loss: 0.1162\n",
      "Epoch 1052/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1169\n",
      "Epoch 1053/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1174\n",
      "Epoch 1054/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1163\n",
      "Epoch 1055/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1169\n",
      "Epoch 1056/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1178\n",
      "Epoch 1057/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0201 - val_loss: 0.1168\n",
      "Epoch 1058/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1171\n",
      "Epoch 1059/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1169\n",
      "Epoch 1060/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0198 - val_loss: 0.1193\n",
      "Epoch 1061/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0210 - val_loss: 0.1166\n",
      "Epoch 1062/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0210 - val_loss: 0.1176\n",
      "Epoch 1063/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0217 - val_loss: 0.1181\n",
      "Epoch 1064/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1174\n",
      "Epoch 1065/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - val_loss: 0.1191\n",
      "Epoch 1066/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0240 - val_loss: 0.1169\n",
      "Epoch 1067/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1196\n",
      "Epoch 1068/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0229 - val_loss: 0.1158\n",
      "Epoch 1069/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0204 - val_loss: 0.1197\n",
      "Epoch 1070/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0243 - val_loss: 0.1186\n",
      "Epoch 1071/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1178\n",
      "Epoch 1072/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0201 - val_loss: 0.1158\n",
      "Epoch 1073/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1196\n",
      "Epoch 1074/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - val_loss: 0.1207\n",
      "Epoch 1075/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0213 - val_loss: 0.1169\n",
      "Epoch 1076/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0196 - val_loss: 0.1168\n",
      "Epoch 1077/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0226 - val_loss: 0.1185\n",
      "Epoch 1078/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1208\n",
      "Epoch 1079/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0212 - val_loss: 0.1167\n",
      "Epoch 1080/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1165\n",
      "Epoch 1081/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0209 - val_loss: 0.1187\n",
      "Epoch 1082/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0181 - val_loss: 0.1187\n",
      "Epoch 1083/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1164\n",
      "Epoch 1084/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1164\n",
      "Epoch 1085/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1192\n",
      "Epoch 1086/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0203 - val_loss: 0.1181\n",
      "Epoch 1087/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1165\n",
      "Epoch 1088/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1172\n",
      "Epoch 1089/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1195\n",
      "Epoch 1090/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0182 - val_loss: 0.1186\n",
      "Epoch 1091/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0200 - val_loss: 0.1168\n",
      "Epoch 1092/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1174\n",
      "Epoch 1093/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1195\n",
      "Epoch 1094/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - val_loss: 0.1188\n",
      "Epoch 1095/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1173\n",
      "Epoch 1096/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - val_loss: 0.1175\n",
      "Epoch 1097/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0202 - val_loss: 0.1187\n",
      "Epoch 1098/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1184\n",
      "Epoch 1099/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1181\n",
      "Epoch 1100/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1169\n",
      "Epoch 1101/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1185\n",
      "Epoch 1102/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0192 - val_loss: 0.1187\n",
      "Epoch 1103/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1183\n",
      "Epoch 1104/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0197 - val_loss: 0.1166\n",
      "Epoch 1105/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1186\n",
      "Epoch 1106/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - val_loss: 0.1201\n",
      "Epoch 1107/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1181\n",
      "Epoch 1108/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1169\n",
      "Epoch 1109/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0197 - val_loss: 0.1183\n",
      "Epoch 1110/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1196\n",
      "Epoch 1111/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - val_loss: 0.1181\n",
      "Epoch 1112/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1175\n",
      "Epoch 1113/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1192\n",
      "Epoch 1114/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0199 - val_loss: 0.1190\n",
      "Epoch 1115/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1191\n",
      "Epoch 1116/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0208 - val_loss: 0.1181\n",
      "Epoch 1117/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0180 - val_loss: 0.1187\n",
      "Epoch 1118/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0189 - val_loss: 0.1183\n",
      "Epoch 1119/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0180 - val_loss: 0.1191\n",
      "Epoch 1120/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1192\n",
      "Epoch 1121/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1181\n",
      "Epoch 1122/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - val_loss: 0.1194\n",
      "Epoch 1123/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1192\n",
      "Epoch 1124/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1181\n",
      "Epoch 1125/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1175\n",
      "Epoch 1126/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1192\n",
      "Epoch 1127/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0180 - val_loss: 0.1203\n",
      "Epoch 1128/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1192\n",
      "Epoch 1129/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1179\n",
      "Epoch 1130/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1187\n",
      "Epoch 1131/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0191 - val_loss: 0.1196\n",
      "Epoch 1132/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1204\n",
      "Epoch 1133/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0193 - val_loss: 0.1183\n",
      "Epoch 1134/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1187\n",
      "Epoch 1135/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1190\n",
      "Epoch 1136/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1201\n",
      "Epoch 1137/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1195\n",
      "Epoch 1138/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1190\n",
      "Epoch 1139/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1191\n",
      "Epoch 1140/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1198\n",
      "Epoch 1141/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1190\n",
      "Epoch 1142/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1187\n",
      "Epoch 1143/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0195 - val_loss: 0.1197\n",
      "Epoch 1144/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0182 - val_loss: 0.1196\n",
      "Epoch 1145/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1188\n",
      "Epoch 1146/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1185\n",
      "Epoch 1147/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0189 - val_loss: 0.1207\n",
      "Epoch 1148/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0186 - val_loss: 0.1197\n",
      "Epoch 1149/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1188\n",
      "Epoch 1150/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1191\n",
      "Epoch 1151/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1200\n",
      "Epoch 1152/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1196\n",
      "Epoch 1153/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1191\n",
      "Epoch 1154/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1197\n",
      "Epoch 1155/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1197\n",
      "Epoch 1156/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1199\n",
      "Epoch 1157/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1193\n",
      "Epoch 1158/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1193\n",
      "Epoch 1159/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1201\n",
      "Epoch 1160/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1204\n",
      "Epoch 1161/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0194 - val_loss: 0.1192\n",
      "Epoch 1162/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1192\n",
      "Epoch 1163/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1194\n",
      "Epoch 1164/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1199\n",
      "Epoch 1165/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1195\n",
      "Epoch 1166/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1196\n",
      "Epoch 1167/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1203\n",
      "Epoch 1168/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1204\n",
      "Epoch 1169/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1200\n",
      "Epoch 1170/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0190 - val_loss: 0.1195\n",
      "Epoch 1171/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1198\n",
      "Epoch 1172/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0182 - val_loss: 0.1206\n",
      "Epoch 1173/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1203\n",
      "Epoch 1174/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1193\n",
      "Epoch 1175/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0182 - val_loss: 0.1191\n",
      "Epoch 1176/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1202\n",
      "Epoch 1177/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1199\n",
      "Epoch 1178/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1200\n",
      "Epoch 1179/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1199\n",
      "Epoch 1180/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1203\n",
      "Epoch 1181/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1201\n",
      "Epoch 1182/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1201\n",
      "Epoch 1183/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1203\n",
      "Epoch 1184/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1198\n",
      "Epoch 1185/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1203\n",
      "Epoch 1186/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1207\n",
      "Epoch 1187/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1199\n",
      "Epoch 1188/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1194\n",
      "Epoch 1189/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1201\n",
      "Epoch 1190/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1207\n",
      "Epoch 1191/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0180 - val_loss: 0.1206\n",
      "Epoch 1192/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1199\n",
      "Epoch 1193/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0195 - val_loss: 0.1197\n",
      "Epoch 1194/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1219\n",
      "Epoch 1195/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0188 - val_loss: 0.1206\n",
      "Epoch 1196/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1203\n",
      "Epoch 1197/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1202\n",
      "Epoch 1198/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1222\n",
      "Epoch 1199/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1207\n",
      "Epoch 1200/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1201\n",
      "Epoch 1201/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1208\n",
      "Epoch 1202/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1207\n",
      "Epoch 1203/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1212\n",
      "Epoch 1204/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1211\n",
      "Epoch 1205/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1206\n",
      "Epoch 1206/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1203\n",
      "Epoch 1207/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1214\n",
      "Epoch 1208/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0185 - val_loss: 0.1215\n",
      "Epoch 1209/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1207\n",
      "Epoch 1210/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1205\n",
      "Epoch 1211/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1209\n",
      "Epoch 1212/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1215\n",
      "Epoch 1213/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1209\n",
      "Epoch 1214/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1200\n",
      "Epoch 1215/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1205\n",
      "Epoch 1216/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1222\n",
      "Epoch 1217/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0183 - val_loss: 0.1206\n",
      "Epoch 1218/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1198\n",
      "Epoch 1219/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0180 - val_loss: 0.1212\n",
      "Epoch 1220/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1227\n",
      "Epoch 1221/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1206\n",
      "Epoch 1222/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1202\n",
      "Epoch 1223/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1216\n",
      "Epoch 1224/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1219\n",
      "Epoch 1225/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1213\n",
      "Epoch 1226/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1214\n",
      "Epoch 1227/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1212\n",
      "Epoch 1228/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1216\n",
      "Epoch 1229/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1215\n",
      "Epoch 1230/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1214\n",
      "Epoch 1231/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1215\n",
      "Epoch 1232/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1222\n",
      "Epoch 1233/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1215\n",
      "Epoch 1234/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0181 - val_loss: 0.1212\n",
      "Epoch 1235/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1228\n",
      "Epoch 1236/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1224\n",
      "Epoch 1237/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0169 - val_loss: 0.1222\n",
      "Epoch 1238/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.0170 - val_loss: 0.1218\n",
      "Epoch 1239/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0172 - val_loss: 0.1227\n",
      "Epoch 1240/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0187 - val_loss: 0.1226\n",
      "Epoch 1241/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1217\n",
      "Epoch 1242/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0164 - val_loss: 0.1219\n",
      "Epoch 1243/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1226\n",
      "Epoch 1244/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1224\n",
      "Epoch 1245/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1217\n",
      "Epoch 1246/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0178 - val_loss: 0.1226\n",
      "Epoch 1247/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1217\n",
      "Epoch 1248/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1223\n",
      "Epoch 1249/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1218\n",
      "Epoch 1250/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1223\n",
      "Epoch 1251/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1227\n",
      "Epoch 1252/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1218\n",
      "Epoch 1253/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1232\n",
      "Epoch 1254/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1228\n",
      "Epoch 1255/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1219\n",
      "Epoch 1256/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1219\n",
      "Epoch 1257/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1236\n",
      "Epoch 1258/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1228\n",
      "Epoch 1259/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1222\n",
      "Epoch 1260/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0173 - val_loss: 0.1226\n",
      "Epoch 1261/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1232\n",
      "Epoch 1262/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1229\n",
      "Epoch 1263/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1221\n",
      "Epoch 1264/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1227\n",
      "Epoch 1265/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1240\n",
      "Epoch 1266/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1223\n",
      "Epoch 1267/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0174 - val_loss: 0.1216\n",
      "Epoch 1268/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1230\n",
      "Epoch 1269/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1251\n",
      "Epoch 1270/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0180 - val_loss: 0.1219\n",
      "Epoch 1271/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1216\n",
      "Epoch 1272/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1231\n",
      "Epoch 1273/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1255\n",
      "Epoch 1274/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0184 - val_loss: 0.1228\n",
      "Epoch 1275/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1215\n",
      "Epoch 1276/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1230\n",
      "Epoch 1277/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1242\n",
      "Epoch 1278/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1231\n",
      "Epoch 1279/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1222\n",
      "Epoch 1280/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1235\n",
      "Epoch 1281/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1244\n",
      "Epoch 1282/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1225\n",
      "Epoch 1283/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1230\n",
      "Epoch 1284/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1231\n",
      "Epoch 1285/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1230\n",
      "Epoch 1286/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1231\n",
      "Epoch 1287/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1225\n",
      "Epoch 1288/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1234\n",
      "Epoch 1289/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1232\n",
      "Epoch 1290/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1228\n",
      "Epoch 1291/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1233\n",
      "Epoch 1292/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1234\n",
      "Epoch 1293/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1234\n",
      "Epoch 1294/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1230\n",
      "Epoch 1295/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1230\n",
      "Epoch 1296/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1244\n",
      "Epoch 1297/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1232\n",
      "Epoch 1298/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1226\n",
      "Epoch 1299/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1234\n",
      "Epoch 1300/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1238\n",
      "Epoch 1301/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1235\n",
      "Epoch 1302/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0168 - val_loss: 0.1227\n",
      "Epoch 1303/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1231\n",
      "Epoch 1304/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1243\n",
      "Epoch 1305/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1243\n",
      "Epoch 1306/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1224\n",
      "Epoch 1307/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1230\n",
      "Epoch 1308/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1253\n",
      "Epoch 1309/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1244\n",
      "Epoch 1310/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1229\n",
      "Epoch 1311/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1231\n",
      "Epoch 1312/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1263\n",
      "Epoch 1313/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1244\n",
      "Epoch 1314/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1227\n",
      "Epoch 1315/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0181 - val_loss: 0.1234\n",
      "Epoch 1316/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1256\n",
      "Epoch 1317/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1239\n",
      "Epoch 1318/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1226\n",
      "Epoch 1319/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1241\n",
      "Epoch 1320/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1246\n",
      "Epoch 1321/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1230\n",
      "Epoch 1322/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1227\n",
      "Epoch 1323/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1251\n",
      "Epoch 1324/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1237\n",
      "Epoch 1325/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1230\n",
      "Epoch 1326/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1233\n",
      "Epoch 1327/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1256\n",
      "Epoch 1328/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0173 - val_loss: 0.1239\n",
      "Epoch 1329/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1226\n",
      "Epoch 1330/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1243\n",
      "Epoch 1331/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1246\n",
      "Epoch 1332/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1243\n",
      "Epoch 1333/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1232\n",
      "Epoch 1334/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1254\n",
      "Epoch 1335/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1246\n",
      "Epoch 1336/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0170 - val_loss: 0.1234\n",
      "Epoch 1337/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1242\n",
      "Epoch 1338/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1254\n",
      "Epoch 1339/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1252\n",
      "Epoch 1340/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1233\n",
      "Epoch 1341/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1242\n",
      "Epoch 1342/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1257\n",
      "Epoch 1343/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0177 - val_loss: 0.1242\n",
      "Epoch 1344/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1243\n",
      "Epoch 1345/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1238\n",
      "Epoch 1346/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1260\n",
      "Epoch 1347/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1254\n",
      "Epoch 1348/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1234\n",
      "Epoch 1349/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1248\n",
      "Epoch 1350/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1266\n",
      "Epoch 1351/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0179 - val_loss: 0.1240\n",
      "Epoch 1352/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1236\n",
      "Epoch 1353/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1254\n",
      "Epoch 1354/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1258\n",
      "Epoch 1355/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1237\n",
      "Epoch 1356/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1237\n",
      "Epoch 1357/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1261\n",
      "Epoch 1358/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1250\n",
      "Epoch 1359/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1241\n",
      "Epoch 1360/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1249\n",
      "Epoch 1361/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1255\n",
      "Epoch 1362/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1245\n",
      "Epoch 1363/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1245\n",
      "Epoch 1364/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1254\n",
      "Epoch 1365/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1249\n",
      "Epoch 1366/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1245\n",
      "Epoch 1367/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1251\n",
      "Epoch 1368/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1257\n",
      "Epoch 1369/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1248\n",
      "Epoch 1370/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1247\n",
      "Epoch 1371/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1253\n",
      "Epoch 1372/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1253\n",
      "Epoch 1373/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1248\n",
      "Epoch 1374/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1249\n",
      "Epoch 1375/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1257\n",
      "Epoch 1376/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1253\n",
      "Epoch 1377/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1251\n",
      "Epoch 1378/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1258\n",
      "Epoch 1379/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1253\n",
      "Epoch 1380/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1252\n",
      "Epoch 1381/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1253\n",
      "Epoch 1382/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1255\n",
      "Epoch 1383/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1253\n",
      "Epoch 1384/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1255\n",
      "Epoch 1385/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1255\n",
      "Epoch 1386/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1252\n",
      "Epoch 1387/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1253\n",
      "Epoch 1388/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1253\n",
      "Epoch 1389/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1251\n",
      "Epoch 1390/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1251\n",
      "Epoch 1391/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1249\n",
      "Epoch 1392/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1260\n",
      "Epoch 1393/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1270\n",
      "Epoch 1394/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1254\n",
      "Epoch 1395/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1248\n",
      "Epoch 1396/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1260\n",
      "Epoch 1397/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1272\n",
      "Epoch 1398/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0176 - val_loss: 0.1248\n",
      "Epoch 1399/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1245\n",
      "Epoch 1400/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1265\n",
      "Epoch 1401/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1260\n",
      "Epoch 1402/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1249\n",
      "Epoch 1403/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1260\n",
      "Epoch 1404/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1265\n",
      "Epoch 1405/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0159 - val_loss: 0.1258\n",
      "Epoch 1406/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1255\n",
      "Epoch 1407/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1256\n",
      "Epoch 1408/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1261\n",
      "Epoch 1409/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1257\n",
      "Epoch 1410/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1253\n",
      "Epoch 1411/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1255\n",
      "Epoch 1412/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1257\n",
      "Epoch 1413/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1250\n",
      "Epoch 1414/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1246\n",
      "Epoch 1415/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1263\n",
      "Epoch 1416/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1260\n",
      "Epoch 1417/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1246\n",
      "Epoch 1418/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1253\n",
      "Epoch 1419/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1268\n",
      "Epoch 1420/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1258\n",
      "Epoch 1421/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1249\n",
      "Epoch 1422/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1255\n",
      "Epoch 1423/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1264\n",
      "Epoch 1424/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1263\n",
      "Epoch 1425/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1252\n",
      "Epoch 1426/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1256\n",
      "Epoch 1427/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1272\n",
      "Epoch 1428/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1257\n",
      "Epoch 1429/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1254\n",
      "Epoch 1430/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1264\n",
      "Epoch 1431/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1261\n",
      "Epoch 1432/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1259\n",
      "Epoch 1433/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1259\n",
      "Epoch 1434/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1258\n",
      "Epoch 1435/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1257\n",
      "Epoch 1436/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1265\n",
      "Epoch 1437/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1266\n",
      "Epoch 1438/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1260\n",
      "Epoch 1439/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1261\n",
      "Epoch 1440/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0172 - val_loss: 0.1267\n",
      "Epoch 1441/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1270\n",
      "Epoch 1442/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1259\n",
      "Epoch 1443/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0166 - val_loss: 0.1261\n",
      "Epoch 1444/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0164 - val_loss: 0.1283\n",
      "Epoch 1445/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1264\n",
      "Epoch 1446/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1257\n",
      "Epoch 1447/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1267\n",
      "Epoch 1448/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1286\n",
      "Epoch 1449/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1261\n",
      "Epoch 1450/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1254\n",
      "Epoch 1451/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1280\n",
      "Epoch 1452/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1272\n",
      "Epoch 1453/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1256\n",
      "Epoch 1454/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1262\n",
      "Epoch 1455/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1277\n",
      "Epoch 1456/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1264\n",
      "Epoch 1457/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1258\n",
      "Epoch 1458/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1265\n",
      "Epoch 1459/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1264\n",
      "Epoch 1460/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0162 - val_loss: 0.1262\n",
      "Epoch 1461/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1262\n",
      "Epoch 1462/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1271\n",
      "Epoch 1463/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1269\n",
      "Epoch 1464/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1259\n",
      "Epoch 1465/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1258\n",
      "Epoch 1466/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1266\n",
      "Epoch 1467/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1266\n",
      "Epoch 1468/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1263\n",
      "Epoch 1469/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1262\n",
      "Epoch 1470/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1269\n",
      "Epoch 1471/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1269\n",
      "Epoch 1472/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1267\n",
      "Epoch 1473/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1261\n",
      "Epoch 1474/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1278\n",
      "Epoch 1475/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1278\n",
      "Epoch 1476/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1262\n",
      "Epoch 1477/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1273\n",
      "Epoch 1478/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1278\n",
      "Epoch 1479/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1268\n",
      "Epoch 1480/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1265\n",
      "Epoch 1481/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1269\n",
      "Epoch 1482/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1288\n",
      "Epoch 1483/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1270\n",
      "Epoch 1484/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1263\n",
      "Epoch 1485/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1270\n",
      "Epoch 1486/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1284\n",
      "Epoch 1487/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1269\n",
      "Epoch 1488/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1266\n",
      "Epoch 1489/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1276\n",
      "Epoch 1490/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1289\n",
      "Epoch 1491/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1270\n",
      "Epoch 1492/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1262\n",
      "Epoch 1493/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0160 - val_loss: 0.1273\n",
      "Epoch 1494/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1291\n",
      "Epoch 1495/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1267\n",
      "Epoch 1496/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1258\n",
      "Epoch 1497/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1283\n",
      "Epoch 1498/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1291\n",
      "Epoch 1499/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1263\n",
      "Epoch 1500/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1265\n",
      "Epoch 1501/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1284\n",
      "Epoch 1502/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1274\n",
      "Epoch 1503/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1267\n",
      "Epoch 1504/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1278\n",
      "Epoch 1505/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1278\n",
      "Epoch 1506/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1273\n",
      "Epoch 1507/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1266\n",
      "Epoch 1508/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1276\n",
      "Epoch 1509/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1287\n",
      "Epoch 1510/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0169 - val_loss: 0.1270\n",
      "Epoch 1511/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1268\n",
      "Epoch 1512/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1276\n",
      "Epoch 1513/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1295\n",
      "Epoch 1514/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0159 - val_loss: 0.1277\n",
      "Epoch 1515/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1267\n",
      "Epoch 1516/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1270\n",
      "Epoch 1517/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1290\n",
      "Epoch 1518/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1280\n",
      "Epoch 1519/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1269\n",
      "Epoch 1520/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1276\n",
      "Epoch 1521/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1290\n",
      "Epoch 1522/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1274\n",
      "Epoch 1523/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1272\n",
      "Epoch 1524/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1283\n",
      "Epoch 1525/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1281\n",
      "Epoch 1526/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1277\n",
      "Epoch 1527/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1272\n",
      "Epoch 1528/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1283\n",
      "Epoch 1529/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1282\n",
      "Epoch 1530/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1280\n",
      "Epoch 1531/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1279\n",
      "Epoch 1532/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1277\n",
      "Epoch 1533/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1285\n",
      "Epoch 1534/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1285\n",
      "Epoch 1535/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1281\n",
      "Epoch 1536/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1280\n",
      "Epoch 1537/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0167 - val_loss: 0.1286\n",
      "Epoch 1538/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1283\n",
      "Epoch 1539/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1278\n",
      "Epoch 1540/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0158 - val_loss: 0.1285\n",
      "Epoch 1541/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1296\n",
      "Epoch 1542/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1273\n",
      "Epoch 1543/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1273\n",
      "Epoch 1544/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1293\n",
      "Epoch 1545/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1285\n",
      "Epoch 1546/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1274\n",
      "Epoch 1547/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1279\n",
      "Epoch 1548/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1287\n",
      "Epoch 1549/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1284\n",
      "Epoch 1550/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1275\n",
      "Epoch 1551/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1281\n",
      "Epoch 1552/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1290\n",
      "Epoch 1553/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1283\n",
      "Epoch 1554/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1274\n",
      "Epoch 1555/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1291\n",
      "Epoch 1556/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1292\n",
      "Epoch 1557/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1276\n",
      "Epoch 1558/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1273\n",
      "Epoch 1559/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1292\n",
      "Epoch 1560/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1291\n",
      "Epoch 1561/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1273\n",
      "Epoch 1562/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1278\n",
      "Epoch 1563/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1301\n",
      "Epoch 1564/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1293\n",
      "Epoch 1565/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0154 - val_loss: 0.1280\n",
      "Epoch 1566/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1284\n",
      "Epoch 1567/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0163 - val_loss: 0.1304\n",
      "Epoch 1568/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1296\n",
      "Epoch 1569/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0153 - val_loss: 0.1287\n",
      "Epoch 1570/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0165 - val_loss: 0.1285\n",
      "Epoch 1571/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1322\n",
      "Epoch 1572/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0171 - val_loss: 0.1291\n",
      "Epoch 1573/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1290\n",
      "Epoch 1574/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0174 - val_loss: 0.1282\n",
      "Epoch 1575/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1319\n",
      "Epoch 1576/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0175 - val_loss: 0.1297\n",
      "Epoch 1577/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1279\n",
      "Epoch 1578/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0146 - val_loss: 0.1289\n",
      "Epoch 1579/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0139 - val_loss: 0.1311\n",
      "Epoch 1580/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0146 - val_loss: 0.1292\n",
      "Epoch 1581/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1279\n",
      "Epoch 1582/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1298\n",
      "Epoch 1583/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1324\n",
      "Epoch 1584/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0161 - val_loss: 0.1282\n",
      "Epoch 1585/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1279\n",
      "Epoch 1586/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0155 - val_loss: 0.1295\n",
      "Epoch 1587/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1311\n",
      "Epoch 1588/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1282\n",
      "Epoch 1589/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1280\n",
      "Epoch 1590/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0151 - val_loss: 0.1297\n",
      "Epoch 1591/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1296\n",
      "Epoch 1592/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1286\n",
      "Epoch 1593/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1284\n",
      "Epoch 1594/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1300\n",
      "Epoch 1595/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1300\n",
      "Epoch 1596/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1284\n",
      "Epoch 1597/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1284\n",
      "Epoch 1598/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1299\n",
      "Epoch 1599/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1299\n",
      "Epoch 1600/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1284\n",
      "Epoch 1601/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1288\n",
      "Epoch 1602/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1299\n",
      "Epoch 1603/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1292\n",
      "Epoch 1604/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1288\n",
      "Epoch 1605/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1290\n",
      "Epoch 1606/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1297\n",
      "Epoch 1607/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1294\n",
      "Epoch 1608/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1293\n",
      "Epoch 1609/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0138 - val_loss: 0.1289\n",
      "Epoch 1610/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1297\n",
      "Epoch 1611/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1294\n",
      "Epoch 1612/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1284\n",
      "Epoch 1613/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1298\n",
      "Epoch 1614/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1295\n",
      "Epoch 1615/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1283\n",
      "Epoch 1616/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1287\n",
      "Epoch 1617/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1298\n",
      "Epoch 1618/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1300\n",
      "Epoch 1619/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1289\n",
      "Epoch 1620/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1287\n",
      "Epoch 1621/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1300\n",
      "Epoch 1622/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1296\n",
      "Epoch 1623/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1286\n",
      "Epoch 1624/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1291\n",
      "Epoch 1625/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1301\n",
      "Epoch 1626/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1293\n",
      "Epoch 1627/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1288\n",
      "Epoch 1628/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1302\n",
      "Epoch 1629/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1308\n",
      "Epoch 1630/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1289\n",
      "Epoch 1631/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1288\n",
      "Epoch 1632/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1299\n",
      "Epoch 1633/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1297\n",
      "Epoch 1634/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1289\n",
      "Epoch 1635/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1290\n",
      "Epoch 1636/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1297\n",
      "Epoch 1637/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1296\n",
      "Epoch 1638/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1295\n",
      "Epoch 1639/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1290\n",
      "Epoch 1640/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1293\n",
      "Epoch 1641/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0138 - val_loss: 0.1302\n",
      "Epoch 1642/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1294\n",
      "Epoch 1643/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1291\n",
      "Epoch 1644/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1296\n",
      "Epoch 1645/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1296\n",
      "Epoch 1646/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1292\n",
      "Epoch 1647/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1291\n",
      "Epoch 1648/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1304\n",
      "Epoch 1649/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1304\n",
      "Epoch 1650/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1290\n",
      "Epoch 1651/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1295\n",
      "Epoch 1652/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1309\n",
      "Epoch 1653/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1300\n",
      "Epoch 1654/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1292\n",
      "Epoch 1655/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1300\n",
      "Epoch 1656/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1309\n",
      "Epoch 1657/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1295\n",
      "Epoch 1658/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1296\n",
      "Epoch 1659/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1312\n",
      "Epoch 1660/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1312\n",
      "Epoch 1661/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1296\n",
      "Epoch 1662/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1294\n",
      "Epoch 1663/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1307\n",
      "Epoch 1664/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1306\n",
      "Epoch 1665/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1295\n",
      "Epoch 1666/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1295\n",
      "Epoch 1667/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1304\n",
      "Epoch 1668/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1300\n",
      "Epoch 1669/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1290\n",
      "Epoch 1670/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1299\n",
      "Epoch 1671/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1308\n",
      "Epoch 1672/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1298\n",
      "Epoch 1673/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1292\n",
      "Epoch 1674/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1300\n",
      "Epoch 1675/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1318\n",
      "Epoch 1676/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1299\n",
      "Epoch 1677/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1295\n",
      "Epoch 1678/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1315\n",
      "Epoch 1679/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1299\n",
      "Epoch 1680/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1306\n",
      "Epoch 1681/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1304\n",
      "Epoch 1682/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1301\n",
      "Epoch 1683/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1307\n",
      "Epoch 1684/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1302\n",
      "Epoch 1685/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1313\n",
      "Epoch 1686/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0146 - val_loss: 0.1302\n",
      "Epoch 1687/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1302\n",
      "Epoch 1688/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1317\n",
      "Epoch 1689/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1301\n",
      "Epoch 1690/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1305\n",
      "Epoch 1691/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1308\n",
      "Epoch 1692/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1308\n",
      "Epoch 1693/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1306\n",
      "Epoch 1694/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1304\n",
      "Epoch 1695/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1323\n",
      "Epoch 1696/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0156 - val_loss: 0.1299\n",
      "Epoch 1697/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1311\n",
      "Epoch 1698/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1314\n",
      "Epoch 1699/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1308\n",
      "Epoch 1700/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1305\n",
      "Epoch 1701/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0148 - val_loss: 0.1308\n",
      "Epoch 1702/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1313\n",
      "Epoch 1703/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0152 - val_loss: 0.1307\n",
      "Epoch 1704/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1313\n",
      "Epoch 1705/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1312\n",
      "Epoch 1706/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1302\n",
      "Epoch 1707/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0141 - val_loss: 0.1318\n",
      "Epoch 1708/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1314\n",
      "Epoch 1709/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1307\n",
      "Epoch 1710/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1302\n",
      "Epoch 1711/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1317\n",
      "Epoch 1712/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1317\n",
      "Epoch 1713/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1300\n",
      "Epoch 1714/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1303\n",
      "Epoch 1715/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1319\n",
      "Epoch 1716/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0145 - val_loss: 0.1310\n",
      "Epoch 1717/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1304\n",
      "Epoch 1718/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1308\n",
      "Epoch 1719/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1315\n",
      "Epoch 1720/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1311\n",
      "Epoch 1721/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1306\n",
      "Epoch 1722/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1311\n",
      "Epoch 1723/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1310\n",
      "Epoch 1724/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1317\n",
      "Epoch 1725/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1308\n",
      "Epoch 1726/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1299\n",
      "Epoch 1727/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1311\n",
      "Epoch 1728/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1319\n",
      "Epoch 1729/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1304\n",
      "Epoch 1730/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1303\n",
      "Epoch 1731/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1309\n",
      "Epoch 1732/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1310\n",
      "Epoch 1733/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1310\n",
      "Epoch 1734/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1309\n",
      "Epoch 1735/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1311\n",
      "Epoch 1736/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1316\n",
      "Epoch 1737/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1308\n",
      "Epoch 1738/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1324\n",
      "Epoch 1739/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0157 - val_loss: 0.1308\n",
      "Epoch 1740/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1323\n",
      "Epoch 1741/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1319\n",
      "Epoch 1742/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0149 - val_loss: 0.1308\n",
      "Epoch 1743/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1319\n",
      "Epoch 1744/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1314\n",
      "Epoch 1745/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1313\n",
      "Epoch 1746/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1305\n",
      "Epoch 1747/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1317\n",
      "Epoch 1748/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1312\n",
      "Epoch 1749/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1302\n",
      "Epoch 1750/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1309\n",
      "Epoch 1751/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1325\n",
      "Epoch 1752/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1313\n",
      "Epoch 1753/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1304\n",
      "Epoch 1754/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1313\n",
      "Epoch 1755/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1325\n",
      "Epoch 1756/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1310\n",
      "Epoch 1757/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1305\n",
      "Epoch 1758/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1324\n",
      "Epoch 1759/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1324\n",
      "Epoch 1760/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1306\n",
      "Epoch 1761/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1307\n",
      "Epoch 1762/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1319\n",
      "Epoch 1763/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1318\n",
      "Epoch 1764/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1310\n",
      "Epoch 1765/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1311\n",
      "Epoch 1766/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1322\n",
      "Epoch 1767/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1312\n",
      "Epoch 1768/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1310\n",
      "Epoch 1769/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1317\n",
      "Epoch 1770/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0147 - val_loss: 0.1324\n",
      "Epoch 1771/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1313\n",
      "Epoch 1772/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1313\n",
      "Epoch 1773/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1324\n",
      "Epoch 1774/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1317\n",
      "Epoch 1775/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1309\n",
      "Epoch 1776/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1328\n",
      "Epoch 1777/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1329\n",
      "Epoch 1778/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1309\n",
      "Epoch 1779/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1317\n",
      "Epoch 1780/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1328\n",
      "Epoch 1781/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1324\n",
      "Epoch 1782/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1313\n",
      "Epoch 1783/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1317\n",
      "Epoch 1784/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1320\n",
      "Epoch 1785/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1318\n",
      "Epoch 1786/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1314\n",
      "Epoch 1787/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1318\n",
      "Epoch 1788/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1317\n",
      "Epoch 1789/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1317\n",
      "Epoch 1790/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1313\n",
      "Epoch 1791/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1316\n",
      "Epoch 1792/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1319\n",
      "Epoch 1793/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1319\n",
      "Epoch 1794/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1314\n",
      "Epoch 1795/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1319\n",
      "Epoch 1796/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1322\n",
      "Epoch 1797/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1320\n",
      "Epoch 1798/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1316\n",
      "Epoch 1799/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1322\n",
      "Epoch 1800/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1329\n",
      "Epoch 1801/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1319\n",
      "Epoch 1802/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1316\n",
      "Epoch 1803/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1328\n",
      "Epoch 1804/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1328\n",
      "Epoch 1805/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1315\n",
      "Epoch 1806/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1318\n",
      "Epoch 1807/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1333\n",
      "Epoch 1808/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1327\n",
      "Epoch 1809/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1316\n",
      "Epoch 1810/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1322\n",
      "Epoch 1811/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1326\n",
      "Epoch 1812/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1327\n",
      "Epoch 1813/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1319\n",
      "Epoch 1814/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1323\n",
      "Epoch 1815/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1329\n",
      "Epoch 1816/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1324\n",
      "Epoch 1817/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1323\n",
      "Epoch 1818/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1327\n",
      "Epoch 1819/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1334\n",
      "Epoch 1820/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1324\n",
      "Epoch 1821/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1323\n",
      "Epoch 1822/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1328\n",
      "Epoch 1823/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0119 - val_loss: 0.1327\n",
      "Epoch 1824/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0121 - val_loss: 0.1322\n",
      "Epoch 1825/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1327\n",
      "Epoch 1826/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1328\n",
      "Epoch 1827/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1321\n",
      "Epoch 1828/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1330\n",
      "Epoch 1829/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1331\n",
      "Epoch 1830/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1321\n",
      "Epoch 1831/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1329\n",
      "Epoch 1832/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1332\n",
      "Epoch 1833/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1327\n",
      "Epoch 1834/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1324\n",
      "Epoch 1835/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1341\n",
      "Epoch 1836/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1336\n",
      "Epoch 1837/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1321\n",
      "Epoch 1838/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1337\n",
      "Epoch 1839/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1343\n",
      "Epoch 1840/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1323\n",
      "Epoch 1841/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1328\n",
      "Epoch 1842/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1338\n",
      "Epoch 1843/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1338\n",
      "Epoch 1844/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1329\n",
      "Epoch 1845/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1332\n",
      "Epoch 1846/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1342\n",
      "Epoch 1847/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1329\n",
      "Epoch 1848/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1326\n",
      "Epoch 1849/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1350\n",
      "Epoch 1850/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1337\n",
      "Epoch 1851/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1328\n",
      "Epoch 1852/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1330\n",
      "Epoch 1853/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1345\n",
      "Epoch 1854/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1347\n",
      "Epoch 1855/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1329\n",
      "Epoch 1856/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1350\n",
      "Epoch 1857/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1339\n",
      "Epoch 1858/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1338\n",
      "Epoch 1859/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1349\n",
      "Epoch 1860/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0144 - val_loss: 0.1328\n",
      "Epoch 1861/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1346\n",
      "Epoch 1862/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1344\n",
      "Epoch 1863/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1331\n",
      "Epoch 1864/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1333\n",
      "Epoch 1865/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1336\n",
      "Epoch 1866/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1345\n",
      "Epoch 1867/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1329\n",
      "Epoch 1868/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1329\n",
      "Epoch 1869/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1347\n",
      "Epoch 1870/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0150 - val_loss: 0.1335\n",
      "Epoch 1871/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1331\n",
      "Epoch 1872/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1344\n",
      "Epoch 1873/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1333\n",
      "Epoch 1874/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1330\n",
      "Epoch 1875/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1334\n",
      "Epoch 1876/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1333\n",
      "Epoch 1877/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1337\n",
      "Epoch 1878/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1333\n",
      "Epoch 1879/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1337\n",
      "Epoch 1880/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1335\n",
      "Epoch 1881/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1332\n",
      "Epoch 1882/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1350\n",
      "Epoch 1883/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1335\n",
      "Epoch 1884/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1333\n",
      "Epoch 1885/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1336\n",
      "Epoch 1886/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1336\n",
      "Epoch 1887/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1332\n",
      "Epoch 1888/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1335\n",
      "Epoch 1889/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1340\n",
      "Epoch 1890/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1331\n",
      "Epoch 1891/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1335\n",
      "Epoch 1892/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1340\n",
      "Epoch 1893/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1340\n",
      "Epoch 1894/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1337\n",
      "Epoch 1895/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1338\n",
      "Epoch 1896/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1338\n",
      "Epoch 1897/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1344\n",
      "Epoch 1898/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1344\n",
      "Epoch 1899/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1335\n",
      "Epoch 1900/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1343\n",
      "Epoch 1901/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1342\n",
      "Epoch 1902/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1340\n",
      "Epoch 1903/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1343\n",
      "Epoch 1904/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0140 - val_loss: 0.1335\n",
      "Epoch 1905/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1344\n",
      "Epoch 1906/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0136 - val_loss: 0.1338\n",
      "Epoch 1907/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1339\n",
      "Epoch 1908/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1337\n",
      "Epoch 1909/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0139 - val_loss: 0.1335\n",
      "Epoch 1910/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1347\n",
      "Epoch 1911/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1346\n",
      "Epoch 1912/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1331\n",
      "Epoch 1913/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1346\n",
      "Epoch 1914/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1343\n",
      "Epoch 1915/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1336\n",
      "Epoch 1916/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1342\n",
      "Epoch 1917/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1341\n",
      "Epoch 1918/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1347\n",
      "Epoch 1919/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1336\n",
      "Epoch 1920/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1342\n",
      "Epoch 1921/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1345\n",
      "Epoch 1922/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1345\n",
      "Epoch 1923/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1341\n",
      "Epoch 1924/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0138 - val_loss: 0.1343\n",
      "Epoch 1925/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1349\n",
      "Epoch 1926/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1344\n",
      "Epoch 1927/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1344\n",
      "Epoch 1928/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1344\n",
      "Epoch 1929/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1347\n",
      "Epoch 1930/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1345\n",
      "Epoch 1931/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1343\n",
      "Epoch 1932/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1348\n",
      "Epoch 1933/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1348\n",
      "Epoch 1934/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1344\n",
      "Epoch 1935/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1339\n",
      "Epoch 1936/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1352\n",
      "Epoch 1937/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1349\n",
      "Epoch 1938/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1338\n",
      "Epoch 1939/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1342\n",
      "Epoch 1940/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1358\n",
      "Epoch 1941/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1343\n",
      "Epoch 1942/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1338\n",
      "Epoch 1943/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1343\n",
      "Epoch 1944/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1364\n",
      "Epoch 1945/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1346\n",
      "Epoch 1946/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1338\n",
      "Epoch 1947/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1349\n",
      "Epoch 1948/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1353\n",
      "Epoch 1949/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1346\n",
      "Epoch 1950/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1343\n",
      "Epoch 1951/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1350\n",
      "Epoch 1952/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1353\n",
      "Epoch 1953/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1345\n",
      "Epoch 1954/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1349\n",
      "Epoch 1955/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1350\n",
      "Epoch 1956/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1347\n",
      "Epoch 1957/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1345\n",
      "Epoch 1958/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1349\n",
      "Epoch 1959/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1350\n",
      "Epoch 1960/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1346\n",
      "Epoch 1961/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1342\n",
      "Epoch 1962/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1348\n",
      "Epoch 1963/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1348\n",
      "Epoch 1964/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1345\n",
      "Epoch 1965/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1348\n",
      "Epoch 1966/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1350\n",
      "Epoch 1967/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1346\n",
      "Epoch 1968/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1348\n",
      "Epoch 1969/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1349\n",
      "Epoch 1970/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1359\n",
      "Epoch 1971/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1350\n",
      "Epoch 1972/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1344\n",
      "Epoch 1973/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1349\n",
      "Epoch 1974/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1355\n",
      "Epoch 1975/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1344\n",
      "Epoch 1976/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1347\n",
      "Epoch 1977/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1351\n",
      "Epoch 1978/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1346\n",
      "Epoch 1979/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1351\n",
      "Epoch 1980/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1347\n",
      "Epoch 1981/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1349\n",
      "Epoch 1982/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1346\n",
      "Epoch 1983/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1348\n",
      "Epoch 1984/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1362\n",
      "Epoch 1985/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1343\n",
      "Epoch 1986/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1348\n",
      "Epoch 1987/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1361\n",
      "Epoch 1988/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1350\n",
      "Epoch 1989/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1347\n",
      "Epoch 1990/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1349\n",
      "Epoch 1991/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1370\n",
      "Epoch 1992/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0143 - val_loss: 0.1346\n",
      "Epoch 1993/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1345\n",
      "Epoch 1994/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1364\n",
      "Epoch 1995/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1361\n",
      "Epoch 1996/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1350\n",
      "Epoch 1997/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1348\n",
      "Epoch 1998/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1356\n",
      "Epoch 1999/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1355\n",
      "Epoch 2000/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1347\n",
      "Epoch 2001/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1347\n",
      "Epoch 2002/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1363\n",
      "Epoch 2003/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1356\n",
      "Epoch 2004/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1346\n",
      "Epoch 2005/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1358\n",
      "Epoch 2006/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1363\n",
      "Epoch 2007/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1348\n",
      "Epoch 2008/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1350\n",
      "Epoch 2009/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1359\n",
      "Epoch 2010/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1354\n",
      "Epoch 2011/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1349\n",
      "Epoch 2012/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1351\n",
      "Epoch 2013/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1352\n",
      "Epoch 2014/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1353\n",
      "Epoch 2015/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1349\n",
      "Epoch 2016/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1349\n",
      "Epoch 2017/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1351\n",
      "Epoch 2018/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1355\n",
      "Epoch 2019/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1356\n",
      "Epoch 2020/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1349\n",
      "Epoch 2021/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1358\n",
      "Epoch 2022/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1356\n",
      "Epoch 2023/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1352\n",
      "Epoch 2024/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1356\n",
      "Epoch 2025/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1353\n",
      "Epoch 2026/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1350\n",
      "Epoch 2027/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1358\n",
      "Epoch 2028/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1356\n",
      "Epoch 2029/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1351\n",
      "Epoch 2030/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1353\n",
      "Epoch 2031/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1354\n",
      "Epoch 2032/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1359\n",
      "Epoch 2033/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1359\n",
      "Epoch 2034/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1355\n",
      "Epoch 2035/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1358\n",
      "Epoch 2036/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1364\n",
      "Epoch 2037/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1355\n",
      "Epoch 2038/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1355\n",
      "Epoch 2039/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1361\n",
      "Epoch 2040/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1357\n",
      "Epoch 2041/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1355\n",
      "Epoch 2042/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1359\n",
      "Epoch 2043/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1354\n",
      "Epoch 2044/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1353\n",
      "Epoch 2045/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1357\n",
      "Epoch 2046/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1361\n",
      "Epoch 2047/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1357\n",
      "Epoch 2048/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1355\n",
      "Epoch 2049/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1362\n",
      "Epoch 2050/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1364\n",
      "Epoch 2051/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1356\n",
      "Epoch 2052/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1354\n",
      "Epoch 2053/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1363\n",
      "Epoch 2054/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1368\n",
      "Epoch 2055/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1353\n",
      "Epoch 2056/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1357\n",
      "Epoch 2057/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1371\n",
      "Epoch 2058/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1361\n",
      "Epoch 2059/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1358\n",
      "Epoch 2060/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1370\n",
      "Epoch 2061/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0126 - val_loss: 0.1372\n",
      "Epoch 2062/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1359\n",
      "Epoch 2063/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1362\n",
      "Epoch 2064/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1380\n",
      "Epoch 2065/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1361\n",
      "Epoch 2066/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1358\n",
      "Epoch 2067/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1367\n",
      "Epoch 2068/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1367\n",
      "Epoch 2069/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1357\n",
      "Epoch 2070/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1362\n",
      "Epoch 2071/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1367\n",
      "Epoch 2072/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1362\n",
      "Epoch 2073/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1360\n",
      "Epoch 2074/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1368\n",
      "Epoch 2075/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1362\n",
      "Epoch 2076/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1360\n",
      "Epoch 2077/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1363\n",
      "Epoch 2078/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1362\n",
      "Epoch 2079/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1360\n",
      "Epoch 2080/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1358\n",
      "Epoch 2081/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1362\n",
      "Epoch 2082/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1362\n",
      "Epoch 2083/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1360\n",
      "Epoch 2084/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1360\n",
      "Epoch 2085/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1361\n",
      "Epoch 2086/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1366\n",
      "Epoch 2087/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1362\n",
      "Epoch 2088/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1360\n",
      "Epoch 2089/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1364\n",
      "Epoch 2090/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1366\n",
      "Epoch 2091/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1360\n",
      "Epoch 2092/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1361\n",
      "Epoch 2093/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1368\n",
      "Epoch 2094/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1362\n",
      "Epoch 2095/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1360\n",
      "Epoch 2096/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1365\n",
      "Epoch 2097/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1365\n",
      "Epoch 2098/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1363\n",
      "Epoch 2099/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1364\n",
      "Epoch 2100/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1367\n",
      "Epoch 2101/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1374\n",
      "Epoch 2102/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1367\n",
      "Epoch 2103/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1365\n",
      "Epoch 2104/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1379\n",
      "Epoch 2105/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1382\n",
      "Epoch 2106/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1362\n",
      "Epoch 2107/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1371\n",
      "Epoch 2108/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1382\n",
      "Epoch 2109/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1358\n",
      "Epoch 2110/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1373\n",
      "Epoch 2111/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1366\n",
      "Epoch 2112/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1368\n",
      "Epoch 2113/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1370\n",
      "Epoch 2114/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0134 - val_loss: 0.1360\n",
      "Epoch 2115/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1367\n",
      "Epoch 2116/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1372\n",
      "Epoch 2117/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1367\n",
      "Epoch 2118/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1365\n",
      "Epoch 2119/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1364\n",
      "Epoch 2120/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0108 - val_loss: 0.1371\n",
      "Epoch 2121/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1367\n",
      "Epoch 2122/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1366\n",
      "Epoch 2123/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1368\n",
      "Epoch 2124/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1364\n",
      "Epoch 2125/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1365\n",
      "Epoch 2126/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1371\n",
      "Epoch 2127/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1369\n",
      "Epoch 2128/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1367\n",
      "Epoch 2129/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1364\n",
      "Epoch 2130/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1377\n",
      "Epoch 2131/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1370\n",
      "Epoch 2132/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1364\n",
      "Epoch 2133/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1377\n",
      "Epoch 2134/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1373\n",
      "Epoch 2135/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1364\n",
      "Epoch 2136/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1377\n",
      "Epoch 2137/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1379\n",
      "Epoch 2138/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1367\n",
      "Epoch 2139/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0120 - val_loss: 0.1374\n",
      "Epoch 2140/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1374\n",
      "Epoch 2141/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1373\n",
      "Epoch 2142/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1377\n",
      "Epoch 2143/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1370\n",
      "Epoch 2144/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1382\n",
      "Epoch 2145/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1371\n",
      "Epoch 2146/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1368\n",
      "Epoch 2147/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1381\n",
      "Epoch 2148/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1373\n",
      "Epoch 2149/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1371\n",
      "Epoch 2150/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1373\n",
      "Epoch 2151/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1374\n",
      "Epoch 2152/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1376\n",
      "Epoch 2153/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1367\n",
      "Epoch 2154/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1381\n",
      "Epoch 2155/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1374\n",
      "Epoch 2156/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1370\n",
      "Epoch 2157/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1379\n",
      "Epoch 2158/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1369\n",
      "Epoch 2159/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1373\n",
      "Epoch 2160/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1370\n",
      "Epoch 2161/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1376\n",
      "Epoch 2162/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1370\n",
      "Epoch 2163/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1375\n",
      "Epoch 2164/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1373\n",
      "Epoch 2165/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1367\n",
      "Epoch 2166/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1384\n",
      "Epoch 2167/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1375\n",
      "Epoch 2168/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1367\n",
      "Epoch 2169/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1386\n",
      "Epoch 2170/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1379\n",
      "Epoch 2171/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1368\n",
      "Epoch 2172/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1378\n",
      "Epoch 2173/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1377\n",
      "Epoch 2174/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1370\n",
      "Epoch 2175/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1372\n",
      "Epoch 2176/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1376\n",
      "Epoch 2177/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1378\n",
      "Epoch 2178/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1371\n",
      "Epoch 2179/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1377\n",
      "Epoch 2180/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1379\n",
      "Epoch 2181/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1375\n",
      "Epoch 2182/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1372\n",
      "Epoch 2183/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1388\n",
      "Epoch 2184/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1383\n",
      "Epoch 2185/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1369\n",
      "Epoch 2186/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1385\n",
      "Epoch 2187/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1383\n",
      "Epoch 2188/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0118 - val_loss: 0.1372\n",
      "Epoch 2189/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1378\n",
      "Epoch 2190/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1375\n",
      "Epoch 2191/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1375\n",
      "Epoch 2192/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1376\n",
      "Epoch 2193/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1380\n",
      "Epoch 2194/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1379\n",
      "Epoch 2195/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1373\n",
      "Epoch 2196/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1382\n",
      "Epoch 2197/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1382\n",
      "Epoch 2198/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1374\n",
      "Epoch 2199/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1377\n",
      "Epoch 2200/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1384\n",
      "Epoch 2201/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0117 - val_loss: 0.1375\n",
      "Epoch 2202/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1376\n",
      "Epoch 2203/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1382\n",
      "Epoch 2204/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1385\n",
      "Epoch 2205/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1377\n",
      "Epoch 2206/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1376\n",
      "Epoch 2207/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1388\n",
      "Epoch 2208/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1381\n",
      "Epoch 2209/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1374\n",
      "Epoch 2210/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1377\n",
      "Epoch 2211/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1383\n",
      "Epoch 2212/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1374\n",
      "Epoch 2213/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1377\n",
      "Epoch 2214/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1383\n",
      "Epoch 2215/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1380\n",
      "Epoch 2216/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1380\n",
      "Epoch 2217/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1387\n",
      "Epoch 2218/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1382\n",
      "Epoch 2219/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1384\n",
      "Epoch 2220/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1386\n",
      "Epoch 2221/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1386\n",
      "Epoch 2222/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1382\n",
      "Epoch 2223/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1381\n",
      "Epoch 2224/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1382\n",
      "Epoch 2225/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1385\n",
      "Epoch 2226/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1383\n",
      "Epoch 2227/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1378\n",
      "Epoch 2228/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1393\n",
      "Epoch 2229/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1380\n",
      "Epoch 2230/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1378\n",
      "Epoch 2231/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1387\n",
      "Epoch 2232/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1386\n",
      "Epoch 2233/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1383\n",
      "Epoch 2234/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1378\n",
      "Epoch 2235/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1387\n",
      "Epoch 2236/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1385\n",
      "Epoch 2237/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1378\n",
      "Epoch 2238/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1388\n",
      "Epoch 2239/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1385\n",
      "Epoch 2240/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1379\n",
      "Epoch 2241/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1388\n",
      "Epoch 2242/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1382\n",
      "Epoch 2243/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1381\n",
      "Epoch 2244/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1389\n",
      "Epoch 2245/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1386\n",
      "Epoch 2246/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1383\n",
      "Epoch 2247/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1386\n",
      "Epoch 2248/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1380\n",
      "Epoch 2249/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1392\n",
      "Epoch 2250/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1388\n",
      "Epoch 2251/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1379\n",
      "Epoch 2252/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1387\n",
      "Epoch 2253/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1385\n",
      "Epoch 2254/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1383\n",
      "Epoch 2255/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1385\n",
      "Epoch 2256/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1386\n",
      "Epoch 2257/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1390\n",
      "Epoch 2258/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1386\n",
      "Epoch 2259/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1385\n",
      "Epoch 2260/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1393\n",
      "Epoch 2261/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1387\n",
      "Epoch 2262/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1384\n",
      "Epoch 2263/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1387\n",
      "Epoch 2264/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1388\n",
      "Epoch 2265/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1388\n",
      "Epoch 2266/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1387\n",
      "Epoch 2267/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1386\n",
      "Epoch 2268/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1389\n",
      "Epoch 2269/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1385\n",
      "Epoch 2270/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1389\n",
      "Epoch 2271/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1394\n",
      "Epoch 2272/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1387\n",
      "Epoch 2273/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1387\n",
      "Epoch 2274/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1395\n",
      "Epoch 2275/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1390\n",
      "Epoch 2276/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1383\n",
      "Epoch 2277/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1394\n",
      "Epoch 2278/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1398\n",
      "Epoch 2279/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1384\n",
      "Epoch 2280/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1386\n",
      "Epoch 2281/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1402\n",
      "Epoch 2282/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1384\n",
      "Epoch 2283/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1382\n",
      "Epoch 2284/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1396\n",
      "Epoch 2285/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1390\n",
      "Epoch 2286/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1384\n",
      "Epoch 2287/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1394\n",
      "Epoch 2288/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1395\n",
      "Epoch 2289/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1387\n",
      "Epoch 2290/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1393\n",
      "Epoch 2291/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1406\n",
      "Epoch 2292/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1391\n",
      "Epoch 2293/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1390\n",
      "Epoch 2294/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1408\n",
      "Epoch 2295/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1409\n",
      "Epoch 2296/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1388\n",
      "Epoch 2297/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1389\n",
      "Epoch 2298/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1414\n",
      "Epoch 2299/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1394\n",
      "Epoch 2300/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1391\n",
      "Epoch 2301/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1424\n",
      "Epoch 2302/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1417\n",
      "Epoch 2303/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0141 - val_loss: 0.1392\n",
      "Epoch 2304/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1400\n",
      "Epoch 2305/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1417\n",
      "Epoch 2306/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0131 - val_loss: 0.1389\n",
      "Epoch 2307/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1391\n",
      "Epoch 2308/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1400\n",
      "Epoch 2309/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1397\n",
      "Epoch 2310/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1385\n",
      "Epoch 2311/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1387\n",
      "Epoch 2312/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1406\n",
      "Epoch 2313/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1386\n",
      "Epoch 2314/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1384\n",
      "Epoch 2315/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1403\n",
      "Epoch 2316/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1401\n",
      "Epoch 2317/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1386\n",
      "Epoch 2318/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1391\n",
      "Epoch 2319/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1411\n",
      "Epoch 2320/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1390\n",
      "Epoch 2321/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1391\n",
      "Epoch 2322/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1414\n",
      "Epoch 2323/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1408\n",
      "Epoch 2324/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1390\n",
      "Epoch 2325/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1392\n",
      "Epoch 2326/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1421\n",
      "Epoch 2327/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1393\n",
      "Epoch 2328/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1390\n",
      "Epoch 2329/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1402\n",
      "Epoch 2330/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1407\n",
      "Epoch 2331/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1386\n",
      "Epoch 2332/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1389\n",
      "Epoch 2333/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1410\n",
      "Epoch 2334/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1395\n",
      "Epoch 2335/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1391\n",
      "Epoch 2336/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1398\n",
      "Epoch 2337/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1406\n",
      "Epoch 2338/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1394\n",
      "Epoch 2339/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1393\n",
      "Epoch 2340/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1404\n",
      "Epoch 2341/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1395\n",
      "Epoch 2342/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1391\n",
      "Epoch 2343/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1390\n",
      "Epoch 2344/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1410\n",
      "Epoch 2345/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0121 - val_loss: 0.1405\n",
      "Epoch 2346/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0128 - val_loss: 0.1392\n",
      "Epoch 2347/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0127 - val_loss: 0.1401\n",
      "Epoch 2348/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1413\n",
      "Epoch 2349/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1395\n",
      "Epoch 2350/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1398\n",
      "Epoch 2351/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0125 - val_loss: 0.1402\n",
      "Epoch 2352/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1421\n",
      "Epoch 2353/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0130 - val_loss: 0.1400\n",
      "Epoch 2354/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1398\n",
      "Epoch 2355/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1413\n",
      "Epoch 2356/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1403\n",
      "Epoch 2357/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1402\n",
      "Epoch 2358/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1390\n",
      "Epoch 2359/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0114 - val_loss: 0.1416\n",
      "Epoch 2360/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1411\n",
      "Epoch 2361/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0135 - val_loss: 0.1389\n",
      "Epoch 2362/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0118 - val_loss: 0.1400\n",
      "Epoch 2363/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1406\n",
      "Epoch 2364/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1398\n",
      "Epoch 2365/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1394\n",
      "Epoch 2366/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1398\n",
      "Epoch 2367/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1412\n",
      "Epoch 2368/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1394\n",
      "Epoch 2369/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1394\n",
      "Epoch 2370/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1404\n",
      "Epoch 2371/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1403\n",
      "Epoch 2372/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1395\n",
      "Epoch 2373/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1394\n",
      "Epoch 2374/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1403\n",
      "Epoch 2375/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1407\n",
      "Epoch 2376/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1396\n",
      "Epoch 2377/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1394\n",
      "Epoch 2378/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1406\n",
      "Epoch 2379/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1409\n",
      "Epoch 2380/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1398\n",
      "Epoch 2381/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1399\n",
      "Epoch 2382/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1406\n",
      "Epoch 2383/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1407\n",
      "Epoch 2384/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1398\n",
      "Epoch 2385/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1398\n",
      "Epoch 2386/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1408\n",
      "Epoch 2387/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1402\n",
      "Epoch 2388/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1397\n",
      "Epoch 2389/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1403\n",
      "Epoch 2390/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1409\n",
      "Epoch 2391/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1399\n",
      "Epoch 2392/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1398\n",
      "Epoch 2393/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1406\n",
      "Epoch 2394/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1403\n",
      "Epoch 2395/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1398\n",
      "Epoch 2396/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1406\n",
      "Epoch 2397/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1411\n",
      "Epoch 2398/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1399\n",
      "Epoch 2399/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1399\n",
      "Epoch 2400/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1411\n",
      "Epoch 2401/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1407\n",
      "Epoch 2402/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1398\n",
      "Epoch 2403/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1402\n",
      "Epoch 2404/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1409\n",
      "Epoch 2405/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1403\n",
      "Epoch 2406/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1397\n",
      "Epoch 2407/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1406\n",
      "Epoch 2408/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1408\n",
      "Epoch 2409/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1397\n",
      "Epoch 2410/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1399\n",
      "Epoch 2411/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1404\n",
      "Epoch 2412/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1402\n",
      "Epoch 2413/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1400\n",
      "Epoch 2414/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1404\n",
      "Epoch 2415/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1399\n",
      "Epoch 2416/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1404\n",
      "Epoch 2417/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1402\n",
      "Epoch 2418/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1403\n",
      "Epoch 2419/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1397\n",
      "Epoch 2420/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1404\n",
      "Epoch 2421/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1402\n",
      "Epoch 2422/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1396\n",
      "Epoch 2423/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1398\n",
      "Epoch 2424/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1405\n",
      "Epoch 2425/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1400\n",
      "Epoch 2426/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1396\n",
      "Epoch 2427/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1401\n",
      "Epoch 2428/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1410\n",
      "Epoch 2429/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1401\n",
      "Epoch 2430/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1401\n",
      "Epoch 2431/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1408\n",
      "Epoch 2432/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0103 - val_loss: 0.1407\n",
      "Epoch 2433/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1402\n",
      "Epoch 2434/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1405\n",
      "Epoch 2435/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1414\n",
      "Epoch 2436/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1407\n",
      "Epoch 2437/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1401\n",
      "Epoch 2438/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0109 - val_loss: 0.1408\n",
      "Epoch 2439/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1414\n",
      "Epoch 2440/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1406\n",
      "Epoch 2441/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1403\n",
      "Epoch 2442/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0102 - val_loss: 0.1415\n",
      "Epoch 2443/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1415\n",
      "Epoch 2444/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1404\n",
      "Epoch 2445/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1408\n",
      "Epoch 2446/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1426\n",
      "Epoch 2447/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1408\n",
      "Epoch 2448/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1403\n",
      "Epoch 2449/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1410\n",
      "Epoch 2450/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1422\n",
      "Epoch 2451/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1403\n",
      "Epoch 2452/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1403\n",
      "Epoch 2453/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1408\n",
      "Epoch 2454/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1408\n",
      "Epoch 2455/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1405\n",
      "Epoch 2456/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1405\n",
      "Epoch 2457/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1411\n",
      "Epoch 2458/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1409\n",
      "Epoch 2459/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1401\n",
      "Epoch 2460/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1411\n",
      "Epoch 2461/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1409\n",
      "Epoch 2462/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1402\n",
      "Epoch 2463/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1417\n",
      "Epoch 2464/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1406\n",
      "Epoch 2465/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1414\n",
      "Epoch 2466/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1412\n",
      "Epoch 2467/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1411\n",
      "Epoch 2468/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1423\n",
      "Epoch 2469/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0132 - val_loss: 0.1407\n",
      "Epoch 2470/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1413\n",
      "Epoch 2471/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1418\n",
      "Epoch 2472/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1411\n",
      "Epoch 2473/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1420\n",
      "Epoch 2474/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0124 - val_loss: 0.1407\n",
      "Epoch 2475/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1424\n",
      "Epoch 2476/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0129 - val_loss: 0.1412\n",
      "Epoch 2477/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1415\n",
      "Epoch 2478/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1421\n",
      "Epoch 2479/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1416\n",
      "Epoch 2480/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - val_loss: 0.1425\n",
      "Epoch 2481/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0137 - val_loss: 0.1409\n",
      "Epoch 2482/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1444\n",
      "Epoch 2483/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0142 - val_loss: 0.1413\n",
      "Epoch 2484/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1417\n",
      "Epoch 2485/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0119 - val_loss: 0.1425\n",
      "Epoch 2486/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1420\n",
      "Epoch 2487/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1423\n",
      "Epoch 2488/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0126 - val_loss: 0.1410\n",
      "Epoch 2489/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1439\n",
      "Epoch 2490/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0133 - val_loss: 0.1418\n",
      "Epoch 2491/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1412\n",
      "Epoch 2492/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0120 - val_loss: 0.1414\n",
      "Epoch 2493/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1415\n",
      "Epoch 2494/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1417\n",
      "Epoch 2495/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1406\n",
      "Epoch 2496/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1414\n",
      "Epoch 2497/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1415\n",
      "Epoch 2498/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1408\n",
      "Epoch 2499/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1410\n",
      "Epoch 2500/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1411\n",
      "Epoch 2501/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1416\n",
      "Epoch 2502/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1406\n",
      "Epoch 2503/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1410\n",
      "Epoch 2504/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1415\n",
      "Epoch 2505/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1409\n",
      "Epoch 2506/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1406\n",
      "Epoch 2507/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1415\n",
      "Epoch 2508/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1412\n",
      "Epoch 2509/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1406\n",
      "Epoch 2510/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1412\n",
      "Epoch 2511/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1420\n",
      "Epoch 2512/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1410\n",
      "Epoch 2513/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1409\n",
      "Epoch 2514/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1423\n",
      "Epoch 2515/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1418\n",
      "Epoch 2516/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1409\n",
      "Epoch 2517/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1420\n",
      "Epoch 2518/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1425\n",
      "Epoch 2519/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1412\n",
      "Epoch 2520/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1409\n",
      "Epoch 2521/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1429\n",
      "Epoch 2522/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0116 - val_loss: 0.1420\n",
      "Epoch 2523/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1409\n",
      "Epoch 2524/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1419\n",
      "Epoch 2525/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1423\n",
      "Epoch 2526/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1414\n",
      "Epoch 2527/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1410\n",
      "Epoch 2528/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0115 - val_loss: 0.1419\n",
      "Epoch 2529/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1431\n",
      "Epoch 2530/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0112 - val_loss: 0.1412\n",
      "Epoch 2531/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1413\n",
      "Epoch 2532/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1431\n",
      "Epoch 2533/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1424\n",
      "Epoch 2534/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1416\n",
      "Epoch 2535/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1417\n",
      "Epoch 2536/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1433\n",
      "Epoch 2537/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1416\n",
      "Epoch 2538/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1411\n",
      "Epoch 2539/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1415\n",
      "Epoch 2540/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1417\n",
      "Epoch 2541/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1414\n",
      "Epoch 2542/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1410\n",
      "Epoch 2543/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1415\n",
      "Epoch 2544/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1421\n",
      "Epoch 2545/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1420\n",
      "Epoch 2546/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1416\n",
      "Epoch 2547/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1416\n",
      "Epoch 2548/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1426\n",
      "Epoch 2549/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0108 - val_loss: 0.1423\n",
      "Epoch 2550/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1416\n",
      "Epoch 2551/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1419\n",
      "Epoch 2552/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1425\n",
      "Epoch 2553/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1418\n",
      "Epoch 2554/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1418\n",
      "Epoch 2555/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1421\n",
      "Epoch 2556/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1425\n",
      "Epoch 2557/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1419\n",
      "Epoch 2558/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1418\n",
      "Epoch 2559/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1422\n",
      "Epoch 2560/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1421\n",
      "Epoch 2561/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1416\n",
      "Epoch 2562/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1419\n",
      "Epoch 2563/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1423\n",
      "Epoch 2564/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1415\n",
      "Epoch 2565/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1417\n",
      "Epoch 2566/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1426\n",
      "Epoch 2567/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1419\n",
      "Epoch 2568/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1418\n",
      "Epoch 2569/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1426\n",
      "Epoch 2570/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1434\n",
      "Epoch 2571/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1420\n",
      "Epoch 2572/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1423\n",
      "Epoch 2573/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1437\n",
      "Epoch 2574/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0117 - val_loss: 0.1425\n",
      "Epoch 2575/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1419\n",
      "Epoch 2576/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1422\n",
      "Epoch 2577/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1430\n",
      "Epoch 2578/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1419\n",
      "Epoch 2579/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1416\n",
      "Epoch 2580/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1425\n",
      "Epoch 2581/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1423\n",
      "Epoch 2582/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1416\n",
      "Epoch 2583/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1421\n",
      "Epoch 2584/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1428\n",
      "Epoch 2585/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1422\n",
      "Epoch 2586/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1417\n",
      "Epoch 2587/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1423\n",
      "Epoch 2588/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1424\n",
      "Epoch 2589/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1417\n",
      "Epoch 2590/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1421\n",
      "Epoch 2591/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1423\n",
      "Epoch 2592/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1422\n",
      "Epoch 2593/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1417\n",
      "Epoch 2594/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1427\n",
      "Epoch 2595/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1430\n",
      "Epoch 2596/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1420\n",
      "Epoch 2597/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1420\n",
      "Epoch 2598/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1430\n",
      "Epoch 2599/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1424\n",
      "Epoch 2600/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1420\n",
      "Epoch 2601/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1422\n",
      "Epoch 2602/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1426\n",
      "Epoch 2603/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1420\n",
      "Epoch 2604/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1423\n",
      "Epoch 2605/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1420\n",
      "Epoch 2606/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1423\n",
      "Epoch 2607/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1422\n",
      "Epoch 2608/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1424\n",
      "Epoch 2609/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1420\n",
      "Epoch 2610/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1420\n",
      "Epoch 2611/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1425\n",
      "Epoch 2612/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1423\n",
      "Epoch 2613/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1421\n",
      "Epoch 2614/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1428\n",
      "Epoch 2615/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1430\n",
      "Epoch 2616/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1425\n",
      "Epoch 2617/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1423\n",
      "Epoch 2618/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1436\n",
      "Epoch 2619/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1432\n",
      "Epoch 2620/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0110 - val_loss: 0.1422\n",
      "Epoch 2621/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1425\n",
      "Epoch 2622/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1431\n",
      "Epoch 2623/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1427\n",
      "Epoch 2624/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1422\n",
      "Epoch 2625/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1424\n",
      "Epoch 2626/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1432\n",
      "Epoch 2627/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1426\n",
      "Epoch 2628/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1423\n",
      "Epoch 2629/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1433\n",
      "Epoch 2630/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1428\n",
      "Epoch 2631/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1428\n",
      "Epoch 2632/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0114 - val_loss: 0.1429\n",
      "Epoch 2633/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1435\n",
      "Epoch 2634/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1433\n",
      "Epoch 2635/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1427\n",
      "Epoch 2636/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1438\n",
      "Epoch 2637/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1433\n",
      "Epoch 2638/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1430\n",
      "Epoch 2639/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1425\n",
      "Epoch 2640/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1433\n",
      "Epoch 2641/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1434\n",
      "Epoch 2642/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1424\n",
      "Epoch 2643/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1428\n",
      "Epoch 2644/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1438\n",
      "Epoch 2645/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1426\n",
      "Epoch 2646/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1427\n",
      "Epoch 2647/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1432\n",
      "Epoch 2648/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1437\n",
      "Epoch 2649/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1428\n",
      "Epoch 2650/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1426\n",
      "Epoch 2651/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1434\n",
      "Epoch 2652/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1442\n",
      "Epoch 2653/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1425\n",
      "Epoch 2654/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1429\n",
      "Epoch 2655/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1437\n",
      "Epoch 2656/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1429\n",
      "Epoch 2657/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1428\n",
      "Epoch 2658/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1432\n",
      "Epoch 2659/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1432\n",
      "Epoch 2660/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1427\n",
      "Epoch 2661/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1428\n",
      "Epoch 2662/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1438\n",
      "Epoch 2663/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1429\n",
      "Epoch 2664/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1426\n",
      "Epoch 2665/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1430\n",
      "Epoch 2666/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1431\n",
      "Epoch 2667/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1430\n",
      "Epoch 2668/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1430\n",
      "Epoch 2669/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1431\n",
      "Epoch 2670/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1429\n",
      "Epoch 2671/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1436\n",
      "Epoch 2672/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1432\n",
      "Epoch 2673/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1427\n",
      "Epoch 2674/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1440\n",
      "Epoch 2675/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1438\n",
      "Epoch 2676/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1429\n",
      "Epoch 2677/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1435\n",
      "Epoch 2678/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1437\n",
      "Epoch 2679/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1433\n",
      "Epoch 2680/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1434\n",
      "Epoch 2681/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1433\n",
      "Epoch 2682/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1440\n",
      "Epoch 2683/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1432\n",
      "Epoch 2684/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1432\n",
      "Epoch 2685/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1436\n",
      "Epoch 2686/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1433\n",
      "Epoch 2687/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1433\n",
      "Epoch 2688/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1437\n",
      "Epoch 2689/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1434\n",
      "Epoch 2690/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1434\n",
      "Epoch 2691/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1435\n",
      "Epoch 2692/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1435\n",
      "Epoch 2693/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1436\n",
      "Epoch 2694/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1433\n",
      "Epoch 2695/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1439\n",
      "Epoch 2696/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1436\n",
      "Epoch 2697/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1433\n",
      "Epoch 2698/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1438\n",
      "Epoch 2699/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1436\n",
      "Epoch 2700/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1438\n",
      "Epoch 2701/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1431\n",
      "Epoch 2702/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1436\n",
      "Epoch 2703/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1437\n",
      "Epoch 2704/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1429\n",
      "Epoch 2705/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1434\n",
      "Epoch 2706/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1436\n",
      "Epoch 2707/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1433\n",
      "Epoch 2708/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1436\n",
      "Epoch 2709/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1437\n",
      "Epoch 2710/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1440\n",
      "Epoch 2711/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1434\n",
      "Epoch 2712/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1436\n",
      "Epoch 2713/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1441\n",
      "Epoch 2714/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1440\n",
      "Epoch 2715/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1436\n",
      "Epoch 2716/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1438\n",
      "Epoch 2717/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1444\n",
      "Epoch 2718/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1435\n",
      "Epoch 2719/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1440\n",
      "Epoch 2720/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1436\n",
      "Epoch 2721/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1437\n",
      "Epoch 2722/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1441\n",
      "Epoch 2723/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1435\n",
      "Epoch 2724/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0084 - val_loss: 0.1436\n",
      "Epoch 2725/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1435\n",
      "Epoch 2726/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1436\n",
      "Epoch 2727/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1439\n",
      "Epoch 2728/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1437\n",
      "Epoch 2729/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1438\n",
      "Epoch 2730/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1438\n",
      "Epoch 2731/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1436\n",
      "Epoch 2732/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1435\n",
      "Epoch 2733/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1441\n",
      "Epoch 2734/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1437\n",
      "Epoch 2735/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1435\n",
      "Epoch 2736/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1442\n",
      "Epoch 2737/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1437\n",
      "Epoch 2738/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1444\n",
      "Epoch 2739/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1441\n",
      "Epoch 2740/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1440\n",
      "Epoch 2741/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1446\n",
      "Epoch 2742/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1449\n",
      "Epoch 2743/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1446\n",
      "Epoch 2744/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1446\n",
      "Epoch 2745/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1443\n",
      "Epoch 2746/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1442\n",
      "Epoch 2747/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1444\n",
      "Epoch 2748/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1441\n",
      "Epoch 2749/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1440\n",
      "Epoch 2750/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1441\n",
      "Epoch 2751/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1441\n",
      "Epoch 2752/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1441\n",
      "Epoch 2753/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1441\n",
      "Epoch 2754/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1442\n",
      "Epoch 2755/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1446\n",
      "Epoch 2756/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1446\n",
      "Epoch 2757/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1444\n",
      "Epoch 2758/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1444\n",
      "Epoch 2759/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1451\n",
      "Epoch 2760/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1446\n",
      "Epoch 2761/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1446\n",
      "Epoch 2762/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1449\n",
      "Epoch 2763/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1444\n",
      "Epoch 2764/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1443\n",
      "Epoch 2765/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1445\n",
      "Epoch 2766/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1442\n",
      "Epoch 2767/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1442\n",
      "Epoch 2768/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1440\n",
      "Epoch 2769/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1443\n",
      "Epoch 2770/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1442\n",
      "Epoch 2771/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1441\n",
      "Epoch 2772/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1447\n",
      "Epoch 2773/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1445\n",
      "Epoch 2774/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1442\n",
      "Epoch 2775/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1450\n",
      "Epoch 2776/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1448\n",
      "Epoch 2777/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1443\n",
      "Epoch 2778/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1443\n",
      "Epoch 2779/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1454\n",
      "Epoch 2780/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1445\n",
      "Epoch 2781/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1442\n",
      "Epoch 2782/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1450\n",
      "Epoch 2783/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1454\n",
      "Epoch 2784/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1442\n",
      "Epoch 2785/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1447\n",
      "Epoch 2786/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1456\n",
      "Epoch 2787/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1444\n",
      "Epoch 2788/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1446\n",
      "Epoch 2789/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1449\n",
      "Epoch 2790/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1443\n",
      "Epoch 2791/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1445\n",
      "Epoch 2792/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1445\n",
      "Epoch 2793/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1445\n",
      "Epoch 2794/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1442\n",
      "Epoch 2795/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1442\n",
      "Epoch 2796/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1447\n",
      "Epoch 2797/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1439\n",
      "Epoch 2798/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1440\n",
      "Epoch 2799/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1451\n",
      "Epoch 2800/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1443\n",
      "Epoch 2801/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1441\n",
      "Epoch 2802/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1450\n",
      "Epoch 2803/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1449\n",
      "Epoch 2804/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1446\n",
      "Epoch 2805/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1446\n",
      "Epoch 2806/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1456\n",
      "Epoch 2807/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1449\n",
      "Epoch 2808/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1444\n",
      "Epoch 2809/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1449\n",
      "Epoch 2810/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1451\n",
      "Epoch 2811/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1448\n",
      "Epoch 2812/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1444\n",
      "Epoch 2813/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1451\n",
      "Epoch 2814/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1447\n",
      "Epoch 2815/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1444\n",
      "Epoch 2816/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1455\n",
      "Epoch 2817/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1454\n",
      "Epoch 2818/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1448\n",
      "Epoch 2819/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1451\n",
      "Epoch 2820/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1462\n",
      "Epoch 2821/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1451\n",
      "Epoch 2822/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1451\n",
      "Epoch 2823/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1460\n",
      "Epoch 2824/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1454\n",
      "Epoch 2825/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1449\n",
      "Epoch 2826/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1459\n",
      "Epoch 2827/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1452\n",
      "Epoch 2828/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1450\n",
      "Epoch 2829/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1452\n",
      "Epoch 2830/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1451\n",
      "Epoch 2831/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1454\n",
      "Epoch 2832/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1450\n",
      "Epoch 2833/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1449\n",
      "Epoch 2834/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1459\n",
      "Epoch 2835/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1456\n",
      "Epoch 2836/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1449\n",
      "Epoch 2837/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1455\n",
      "Epoch 2838/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1458\n",
      "Epoch 2839/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1448\n",
      "Epoch 2840/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1448\n",
      "Epoch 2841/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1455\n",
      "Epoch 2842/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1454\n",
      "Epoch 2843/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1449\n",
      "Epoch 2844/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1449\n",
      "Epoch 2845/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1458\n",
      "Epoch 2846/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1454\n",
      "Epoch 2847/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1450\n",
      "Epoch 2848/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1470\n",
      "Epoch 2849/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0106 - val_loss: 0.1456\n",
      "Epoch 2850/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1453\n",
      "Epoch 2851/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1459\n",
      "Epoch 2852/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0083 - val_loss: 0.1465\n",
      "Epoch 2853/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1454\n",
      "Epoch 2854/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1454\n",
      "Epoch 2855/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1469\n",
      "Epoch 2856/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1458\n",
      "Epoch 2857/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1453\n",
      "Epoch 2858/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1472\n",
      "Epoch 2859/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1466\n",
      "Epoch 2860/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1453\n",
      "Epoch 2861/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1457\n",
      "Epoch 2862/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1469\n",
      "Epoch 2863/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1451\n",
      "Epoch 2864/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1451\n",
      "Epoch 2865/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1464\n",
      "Epoch 2866/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1453\n",
      "Epoch 2867/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1451\n",
      "Epoch 2868/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1458\n",
      "Epoch 2869/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1460\n",
      "Epoch 2870/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1451\n",
      "Epoch 2871/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1452\n",
      "Epoch 2872/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1461\n",
      "Epoch 2873/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1452\n",
      "Epoch 2874/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1452\n",
      "Epoch 2875/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1456\n",
      "Epoch 2876/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1454\n",
      "Epoch 2877/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1454\n",
      "Epoch 2878/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1461\n",
      "Epoch 2879/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1456\n",
      "Epoch 2880/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1453\n",
      "Epoch 2881/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1457\n",
      "Epoch 2882/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1458\n",
      "Epoch 2883/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0082 - val_loss: 0.1453\n",
      "Epoch 2884/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1456\n",
      "Epoch 2885/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1458\n",
      "Epoch 2886/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1452\n",
      "Epoch 2887/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1454\n",
      "Epoch 2888/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1461\n",
      "Epoch 2889/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1453\n",
      "Epoch 2890/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0078 - val_loss: 0.1451\n",
      "Epoch 2891/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1462\n",
      "Epoch 2892/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1460\n",
      "Epoch 2893/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1454\n",
      "Epoch 2894/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1461\n",
      "Epoch 2895/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1462\n",
      "Epoch 2896/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1459\n",
      "Epoch 2897/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1465\n",
      "Epoch 2898/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1464\n",
      "Epoch 2899/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1458\n",
      "Epoch 2900/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1457\n",
      "Epoch 2901/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1465\n",
      "Epoch 2902/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1459\n",
      "Epoch 2903/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0084 - val_loss: 0.1454\n",
      "Epoch 2904/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1464\n",
      "Epoch 2905/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1462\n",
      "Epoch 2906/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1456\n",
      "Epoch 2907/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1456\n",
      "Epoch 2908/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1470\n",
      "Epoch 2909/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1461\n",
      "Epoch 2910/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1459\n",
      "Epoch 2911/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1471\n",
      "Epoch 2912/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1465\n",
      "Epoch 2913/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1459\n",
      "Epoch 2914/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1462\n",
      "Epoch 2915/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1469\n",
      "Epoch 2916/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1461\n",
      "Epoch 2917/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1457\n",
      "Epoch 2918/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1466\n",
      "Epoch 2919/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1464\n",
      "Epoch 2920/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0101 - val_loss: 0.1455\n",
      "Epoch 2921/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1460\n",
      "Epoch 2922/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1466\n",
      "Epoch 2923/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1456\n",
      "Epoch 2924/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1456\n",
      "Epoch 2925/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1470\n",
      "Epoch 2926/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1460\n",
      "Epoch 2927/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1456\n",
      "Epoch 2928/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1463\n",
      "Epoch 2929/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1463\n",
      "Epoch 2930/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1454\n",
      "Epoch 2931/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1457\n",
      "Epoch 2932/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1462\n",
      "Epoch 2933/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1462\n",
      "Epoch 2934/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1457\n",
      "Epoch 2935/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1463\n",
      "Epoch 2936/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0087 - val_loss: 0.1469\n",
      "Epoch 2937/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1459\n",
      "Epoch 2938/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0084 - val_loss: 0.1458\n",
      "Epoch 2939/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1473\n",
      "Epoch 2940/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1467\n",
      "Epoch 2941/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1459\n",
      "Epoch 2942/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0109 - val_loss: 0.1461\n",
      "Epoch 2943/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1475\n",
      "Epoch 2944/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1456\n",
      "Epoch 2945/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1458\n",
      "Epoch 2946/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1472\n",
      "Epoch 2947/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1465\n",
      "Epoch 2948/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1462\n",
      "Epoch 2949/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1465\n",
      "Epoch 2950/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1473\n",
      "Epoch 2951/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1462\n",
      "Epoch 2952/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1463\n",
      "Epoch 2953/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1477\n",
      "Epoch 2954/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1462\n",
      "Epoch 2955/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1462\n",
      "Epoch 2956/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1468\n",
      "Epoch 2957/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0086 - val_loss: 0.1474\n",
      "Epoch 2958/3000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0098 - val_loss: 0.1462\n",
      "Epoch 2959/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0096 - val_loss: 0.1463\n",
      "Epoch 2960/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.0081 - val_loss: 0.1477\n",
      "Epoch 2961/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1466\n",
      "Epoch 2962/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0084 - val_loss: 0.1465\n",
      "Epoch 2963/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1478\n",
      "Epoch 2964/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1476\n",
      "Epoch 2965/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1466\n",
      "Epoch 2966/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0104 - val_loss: 0.1469\n",
      "Epoch 2967/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0083 - val_loss: 0.1474\n",
      "Epoch 2968/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1464\n",
      "Epoch 2969/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0085 - val_loss: 0.1463\n",
      "Epoch 2970/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1477\n",
      "Epoch 2971/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1469\n",
      "Epoch 2972/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0088 - val_loss: 0.1462\n",
      "Epoch 2973/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1472\n",
      "Epoch 2974/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1478\n",
      "Epoch 2975/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1463\n",
      "Epoch 2976/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1466\n",
      "Epoch 2977/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0084 - val_loss: 0.1488\n",
      "Epoch 2978/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0108 - val_loss: 0.1464\n",
      "Epoch 2979/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0091 - val_loss: 0.1464\n",
      "Epoch 2980/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0098 - val_loss: 0.1479\n",
      "Epoch 2981/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0094 - val_loss: 0.1473\n",
      "Epoch 2982/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0090 - val_loss: 0.1463\n",
      "Epoch 2983/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1467\n",
      "Epoch 2984/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0084 - val_loss: 0.1478\n",
      "Epoch 2985/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0102 - val_loss: 0.1465\n",
      "Epoch 2986/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0082 - val_loss: 0.1464\n",
      "Epoch 2987/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0089 - val_loss: 0.1482\n",
      "Epoch 2988/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1470\n",
      "Epoch 2989/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0093 - val_loss: 0.1465\n",
      "Epoch 2990/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0100 - val_loss: 0.1479\n",
      "Epoch 2991/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0099 - val_loss: 0.1483\n",
      "Epoch 2992/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0105 - val_loss: 0.1467\n",
      "Epoch 2993/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0113 - val_loss: 0.1465\n",
      "Epoch 2994/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0095 - val_loss: 0.1495\n",
      "Epoch 2995/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0123 - val_loss: 0.1471\n",
      "Epoch 2996/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0097 - val_loss: 0.1467\n",
      "Epoch 2997/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0122 - val_loss: 0.1476\n",
      "Epoch 2998/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0103 - val_loss: 0.1488\n",
      "Epoch 2999/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0107 - val_loss: 0.1465\n",
      "Epoch 3000/3000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0092 - val_loss: 0.1463\n"
     ]
    }
   ],
   "source": [
    "tf.config.run_functions_eagerly(True)\n",
    "history2 = model2.fit(array_X,y_train, batch_size = 1000, epochs = 3000,verbose=1,validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289f07c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss of VGG19')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0409b233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of VGG19 :  0.14059926706657025\n",
      "RMSE of VGG19 :  0.37496568785232903\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(array_X_test)\n",
    "m = mean_squared_error(y_test,y_pred)\n",
    "r = math.sqrt(m)\n",
    "print('MSE of VGG19 : ',m)\n",
    "print('RMSE of VGG19 : ',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9059ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
